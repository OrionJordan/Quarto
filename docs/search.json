[
  {
    "objectID": "qmd/integral/intro.html",
    "href": "qmd/integral/intro.html",
    "title": "Integration",
    "section": "",
    "text": "This section of notes is all about integration. I am currently studying for the 2024 UNT Integration bee. On the left you’ll see detailed strategies for solving different types of integrals.\nThe scope of this section is limited to integrals whos contents may appear in the UNT integration bee. As such no methods for definite integrals will be shown."
  },
  {
    "objectID": "qmd/graph/GraphTheory.html",
    "href": "qmd/graph/GraphTheory.html",
    "title": "Graph Theory",
    "section": "",
    "text": "Graph Theory is the study of Graphs (Shocking) and their applications. The subject doesn’t require any real prerequisites, except some basic knowledge of naive set theory. Many problems in math and computer science can be modeled with graphs, despite seeming on the surface entirely unrelated. In fact, even chemist have begun to use graphs as a way to model molecules!\n\nTable of Contents\n0 - Graph Theory\n  0.1 - Preface\n  0.2 - Table of Contents\n1 - Introduction\n  1.1 - Graphs\n    1.1.1 - Definition\n    1.1.2 - Common Families of Graphs\n  1.2 - Vertex Degrees\n  1.3 - Paths, Cycles, Trails\n2 - Structure and Representation\n3 - Matching\n4 - Subgraphs\n5 - Trees\n6 - Connectivity\n7 - Planarity\n8 - Coloring\n9 - Flows\n10 - Hamilton Cycles"
  },
  {
    "objectID": "qmd/integral/simple/trivial.html",
    "href": "qmd/integral/simple/trivial.html",
    "title": "Basics",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If \\frac{x}{dx}f(x) = g(x), then\n\n\\int g(x)dx = f(x) + C"
  },
  {
    "objectID": "qmd/basics/sets.html",
    "href": "qmd/basics/sets.html",
    "title": "Sets",
    "section": "",
    "text": "A set is a collection of elements, usually denoted with a capital letter A,B,\\cdots,Z. Important groups of numbers are denoted in Blackboard bold font; for example the set \\mathbb{N}, which refers to the natural numbers. Sets are given the following notation\nA set S containing the numbers 1,2 and 3 as elements is wrote S = \\{1,2,3\\}. The order in which the elements are listed is irrelevant, S = \\{1,2,3\\} = \\{3,2,1\\}. This notation becomes tedious however when attempting to write a set with a large amount of elements. This is where set builder notation comes in. Set builder notation defines a set in the form\nS = \\{\\text{A function of}\\: x \\:|\\: \\text{A predicate of}\\: x\\}\nFor example, the set of all square numbers would be\nS = \\{ x^2 \\:|\\: x \\in \\mathbb{N}\\} = \\{1,4,9,\\ldots\\}\nThere are very commonly used sets we assume the existence of, and denote with special characters to save time\nDefinition: Given any set A, the of A, denoted \\mathcal{P}(\\mathbb{A}) is the set of all subsets of A; i.e.\n\\mathcal{P}(A) = \\{B | B \\subseteq A\\}\nFor example, if A = \\{a,b\\}, then \\mathcal{P}(A) = \\{\\{\\},\\{a\\},\\{b\\},\\{a,b\\}\\} Notice that \\varnothing and A are always elements of \\mathcal{P}(A). Also note a \\not\\in \\mathcal{P}(A), but \\{a\\} \\in \\mathcal{P}(A)."
  },
  {
    "objectID": "qmd/basics/sets.html#footnotes",
    "href": "qmd/basics/sets.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\mathbb{Z} for integers comes from the German word Zahlen, which means integer.↩︎"
  },
  {
    "objectID": "qmd/basics/sets1.html",
    "href": "qmd/basics/sets1.html",
    "title": "Sets",
    "section": "",
    "text": "A set is a collection of elements, usually denoted with a capital letter A,B,\\cdots,Z. Important groups of numbers are denoted in Blackboard bold font; for example the set \\mathbb{N}, which refers to the natural numbers. Sets are given the following notation\nA set S containing the numbers 1,2 and 3 as elements is wrote S = \\{1,2,3\\}. The order in which the elements are listed is irrelevant, S = \\{1,2,3\\} = \\{3,2,1\\}. This notation becomes tedious however when attempting to write a set with a large amount of elements. This is where set builder notation comes in. Set builder notation defines a set in the form\nS = \\{\\text{A function of}\\: x \\:|\\: \\text{A predicate of}\\: x\\}\nFor example, the set of all square numbers would be\nS = \\{ x^2 \\:|\\: x \\in \\mathbb{N}\\} = \\{1,4,9,\\ldots\\}\nThere are very commonly used sets we assume the existence of, and denote with special characters to save time\nDefinition: Given any set A, the of A, denoted \\mathcal{P}(\\mathbb{A}) is the set of all subsets of A; i.e.\n\\mathcal{P}(A) = \\{B | B \\subseteq A\\}\nFor example, if A = \\{a,b\\}, then \\mathcal{P}(A) = \\{\\{\\},\\{a\\},\\{b\\},\\{a,b\\}\\} Notice that \\varnothing and A are always elements of \\mathcal{P}(A). Also note a \\not\\in \\mathcal{P}(A), but \\{a\\} \\in \\mathcal{P}(A)."
  },
  {
    "objectID": "qmd/basics/sets1.html#footnotes",
    "href": "qmd/basics/sets1.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\mathbb{Z} for integers comes from the German word Zahlen, which means integer.↩︎"
  },
  {
    "objectID": "qmd/basics/sets2.html",
    "href": "qmd/basics/sets2.html",
    "title": "Sets",
    "section": "",
    "text": "A set is a collection of elements, usually denoted with a capital letter A,B,\\cdots,Z. Important groups of numbers are denoted in Blackboard bold font; for example the set \\mathbb{N}, which refers to the natural numbers. Sets are given the following notation\nA set S containing the numbers 1,2 and 3 as elements is wrote S = \\{1,2,3\\}. The order in which the elements are listed is irrelevant, S = \\{1,2,3\\} = \\{3,2,1\\}. This notation becomes tedious however when attempting to write a set with a large amount of elements. This is where set builder notation comes in. Set builder notation defines a set in the form\nS = \\{\\text{A function of}\\: x \\:|\\: \\text{A predicate of}\\: x\\}\nFor example, the set of all square numbers would be\nS = \\{ x^2 \\:|\\: x \\in \\mathbb{N}\\} = \\{1,4,9,\\ldots\\}\nThere are very commonly used sets we assume the existence of, and denote with special characters to save time\nDefinition: Given any set A, the of A, denoted \\mathcal{P}(\\mathbb{A}) is the set of all subsets of A; i.e.\n\\mathcal{P}(A) = \\{B | B \\subseteq A\\}\nFor example, if A = \\{a,b\\}, then \\mathcal{P}(A) = \\{\\{\\},\\{a\\},\\{b\\},\\{a,b\\}\\} Notice that \\varnothing and A are always elements of \\mathcal{P}(A). Also note a \\not\\in \\mathcal{P}(A), but \\{a\\} \\in \\mathcal{P}(A)."
  },
  {
    "objectID": "qmd/basics/sets2.html#footnotes",
    "href": "qmd/basics/sets2.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\mathbb{Z} for integers comes from the German word Zahlen, which means integer.↩︎"
  },
  {
    "objectID": "qmd/graph/intro/graphs.html",
    "href": "qmd/graph/intro/graphs.html",
    "title": "Graphs",
    "section": "",
    "text": "This section covers the definition of a graph, and common families of graphs."
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#alternate-definition",
    "href": "qmd/graph/intro/graphs.html#alternate-definition",
    "title": "Graphs",
    "section": "Alternate definition",
    "text": "Alternate definition\nA more rigourous definition of a graph G will include an incidence function \\psi_G that connects vertices to edges.\n\n\n\n\n\n\nDefinition\n\n\n\nA graph G is an ordered pair (V(G),E(G)) where V(G) is a set of vertices and E(G) is a set, disjoint from V(G), of edges, along with an incidence function \\psi_G that associates each edge in E(G) an unordered pair of vertices in V(G).\n\n\nAn edge e is said to join its endpoints u,v if \\psi_G(e) = \\{u,v\\}.\n\n\n\n\n\n\nExample (Rigourous Graph)\n\n\n\n\n\nAn example of a rigourous graph G is\n\nG = (V(G),E(G))\n\nwhere\n\nV(G) = \\{a,b,c,d,e\\}\\\\\nE(G) = \\{e_1,e_2,e_3,e_4,e_5,e_6,e_7,e_8\\}\n\nand \\psi_G conncects\n\n\\psi_G(e_1) = \\{a,b\\}, \\psi_G(e_2) = \\{a,a\\}, \\psi_G(e_3) = \\{a,c\\}, \\psi_G(e_4) = \\{b,e\\}\\\\\n\\psi_G(e_5) = \\{b,a\\}, \\psi_G(e_6) = \\{c,b\\}, \\psi_G(e_7) = \\{d,d\\}, \\psi_G(e_8) = \\{c,e\\}"
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#complete-graphs",
    "href": "qmd/graph/intro/graphs.html#complete-graphs",
    "title": "Graphs",
    "section": "Complete Graphs",
    "text": "Complete Graphs\n\n\n\n\n\n\nDefinition\n\n\n\nA complete graph is a simple graph where there exist an edge between every pair of distinct vertices. A complete graph with n vertices is notated K_n.\n\n\n(Insert picture of graphs K1 through K5)\n\n\n\n\n\n\nTheorem\n\n\n\nA complete graph K_n contains \\binom{n}{2} edges.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe graph K_n has an edge between every pair of distinct vertices. Because order doesn’t affect edges (e = uv is equivalent to e = vu), the number of edges is analougous to n choose 2, \\binom{n}{2}."
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#bipartite-graphs",
    "href": "qmd/graph/intro/graphs.html#bipartite-graphs",
    "title": "Graphs",
    "section": "Bipartite Graphs",
    "text": "Bipartite Graphs\n\n\n\n\n\n\nDefinition\n\n\n\nA bipartite graph G is a simple graph whose vertex set can be partitioned into two subsets U and V, such that every edge in G has one endpoint in U, and one edpoint in V.\n\n\n(Insert picture of a few bipartite graphs)\n\n\n\n\n\n\nProposition\n\n\n\nA bipartite graph cannot contain any loops.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf an edge was loop, it would connect the same vertex to both endpoints, which contradicts our definition of a bipartite graph.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA complete bipartite graph G is a simple bipartite graph such that every vertex in one of the bipartition subsets is joined to every other vertex in the other bipartite subset. A complete bipartite graph is notated K_{m,n} where m is the number of vertices in one of the graphs bipartite set, and n is the number of vertices in the other.\n\n\n(Example of a complete bipartite graph)"
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#regular-graphs",
    "href": "qmd/graph/intro/graphs.html#regular-graphs",
    "title": "Graphs",
    "section": "Regular Graphs",
    "text": "Regular Graphs\nTo look at regular graphs, we first have to establish the degree of a vertex.\n\n\n\n\n\n\nDefinition\n\n\n\nThe degree of a vertex v is a positive integer equal to the number of vertices in the neighborhood of v.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA k-regular graph is a graph where each vertex has k other vertices in it’s neighborhood.\n\n\n\n\n\n\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n\n\nFor example, the Petersen graph is 3-regular, as each vertex in the graph has three other vertices in it’s neighborhood."
  },
  {
    "objectID": "qmd/graph/trees/Matchings.html",
    "href": "qmd/graph/trees/Matchings.html",
    "title": "Matchings",
    "section": "",
    "text": "A Matching is a name given to a collection of edges in a graph G with no common vertex.\n\n\n\n\n\n\nDefinition\n\n\n\nGiven a graph G and a matching M\nAn alternating path is a path that alternates between edges in M and edges outside of M.\nAn augmented Path is an alternating path that starts and ends on vertices not included in the matching.\n\n\nNote that is (G,M) has an augmented path, than M is not a maximum matching, as flipping each edge to be in M if it wasn’t before, or out of M if it was produces a matching with more edges.\n\n\n\n\n\n\nDefinition\n\n\n\nA perfect matching is a matching where every vertex is in the matching.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nA matching M in a graph G is maximum if and only if there are no augementing paths in G\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe already know that if G,M has an augmented path, then M is not maximum. All we need to prove is thay if there are no augmented paths, than M is maximum. If we assume M is not maximum, there exist a matching M^\\prime such that |M^\\prime| &gt; |M|.\nConsider the graph with a vertex set of V(G) and an edge set M \\Delta M^\\prime. Every vertex in this graph has a degree less than or equal to 2. Any connected componet of this new graph will be either a path or a cycle."
  },
  {
    "objectID": "qmd/about.html",
    "href": "qmd/about.html",
    "title": "Orions Online Math Notes",
    "section": "",
    "text": "A work in progress website documenting my varius math and lecture notes."
  },
  {
    "objectID": "qmd/random/discrete.html",
    "href": "qmd/random/discrete.html",
    "title": "Discrete Calculus",
    "section": "",
    "text": "Discrete calculus, sometimes called Finite calculus, is the study of incremental change, as opposed to regular calculus, the study of continuous change. Discrete calculus most regularly deals with solving summations and functions defined on the natural numbers."
  },
  {
    "objectID": "qmd/random/discrete.html#discrete-derivative",
    "href": "qmd/random/discrete.html#discrete-derivative",
    "title": "Discrete Calculus",
    "section": "Discrete Derivative",
    "text": "Discrete Derivative\nIn continuous calculus, the derivative is the ‘instantaneous rate of change’ of a function. That concept can’t exist with incremental change. The smallest rate of change in a discrete function is the change between integers. Therefore we define our discrete derivative\n\n\n\n\n\n\nDefinition\n\n\n\nThe discrete derivative is the smallest change in a discrete function, defined $$ f(x) = f(x+1) - f(x)\n\n\nWe can now prove may properties about the discrete derivative\n\n\n\n\n\n\nTheorem\n\n\n\nThe discrete derivative has the following properties\nConstant rule\n\\Delta c = 0 for all c \\in \\mathbb{N}\nLinearity\n\\Delta af(x) = a \\Delta f(x)\nProduct rule\n\\Delta f(x)g(x) = f(x) \\Delta g(x) + g(x) \\Delta f(x) + \\Delta f(x) \\Delta g(x)\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nTo-do\n\n\n\n\nFunctions\nNow that we’ve defined the discrete derivative, we can start finding the discrete derivative of functions.\nTake for example, the function"
  },
  {
    "objectID": "qmd/integral/simple/basics.html",
    "href": "qmd/integral/simple/basics.html",
    "title": "Basics",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If f^\\prime(x) = g(x), then\n\\int g(x)\\,dx = f(x) + C.\nIntegrals have a property called linearity. This means they are closed under linear transformations of functions, as shown below.\n\\int \\alpha f(x) + \\beta g(x) \\,dx = \\alpha \\int f(x) \\,dx+ \\beta \\int g(x) \\,dx"
  },
  {
    "objectID": "qmd/integral/simple/basics.html#inverse-power-rule",
    "href": "qmd/integral/simple/basics.html#inverse-power-rule",
    "title": "Basics",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/simple/basics.html#common-identities",
    "href": "qmd/integral/simple/basics.html#common-identities",
    "title": "Basics",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/simple/substitution.html",
    "href": "qmd/integral/simple/substitution.html",
    "title": "Substitution",
    "section": "",
    "text": "The motivating example for this section will be the integral shown below.\n\\int \\sec^2(x)e^{1 + \\tan{x}} \\, dx\nThe techniques shown in the last section don’t work here. Linearity does not allow for separation of products, and we don’t have an identity which gets us a solution. In order to solve these types of integrals, we’ll need a new rule.\nSubstitution for integrals is often in the form\n\\int f(g(x))g^\\prime(x)\\, dx = \\int f(u)\\, du, \\text{where } u = g(x)."
  },
  {
    "objectID": "qmd/integral/simple/substitution.html#inverse-power-rule",
    "href": "qmd/integral/simple/substitution.html#inverse-power-rule",
    "title": "Substitution",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/simple/substitution.html#common-identities",
    "href": "qmd/integral/simple/substitution.html#common-identities",
    "title": "Substitution",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logorithmic functions\nBy once again inversing common derivaitve rules, we get the following identites.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/simple/intpart.html",
    "href": "qmd/integral/simple/intpart.html",
    "title": "Integration by parts",
    "section": "",
    "text": "There will often be integrals where substitution cannot simplify the integrand into one term. We can use the following as our motivating example\n\\int x e^{6x} dx\nAttempting to use a substitution, such as u = 6x gives us\n\\int ue^u\\,du\nwhich while technically simpler gets us nowhere. We need a new technique to be able to properly separate functions where substitution fails. This is where integration by parts comes in.\nLets try to use the formula to solve our example. We can choose u to be either term in our example.\nAnd voila, our integral is solved."
  },
  {
    "objectID": "qmd/integral/simple/intpart.html#tabular-method",
    "href": "qmd/integral/simple/intpart.html#tabular-method",
    "title": "Integration by parts",
    "section": "Tabular method",
    "text": "Tabular method\nAn easier (faster) way to do integration by parts is known as the Tabular method. The tabular method can quickly calculate repeated integration by parts.\n\n\n\n\n\n\nExample (Stop 1)\n\n\n\n\n\nThe following example will show the first ‘stop’ used in tabular integration.\nFind the solution to the following integral\n\n\\int x^2 \\sin(3x) \\, dx\n\nThis could be solved using our formula for integration by parts, but this results in a messy calculation using repeated integration by parts. In order to solve these problems faster, we will use the Tabular method.\nFirst, choose two terms to work with in the integral. We will choose x^2 and \\sin(3x). We want to choose a term that will eventually default to 0 after repeated differention. Place this term under the D in your table, and the other term under the I. Draw a plus to the left of your terms.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\n\\end{array}\nTo begin, we will differentiate the term under our D, and integrate the term under our I, then flip the sign.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\\\\\n- & \\hspace{0.25in} 2x \\hspace{0.25in} & \\frac{1}{3}\\cos(3x)\n\\end{array}\nRepeating this process eventually gives us a 0 in our D column. This is our first stop, meaning we don’t need any more steps.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\\\\\n- & \\hspace{0.25in} 2x \\hspace{0.25in} & -(1/3)\\cos(3x)\\\\\n+ & \\hspace{0.25in} 2 \\hspace{0.25in} & -(1/9)\\sin(3x)\\\\\n- & \\hspace{0.25in} 0 \\hspace{0.25in} & (1/27)\\cos(3x)\\\\\n\\end{array}\nMultiply the n^{th} under the D by the (n+1)^{th} term under the I. Then add or subtract the product by the sign the the left of the D column. This is the answer to our integral.\n\n\\int x^2 \\sin (3x) \\,dx = -\\frac{1}{3}x^2\\cos(3x) + \\frac{2}{9}x\\sin(3x) - \\frac{2}{27}\\cos(3x) + C\n\nAnd we’re done!\n\n\n\n\n\n\n\n\n\nExample (Stop 2)\n\n\n\n\n\nThe following example will show the second ‘stop’ used in tabular integration.\n\n\\int x^4 \\ln x \\,dx\n\nAlthough it seems obvious we should put x^4 under the D column, we quickly realize that we cannot integrate \\ln x without integration by parts. Because of this, we have no choice but to but \\ln x under the D column. Carrying on with our calculations\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\ln x \\hspace{0.25in} & x^4\\\\\n- & \\hspace{0.25in} x^{-1} \\hspace{0.25in} & (1/5)x^5\n\\end{array}\nWe can quickly notice that 0 will never appear under the D column. This is where our second stop comes in. If we can easily calculate the integral of a rows product (That is, the product of terms under the D and I columns for a singular row) than we stop, and add the integral of that row to our diagonal solution.\n\n\\int x^4 \\ln x \\,dx = \\frac{1}{5}x^5\\ln x  - \\frac{1}{5} \\int x^{-1}x^5\n\nThis is formula for regular integration by parts, so unfortunately this didn’t save us any time, but we still got the right answer!\n\n\\int x^4 \\ln x \\,dx = \\frac{1}{5}x^5\\ln x  - \\frac{1}{25} x^5\n\n\n\n\n\n\n\n\n\n\nExample (Stop 3)\n\n\n\n\n\nThe following example will show the third ‘stop’ used in tabular integration.\n\n\\int e^x \\sin x \\,dx\n\nIntegrating e^x and \\sin x are both easy. I’ll choose to integrate e^x for simplicity sake.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\sin x \\hspace{0.25in} & e^x\\\\\n- & \\hspace{0.25in} \\cos x \\hspace{0.25in} & e^x\\\\\n+ & \\hspace{0.25in} -\\sin x \\hspace{0.25in} & e^x\\\\\n- & \\hspace{0.25in} -\\cos x \\hspace{0.25in} & e^x\n\\end{array}\nClearly this will go on forever without a 0 under our D column, or an easily integrable row. This introduces our third stop. Notice that our first and third rows only differ by a constant coefficient. When this happens, we write our diagonalization and our integral, stopping at the repeated row.\n\n\\int e^x \\sin x \\,dx = e^x \\sin x - e^x \\cos(x) - \\int e^x \\sin x \\, dx\n\nNotice how this is the same integral on the left and right hand of the equation. Moving the integral over gives us\n\n2\\int e^x \\sin x \\,dx = e^x \\sin x - e^x \\cos(x)\n\nDiving by 2\n\n\\int e^x \\sin x \\,dx = \\frac{e^x \\sin x - e^x \\cos(x)}{2}\n\nAnd we have our answer.\n\n\n\nClearly the tabular method is a huge time saver for repeated integration by parts."
  },
  {
    "objectID": "qmd/integral/simple/basics.html#examples",
    "href": "qmd/integral/simple/basics.html#examples",
    "title": "Basics",
    "section": "Examples",
    "text": "Examples\nSome example problems from various websites\n\nInverse power rule\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5 - 18x^2 + 7 \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the formula for evaluating polynomials\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 6x^3 + 7x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5\\, dx - 18x^2 + 7\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice the integral ends at the dx, meaning the solution is\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 18x^2 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.3)\n\n\n\nEvaluate the following integral\n\n\\int 12t^7 - t^2 - t + 3 \\, dt\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nClassic polynomial, the only difference is the use of t instead of x\n\n\\int 12t^7 - t^2 - t + 3 \\, dt = \\frac{3}{2}t^8 - \\frac{1}{3}t^3 - \\frac{1}{2}t^2 + 3t + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.6)\n\n\n\nEvaluate the following integral\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponets\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\int w^\\frac{1}{3} + 10w^\\frac{3}{5} \\, dw\n\nAnd then apply inverse power rule\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\frac{3}{4}w^\\frac{4}{3} + \\frac{25}{4}w^\\frac{8}{5} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.9)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponents\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = \\int \\frac{7}{3}y^{-6} + y^{-10} - 2y^{\\frac{4}{3}} \\, dy\n\nAnd then apply inverse power rule\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = -\\frac{7}{15}y^{-5} - \\frac{1}{9} y^{-9} + 6y^{-\\frac{1}{3}} + C\n\nBe careful to make sure you have the right answer.\n\n\n\n\n\nCommon identites\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.14)\n\n\n\nEvaluate the following integral\n\n\\int \\sin x + 10 \\csc^2 x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int \\sin x + 10 \\csc^2 x \\, dx = -\\cos x - 10 \\cot x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.15)\n\n\n\nEvaluate the following integral\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx = 2 \\sin x - \\sec x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.16)\n\n\n\nEvaluate the following integral\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMultiply out and simplify the equation. \n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = \\int 12 + 1 + \\csc^2 \\theta \\, d\\theta\n\nBecause\n\n\\csc x= \\frac{1}{\\sin x}\n\nSo we get the answer\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = 13 \\theta + \\cot \\theta + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.20)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the inverse trig identities\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}} = \\arctan x + 12 \\arcsin x + C"
  },
  {
    "objectID": "qmd/integral/simple/substitution.html#examples",
    "href": "qmd/integral/simple/substitution.html#examples",
    "title": "Substitution",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.1)\n\n\n\nEvaluate the following integral\n\n\\int   {{\\left( {8x - 12} \\right){{\\left( {4{x^2} - 12x} \\right)}^4}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = 4x^2 - 12x\n\nWe get \n\\int   {{\\left( {8x - 12} \\right){{\\left( {4{x^2} - 12x} \\right)}^4}\\,dx}} = \\frac{1}{5}(4x^2 - 12x)^5 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.2)\n\n\n\nEvaluate the following integral\n\n\\int{{3{t^{ - 4}}{{\\left( {2 + 4{t^{ - 3}}} \\right)}^{ - 7}}\\,dt}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = 2 - 4t^{-3}\n\nWe get \n\\int{{3{t^{ - 4}}{{\\left( {2 + 4{t^{ - 3}}} \\right)}^{ - 7}}\\,dt}} = \\frac{1}{24}(2+4t^{-3})^{-6} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.14)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst notice how \\csc x \\cot x is clearly the derivative of -\\csc x. This leads us to try some form of \\csc x for u. I use\n\nu = \\csc x\n\nLeading too \n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx = - \\int \\frac{1}{2 - u} \\, du\n\nWhich is clearly\n\n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx = \\ln |2 - u| + C = \\ln |2 - \\csc x| + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.13)\n\n\n\nEvaluate the following integral\n\n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhile the integral looks incredibly complex, if we substitute the term inside the radical (the usual choice) we can start to break it down.\n\nu = \\cos^2(2x) - 5\n\nThus \n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}} = -\\frac{5}{2} \\int \\sqrt{u} \\, du\n\nWhich leads too\n\n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}} = -\\frac{5}{3}(\\cos^2(2x) - 5)^\\frac{3}{2} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.15)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{6}{7 + y^2} \\,dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis does not follow our usual f(g(x))g^\\prime(x) example. For this case, we’ll try to convert into an identity we know. It is clear we can’t have y^2 be a term in u, as this would only make the integral more complicated (as thers no y to be consumed in the du). The integrand sorta resembles the derivative of \\arctan y, so we can try to rewrite it\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6}{7} \\int \\frac{1}{1 + \\frac{y^2}{7}} \\, dy\n\nNotice that if we make the substitution \nu = \\frac{y}{\\sqrt{7}}\n\nWe get\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6\\sqrt{7}}{7} \\int \\frac{1}{1 + u^2} \\, du\n\nWhich gives us\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6\\sqrt{7}}{7} \\arctan \\left(\\frac{y}{\\sqrt{7}}\\right) + C\n\n\n\n\n\n\n\n\n\n\nProblem - Arctan generalization\n\n\n\nEvaluate the previous integral in it’s general form\n\n\\int \\frac{1}{a^2 + x^2} \\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLike last time, we’ll factor out a^2 from the bottom and then use a substitution.\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a^2} \\int \\frac{1}{1 + (x^2/a^2)} \\, dy\n\nMakeing the substitution \nu = \\frac{x}{a}\n\nWe get\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a} \\int \\frac{1}{1 + u^2} \\, dx\n\nWhich gives us\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a} \\arctan \\left(\\frac{x}{a}\\right) + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.4.6)\n\n\n\nEvaluate the following integral\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\, + 7{w^3} - 6\\,\\,\\sqrt[3]{w}\\,dw}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing linearity on the integral allows us to do different substitutions. Seeing as the last two terms can be integrated with the inverse power rule, we only need to a substitution on the first term. Luckily this is an easy case.\n\nu = 1 + e^{2-8w}\n\nGives\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\,dw} = -\\frac{5}{2}\\int \\sqrt{u}\\, du\n\nWhich is\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\,dw} = -\\frac{5}{3}(1 + e^{2-8w})^\\frac{3}{2} + C\n\nThen solving the other terms gives us our solution.\n\n= -\\frac{5}{3}(1 + e^{2-8w})^\\frac{3}{2} + \\frac{7}{4}w^4 - \\frac{9}{2}w^\\frac{4}{3} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - A7.1.18)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = x^4 + 1\n\nWe get\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}} = \\frac{1}{4}\\int \\frac{u - 1}{\\sqrt{u}}\n\nWhich we can then apply linearity and inverse power rule to, giving us\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}} = \\frac{1}{4}\\left( \\frac{2}{3}(x^4 + 1)^\\frac{3}{2} + 2(x^4 + 1)^\\frac{1}{2}\\right) + C"
  },
  {
    "objectID": "qmd/integral/simple/intpart.html#examples",
    "href": "qmd/integral/simple/intpart.html#examples",
    "title": "Integration by parts",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nProblem\n\n\n\nEvaluate the following integral\n\n\\int \\ln x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolving this is a little counter intuitive seeing as it only has one term. If we let 1 be the second term however, we can evaluate with the tabular method. We pretty cleary have the integrate 1, as we can’t integrate \\ln x.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\ln x \\hspace{0.25in} & 1\\\\\n- & \\hspace{0.25in} \\frac{1}{x} \\hspace{0.25in} & x\n\\end{array}\nBecause the product of the second row is easy to integrate, we stop using the tabular method and compute.\n\n\\int \\ln x \\, dx = x \\ln x - \\int 1 \\, dx = x \\ln x - x + C\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - 7.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 4x \\cos \\left( {2 - 3x} \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe have two terms, 4x and \\cos (2-3x). Its clear that differentiaing 4x will give us 0 quickly, so we begin with the tabular method.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} 4x \\hspace{0.25in} & \\cos (2-3x)\\\\\n- & \\hspace{0.25in} 4 \\hspace{0.25in} & -(1/3)\\sin (2-3x)\\\\\n+ & \\hspace{0.25in} 0 \\hspace{0.25in} & -(1/9)\\cos (2-3x)\\\\\n\\end{array}\nWe use the first stop, and get the following solution to the integral\n\n\\int 4x \\cos \\left( {2 - 3x} \\right)\\,dx = -\\frac{4x}{3}\\sin (2-3x) - \\frac{4}{9} \\cos (2-3x) + C\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - 7.1.5)\n\n\n\nEvaluate the following integral\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWithout any leads on which term to integrate, I choose to integrate cos(\\frac{1}{4}x) on a whim. You may integrate either term however, and the answer will be the same.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} e^{2x} \\hspace{0.25in} & \\cos ((1/4)x)\\\\\n- & \\hspace{0.25in} 2e^{2x} \\hspace{0.25in} & 4\\sin ((1/4)x)\\\\\n+ & \\hspace{0.25in} 4e^{2x} \\hspace{0.25in} & -16\\cos ((1/4)x)\\\\\n\\end{array}\nNotice how the product of row three is a multiple of our initial integral. This is the third stop, so we evaluate our table to get.\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = 4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x) - 64\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx\n\n\n65 \\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = 4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x)\n\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = \\frac{4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x)}{65}\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - A7.1.12)\n\n\n\nEvaluate the following integral\n\n\\int 8\\arctan\\left( 2x \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBecause integrating \\arctan is the question, we will derive it instead, and integrate the 8.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\arctan(2x) \\hspace{0.25in} & 8\\\\\n- & \\hspace{0.25in} 2/(1+4x^2) \\hspace{0.25in} & 8x\\\\\n\\end{array}\nUsing our third stop and integrating the second row, we get\n\n\\int 8\\arctan\\left(2x\\right)\\,dx = 8x\\arctan(2x) - \\int \\frac{8x}{1+4x^2}\n\nApplying a substitution \nu = 4x^2\n\nWe get \n\\int 8\\arctan\\left(2x \\right)\\,dx = 8x\\arctan(2x) - \\ln |1+4x^2| + C\n\nSolving our integral."
  },
  {
    "objectID": "qmd/integral/simple/decomp.html",
    "href": "qmd/integral/simple/decomp.html",
    "title": "Partial fraction decomposition",
    "section": "",
    "text": "Consider the integral shown below.\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}}\nOur current methods will not work to evaluate the integral. There is no simple way to apply a substitution or the tabular method. However, if we break up the fraction\n\\frac{{3x + 11}}{{{x^2} - x - 6}} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\nThe solution becomes trivial\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C.\nFinding ways to break up the fractions is known as partial fraction decomposition."
  },
  {
    "objectID": "qmd/integral/simple/decomp.html#examples",
    "href": "qmd/integral/simple/decomp.html#examples",
    "title": "Partial fraction decomposition",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nJoe Foster (Integration by parts - C3)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can break up the integral as it contains distinct quadratic factors.\n\n\\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} =  \\frac{Ax + B}{x^2 + 1} + \\frac{Cx + D}{x^2 + 2}\n\nCross multiplying \nx^3 + x^2 + 2x + 1 = (Ax + B)(x^2 + 2) + (Cx + D)(x^2 + 1)\n\nGives us the following system of equations\n\\begin{array}{ll}\nx^3  & = (A + C)x^3\\\\\nx^2 & = (B + D)x^2\\\\\n2x & = (2A + C)x \\\\\n1 & = (2B + D)\n\\end{array}\nSolving the system yields\n\\begin{array}{ll}\nA = 1  & B = 0\\\\\nC = 0 & D = 1\n\\end{array}\nThis solves our decomposition. We now have to integrate\n\n\\int \\frac{x}{x^2 + 1} + \\frac{1}{x^2 + 2} \\, dx\n\nThe first term can be solved by the substitution u = x^2, and the second term can be evaluated with an \\arctan x. This gives us\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx = \\frac{1}{2}\\ln |x^2 + 1| + \\frac{1}{\\sqrt{2}} \\arctan \\left( \\frac{x}{\\sqrt{2}} \\right) + C"
  },
  {
    "objectID": "qmd/integral/simple/decomp.html#method",
    "href": "qmd/integral/simple/decomp.html#method",
    "title": "Partial fraction decomposition",
    "section": "Method",
    "text": "Method\nWhen given an integral in the form\n\n\\int \\frac{P(X)}{Q(X)} \\, dx\n\nWhere P(x) and Q(x) are polynomials such that the degree of Q(x) is higher than the degree of P(x). We can decompose the fraction based on the factors of Q(x). There are four cases for the factors of Q(x).\n\n\n\n\n\n\nDecomposition cases\n\n\n\n\n\nCase I: Distinct linear factors\nWhen Q(x) has distinct linear factors, i.e.\n\nQ(x) = (a_1 x + b_1)(a_2 x + b_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{B}{a_2x + b_2}\n\nCase 2: Repeated linear factors\nWhen Q(x) has repeated linear factors, i.e.\n\nQ(x) = (a x + b)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1}{ax + b} + \\frac{A_2}{(ax + b)^2} + \\cdots + \\frac{A_k}{(a x + b)^k}\n\nCase 3: Distinct quadratic factors\nWhen Q(x) has distinct quadratic factors, i.e.\n\nQ(x) = (a_1 x^2 + b_1x + c_1)(a_2 x^2 + b_2x + c_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1 + B_1}{a_1 x^2 + b_1x + c_1} + \\frac{A_2 + B_2}{a_2 x^2 + b_2x + c_2}\n\nCase 4: Repeated quadratic factors\nWhen Q(x) has repeated quadratic factors, i.e.\n\nQ(x) = (a x^2 + bx + c)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1x + B_1}{a x^2 + bx + c} + \\cdots + \\frac{A_kx + B_k}{(a x^2 + bx + c)^k}\n\n\n\n\nNote that Q(x) does not have one case of factors exculsivly. For example\n\nQ(x) = (a_1x+b_1)(a_2x^2 + b_2x + c_2)^2\n\nWill decompose into\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{Bx + C}{a_2 x^2 + b_2x + c_2} + \\frac{Dx + E}{(a_2 x^2 + b_2x + c_2)^2}\n\nNext we need a method for finding the value of the constants in the numerator.\n\n\n\n\n\n\nEvaluating constants\n\n\n\n\n\nConsider the integral from the beginning\n\n\\int \\frac{3x + 11}{x^2 - x - 6} \\,dx\n\nWe can now decompose the integrand to obtain\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A}{x - 3} + \\frac{B}{x + 2}\n\nThe problem is now finding values for the constants A,B which make the relation true. By cross multiplying the right side of the equation we get\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A(x + 2) + B(x - 3)}{(x - 3)(x + 2)}\n\nWhich simplifies to\n\n3x + 11 = A(x + 2) + B(x - 3).\n\nWe can then create a system of equations such that the above expression is always true. This method is long but will always work. The faster method (that isn’t always possible) is to find values of x such that the equation reduces. Using the faster method, we obtain\n\nx = 3 \\: : \\: 3(3) + 11 = A(3 + 2) + B(3 - 3) \\implies A = 4\\\\\nx = -2 \\: : \\: 3(-2) + 11 = A(-2 + 2) + B(-2 - 3) \\implies B = -1\n\nWhich gives us our final expression\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\n\nWhich as shown above, makes the integral trivial to solve.\n\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C."
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html",
    "href": "qmd/integral/tricky/hyperbolic.html",
    "title": "Hyperbolic trigonometry",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If f^\\prime(x) = g(x), then\n\\int g(x)\\,dx = f(x) + C.\nIntegrals have a property called linearity. This means they are closed under linear transformations of functions, as shown below.\n\\int \\alpha f(x) + \\beta g(x) \\,dx = \\alpha \\int f(x) \\,dx+ \\beta \\int g(x) \\,dx"
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html#inverse-power-rule",
    "href": "qmd/integral/tricky/hyperbolic.html#inverse-power-rule",
    "title": "Hyperbolic trigonometry",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html#common-identities",
    "href": "qmd/integral/tricky/hyperbolic.html#common-identities",
    "title": "Hyperbolic trigonometry",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html#examples",
    "href": "qmd/integral/tricky/hyperbolic.html#examples",
    "title": "Hyperbolic trigonometry",
    "section": "Examples",
    "text": "Examples\nSome example problems from various websites\n\nInverse power rule\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5 - 18x^2 + 7 \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the formula for evaluating polynomials\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 6x^3 + 7x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5\\, dx - 18x^2 + 7\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice the integral ends at the dx, meaning the solution is\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 18x^2 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.3)\n\n\n\nEvaluate the following integral\n\n\\int 12t^7 - t^2 - t + 3 \\, dt\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nClassic polynomial, the only difference is the use of t instead of x\n\n\\int 12t^7 - t^2 - t + 3 \\, dt = \\frac{3}{2}t^8 - \\frac{1}{3}t^3 - \\frac{1}{2}t^2 + 3t + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.6)\n\n\n\nEvaluate the following integral\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponets\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\int w^\\frac{1}{3} + 10w^\\frac{3}{5} \\, dw\n\nAnd then apply inverse power rule\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\frac{3}{4}w^\\frac{4}{3} + \\frac{25}{4}w^\\frac{8}{5} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.9)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponents\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = \\int \\frac{7}{3}y^{-6} + y^{-10} - 2y^{\\frac{4}{3}} \\, dy\n\nAnd then apply inverse power rule\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = -\\frac{7}{15}y^{-5} - \\frac{1}{9} y^{-9} + 6y^{-\\frac{1}{3}} + C\n\nBe careful to make sure you have the right answer.\n\n\n\n\n\nCommon identites\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.14)\n\n\n\nEvaluate the following integral\n\n\\int \\sin x + 10 \\csc^2 x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int \\sin x + 10 \\csc^2 x \\, dx = -\\cos x - 10 \\cot x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.15)\n\n\n\nEvaluate the following integral\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx = 2 \\sin x - \\sec x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.16)\n\n\n\nEvaluate the following integral\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMultiply out and simplify the equation. \n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = \\int 12 + 1 + \\csc^2 \\theta \\, d\\theta\n\nBecause\n\n\\csc x= \\frac{1}{\\sin x}\n\nSo we get the answer\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = 13 \\theta + \\cot \\theta + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.20)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the inverse trig identities\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}} = \\arctan x + 12 \\arcsin x + C"
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html",
    "href": "qmd/integral/simple/trigsub.html",
    "title": "Trig substitutions",
    "section": "",
    "text": "Our motivation for this section is the following integral\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx\nThis integral is very difficult to solve with the previous techniques. The trick comes from the substitution\nx = \\frac{2}{5}\\sec \\theta\nWhich after a fair amount of algebra and calculus gives us\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx = \\sqrt{25x^2 - 4} + 2\\arccos \\left(\\frac{2}{5x}\\right) + C\nSolving these integrals relies on a method known as trigonometric substitutions."
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#inverse-power-rule",
    "href": "qmd/integral/simple/trigsub.html#inverse-power-rule",
    "title": "Trig substitutions",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#common-identities",
    "href": "qmd/integral/simple/trigsub.html#common-identities",
    "title": "Trig substitutions",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#examples",
    "href": "qmd/integral/simple/trigsub.html#examples",
    "title": "Trig substitutions",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nProblem\n\n\n\nEvaluate the following integral\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice that the radicle expression resembles the third row of our table. If we make the substitution\n\nx = 3\\sin \\theta\\\\\ndx = 3\\cos\\theta\\,d\\theta\n\nWe get\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx = \\int\\frac{3\\sqrt{1-\\sin^2\\theta}}{9\\sin^2\\theta}(3\\cos\\theta)\\,d\\theta = \\int\\frac{\\cos^2\\theta}{\\sin^2\\theta} d\\theta\n\nWhich evaulates to \n\\int\\frac{\\cos^2\\theta}{\\sin^2\\theta} d\\theta = -\\cot\\theta - \\theta + C\n\nThis however, is only half the problem. We still need to convert the equation back to its orginal variable. Once again, the method of drawing a triangle will help to simplify the final expression.\nNote that \\sin \\theta = \\displaystyle\\frac{\\text{opp}}{\\text{hyp}} = \\displaystyle\\frac{x}{3}\n\n\nCode\n\\usetikzlibrary{graphs,graphs.standard,angles,quotes}\n\n\\begin{tikzpicture}\n\n\\draw[fill=black] (0,0);\n\\draw[fill=black] (3,0);\n\\draw[fill=black] (3,2);\n\\draw[line width=1pt] (0,0) -- (3,0) -- (3,2) -- (0,0);\n\\node at (1.75,-.3) {$\\sqrt{9 -x^2}$};\n\\node at (1.2,1.25) {$3$};\n\\node at (3.2,1) {$x$};\n\n\\coordinate (origo) at (0,0);\n\\coordinate (pivot) at (3,2);\n\\coordinate (mary) at (3,0);\n\n\\pic[draw, -, \"$\\theta$\", angle eccentricity=1.5]{angle = mary--origo--pivot};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nSo\n\n\\cot \\theta = \\frac{\\text{adj}}{\\text{opp}} = \\frac{\\sqrt{9 -x^2}}{x}\n\nGiving us a final answer of\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx = \\frac{-\\sqrt{9-x^2}}{x} - \\arcsin\\left(\\frac{x}{3}\\right) + C"
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#method",
    "href": "qmd/integral/simple/trigsub.html#method",
    "title": "Trig substitutions",
    "section": "Method",
    "text": "Method\nFirst, lets explain how we solved the previous integral.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWe have the following integral, which is difficult to solve using previous techniques.\n\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx\n\nUsing the substitution\n\nx = \\frac{2}{5}\\sec \\theta\n\nWe can reduce the integral and get a solution in terms of \\theta.\n\\begin{array}{ll}\n\n& = \\displaystyle \\int \\frac{\\sqrt{25(\\frac{2}{5}\\sec \\theta)^2 - 4}}{\\frac{2}{5}\\sec \\theta} \\, (\\frac{2}{5}\\tan \\theta \\sec \\theta \\, d\\theta)\\\\\n& =  \\displaystyle\\int \\sqrt{4\\sec^2 \\theta - 4} \\, \\tan \\theta \\, d\\theta\\\\\n& = \\displaystyle2\\int \\sqrt{\\sec^2 \\theta - 1} \\, \\tan \\theta \\, d\\theta = 2\\int\\tan^2\\theta \\, d\\theta\\\\\n& = 2\\left(\\tan \\theta + \\theta\\right) + C\n\\end{array}\nNow we only need to undo our substitution. Notice that\n\n\\sec \\theta = \\frac{\\text{hyp}}{\\text{adj}} = \\frac{5x}{2}\n\nThis can be visualized in the triangle.\n\n\nCode\n\\usetikzlibrary{graphs,graphs.standard,angles,quotes}\n\n\\begin{tikzpicture}\n\n\\draw[fill=black] (0,0);\n\\draw[fill=black] (3,0);\n\\draw[fill=black] (3,2);\n\\draw[line width=1pt] (0,0) -- (3,0) -- (3,2) -- (0,0);\n\\node at (1.75,-.25) {$2$};\n\\node at (1.2,1.25) {$5x$};\n\\node at (3.9,1) {$\\sqrt{25x^2 - 4}$};\n\n\\coordinate (origo) at (0,0);\n\\coordinate (pivot) at (3,2);\n\\coordinate (mary) at (3,0);\n\n\\pic[draw, -, \"$\\theta$\", angle eccentricity=1.5]{angle = mary--origo--pivot};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nFrom here can see that \n\\tan \\theta = \\frac{\\sqrt{25x^2-4}}{2}\n\n\n\\theta = \\arccos \\left(\\frac{2}{5x}\\right)\n\nGiving us our final answer\n\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx = \\sqrt{25x^2-4} + 2\\arccos \\left(\\frac{2}{5x}\\right) + C\n\n\n\n\nWhen faced with an integral containing a radical expression in the form \\sqrt{\\pm(bx + c)^2 \\pm a}, we can usually find some subtitution for x which simplifies the expression into a singular trigonometric identity. This is achievable due to the following three identities.\n\\begin{array}{ll}\n1 - \\sin^2x &=& \\cos^2 x\\\\\n\\tan^2x + 1 &=& \\sec^2 x\\\\\n\\sec^2x - 1 &=& \\tan^2 x\n\\end{array}\nLets see how these identites allow us to reduce certain radicals.\n\n\n\n\n\n\nTrig substitutions\n\n\n\n\n\nLets examine the three cases where trig identities allow us to simplify a radical expression.\nCase I: \\sqrt{a - (bx + c)^2}\nNotice how this case is a constant, subtracted by a squared variable term. This resembles our first expression, 1 - \\sin^2x = \\cos^2 x. We want to get the expression in these terms so we can reduce the radicle. Notice by making the substitution\n\n(bx + c) = \\sqrt{a}\\sin \\theta\n\nWe get the equation\n\n\\sqrt{a - (\\sqrt{a}\\sin\\theta)^2} = \\sqrt{a}\\sqrt{1-\\sin^2\\theta} = \\sqrt{a}\\cos\\theta\n\nWe have now elimated the variable from the radical.\nCase II: \\sqrt{(bx + c)^2 + a}\nThis case resembles our identity \\tan^2x + 1 = \\sec^2 x. So lets try the substitution\n\n(bx + c) = \\sqrt{a}\\tan \\theta\n\nWhich gives us\n\n\\sqrt{(\\sqrt{a}\\tan \\theta)^2 + a} = \\sqrt{a}\\sqrt{\\tan^2 \\theta + 1} = \\sqrt{a}\\sec\\theta\n\nWe have now elimated the variable from the radical.\nCase III: \\sqrt{(bx + c)^2 - a}\nThis case resembles \\sec^2x - 1. Using the substitution\n\n(bx + c) = \\sqrt{a}\\sec \\theta\n\nWe get the equation\n\n\\sqrt{(\\sqrt{a}\\sec \\theta)^2 - a} = \\sqrt{a}\\sqrt{\\sec^2\\theta - 1} = \\sqrt{a}\\tan\\theta\n\nWe have now elimated the variable from the radical.\n\n\n\nFor ease of use, the following table shows what substitution to make depending on the case.\n\\begin{array}{ll}\n\\text{Radical expression} \\hspace{0.25in} & \\text{Substitution}\\\\\n&\\\\\n\\sqrt{a - (bx + c)^2} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\sin\\theta\\\\\n&\\\\\n\\sqrt{(bx + c)^2 + a} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\tan\\theta\\\\\n&\\\\\n\\sqrt{(bx + c)^2 - a} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\sec\\theta\n\\end{array}"
  },
  {
    "objectID": "qmd/todo/todo.html",
    "href": "qmd/todo/todo.html",
    "title": "Todo",
    "section": "",
    "text": "Todo list for the website"
  },
  {
    "objectID": "qmd/todo/todo.html#discrete-derivative",
    "href": "qmd/todo/todo.html#discrete-derivative",
    "title": "Discrete Calculus",
    "section": "Discrete Derivative",
    "text": "Discrete Derivative\nIn continuous calculus, the derivative is the ‘instantaneous rate of change’ of a function. That concept can’t exist with incremental change. The smallest rate of change in a discrete function is the change between integers. Therefore we define our discrete derivative\n\n\n\n\n\n\nDefinition\n\n\n\nThe discrete derivative is the smallest change in a discrete function, defined $$ f(x) = f(x+1) - f(x)\n\n\nWe can now prove may properties about the discrete derivative\n\n\n\n\n\n\nTheorem\n\n\n\nThe discrete derivative has the following properties\nConstant rule\n\\Delta c = 0 for all c \\in \\mathbb{N}\nLinearity\n\\Delta af(x) = a \\Delta f(x)\nProduct rule\n\\Delta f(x)g(x) = f(x) \\Delta g(x) + g(x) \\Delta f(x) + \\Delta f(x) \\Delta g(x)\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nTo-do\n\n\n\n\nFunctions\nNow that we’ve defined the discrete derivative, we can start finding the discrete derivative of functions.\nTake for example, the function"
  },
  {
    "objectID": "qmd/todo/todo.html#website",
    "href": "qmd/todo/todo.html#website",
    "title": "Todo",
    "section": "Website",
    "text": "Website\n\nMakeover\nAdd about page, change math notes to one section\nCopy castles notes"
  },
  {
    "objectID": "qmd/todo/todo.html#integrals",
    "href": "qmd/todo/todo.html#integrals",
    "title": "Todo",
    "section": "Integrals",
    "text": "Integrals\n\nMake everything less plagarized\nmake the equations fit on mobile"
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html",
    "href": "qmd/bookrev/concrete/recprob.html",
    "title": "Recurrent Problems",
    "section": "",
    "text": "This chapter of ‘Concrete Mathematics’ explores recurrence problems."
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html#the-tower-of-hanoi",
    "href": "qmd/bookrev/concrete/recprob.html#the-tower-of-hanoi",
    "title": "Recurrent Problems",
    "section": "The Tower of Hanoi",
    "text": "The Tower of Hanoi\nThe Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nThe authors present the solution throught the use of two techniques. The authors first look at small cases of the problem, and then create a variable T_n to analyze.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in Equation 1 is called a recurrence. Defined as giving an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nThrough less than rigourous means, one can determine that the equation\n\nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will use a tool called Mathematical induction.\nThis works by first proving the equation true for one value of n, know as n_0 called the basis. Then proving it for all $ n &gt; n_0$. We assume the statement is true for all values n_0 to n - 1 inclusive.\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html#lines-in-the-plane",
    "href": "qmd/bookrev/concrete/recprob.html#lines-in-the-plane",
    "title": "Recurrent Problems",
    "section": "Lines in the Plane",
    "text": "Lines in the Plane\nOur next problem is on the plane. What is the maximum number L_n of regions defined by n lines on a plane. This problem was first solved by Jacob Steiner in 1826. If we take a similar approach to the last section, starting with smaller cases:\n\nL_0 = 1\\\\\nL_1 = 2\\\\\nL_2 = 4\n\nWe might come to the natural conclusion that L_n = 2^n. And this would be true if each line cut each region in half; but adding a third line makes it clear that we can only split as most 3 regions, giving us L_3 = 7. We realize that a new line on the plane adds k extra regions if and only if it intersects k old regions, and the line intersects k regions if and only if it hits the previous lines in k-1 places. Two lines can intersect in at most one point. So the new line can intersect the n - 1 lines at n-1 places. Thus the upper bound for this problem is\n\nL_n \\leq L_{n-1} + n \\quad \\text{for} n &gt; 0.\n\nFurthermore it’s easy to change this into equality by adding the restriction that none of the n lines are parrall, and that three lines do not intersect at the same point. This ensures that each new line n intersects every other line at some new point splitting the region. Our recurrence relation is then\n\nL_0 = 1;\\\\\nL_n = L_{n-1} + n,\\quad \\text{for } n &gt; 0.\n\\tag{4}\nOne can verify there are no silly mistakes by checking our established values of L_0,L_1 and L_2. All checks out, so we buy the recurrence relation. Now we need a general formula.\nThrough some trial and error, we can unfold L_n into\n\nL_n = L_0 + 1 + 2 + \\cdots + n\n\nLetting\n\nS_n = 1 + 2 + \\cdots + n\n\nWe get the ‘closed form’\n\nL_n = 1 + S_n\n\nBut this just replaces one recurrence for another. It is said that in 1786, when Guass was nine years old, he had found a closed form of S_n using the following trick\n\\begin{array}{ll}\n&S_n &=  &1  &+ &2 &+ \\cdots + &(n - 1) &+ &n\\\\\n+&S_n &=  &n  &+ &(n-1) &+ \\cdots + &2 &+ &1\\\\\n\\hline\n2&S_n &= &(n+1) &+ &(n+1) &+ \\cdots + &(n+1) &+ &(n+1)\n\\end{array}\\\\\nNotice how 2S_n is now just equal to n copies of (n + 1), therefore\n\nS_n = \\frac{n(n+1)}{2}, \\quad \\text{for } n \\geq 0\n\\tag{5}\nGiving us our closed form\n\nL_n = \\frac{n(n+1)}{2} + 1, \\quad \\text{for } n \\geq 0.\n\\tag{6}\nOne might consider this a proof, despite the handwavy techniques used in its derivation. A proof by induction is simple, so we might as well give ourselves some stricter standards. The induction is proved with\n\nL_n = \\frac{(n-1)n}{2} + 1 + n = \\frac{n(n+1)}{2} + 1\n\nThus we have no doubt (6) is correct.\nWe can now look at a vairation of the line problem. Suppose instead of straight lines each line has a zig in it. What is the maximum number Z_n of regions determined by n. One can see Z_1 = 2 and Z_2 = 7.\nFrom some thought and small cases, one notices that a line with a zig is simply two lines who don’t extend past their intersection point. We can arrange these zigged lines such that the intersection point is far enough from the other lines that we only lose two regions per line. Thus\n\nZ_n = L_2n - 2n = 2n(2n - 1)/2 + 1 - 2n\\\\\nZ_n = 2n^2 - n + 1 \\quad \\text{for } n \\geq 0.\n\\tag{7}"
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html#the-josephus-problem",
    "href": "qmd/bookrev/concrete/recprob.html#the-josephus-problem",
    "title": "Recurrent Problems",
    "section": "The Josephus Problem",
    "text": "The Josephus Problem\nThe Josephus problem is actually an ancient problem dating back to the first century. The problem has n people standing in a circle. Each person kills the person directly to their left, until there is only one left. We want to find the position of the surviving player.\nWe can easily see J(1) = 1. When there is an even number 2n of players, note that all the even numbers die the first round. Our circle would then resemble a circle of size n, where each players number has been doubled and then had 1 subtracted from it. That is\n\nJ(2n) = 2J(n) - 1\n\nNow if we do a similar thing with an odd number of survivors, we see\n\nJ(2n + 1) = 2J(n) + 1\n\nThis can be used to define a recurrence relation\n\nJ(1) = 1\\\\\nJ(2n) = 2J(n) - 1\\\\\nJ(2n + 1) = 2J(n) + 1\n\\tag{8}\nThis recurrence is much more effienct than our previous ones. As if we wanted to calculate a large n, we would need far fewer than n steps to get our solution (Around \\log_2n steps).\nThrough some trial and error, we can arrive at the following equation\n\nJ(2^m + l) = 2l + 1\n\\tag{9}\nWhich can be solved by induction.\n\nBinary Representation\nBecause powers of 2 played such an important role in finding our solution, one might want to look at n in it’s base 2 reprensentation. Suppose\n\nn = (b_mb_{m-1}\\ldots b_1b_0)_2\n\nNote that b_m is always 1. Letting n = 2^m + l, we have\n\nn = (1b_{m-1}\\ldots b_1b_0)_2\\\\\nl = (0b_{m-1}\\ldots b_1b_0)_2\\\\\n2l = (b_{m-1}\\ldots b_1b_00)_2\\\\\n2l + 1 = (b_{m-1}\\ldots b_1b_01)_2\\\\\nJ(n) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\nThus\n\nJ((1b_{m-1}\\ldots b_1b_0)_2) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\\tag{10}\nThis means we can find J(n) by doing a one-bit cyclic shift left on n. Which is insanely simple given the amount of work it was to find a solution in base 10! For example, if n = 1101_2 then J(n) = 1011_2. Note this breaks when J(1011_2) = 111_2\nIf we repeatedly apply J to a number n, we will eventually produce a number consisting of bits which are exclusivly 1, whos value is 2^{v(n)} - 1 where v(n) is the number of bits of value 1 in the binary representation of n. Because v(13) = 3,\n\nJ(J(\\cdots J(13)\\cdots)) = 2^3 - 1 = 7.\n\nHow many iterations of J does it take to get this fixed value? No idea.\n\n\nGenerilized Josephus Problem\nWhat would happen if we generilized (8) with different constants? How would that change our closed form solutions. Lets investiagte this with a more general recurrence\n\\begin{array}{ll}\nf(1) &=& \\alpha;\\\\\nf(2n) &=& 2f(n) + \\beta;\\\\\nf(2n + 1) &=& 2f(n) + \\gamma;\n\\end{array}\n\n\\tag{11}\nOur recurrence J(n) had constants \\alpha = 1, \\beta = -1 and \\gamma = 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html",
    "href": "qmd/bookrev/towerhanoi.html",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\n\n\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#the-tower-of-hanoi",
    "href": "qmd/bookrev/towerhanoi.html#the-tower-of-hanoi",
    "title": "Recurrent Problems",
    "section": "The Tower of Hanoi",
    "text": "The Tower of Hanoi\nThe Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nThe authors present the solution throught the use of two techniques. The authors first look at small cases of the problem, and then create a variable T_n to analyze.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in Equation 1 is called a recurrence. Defined as giving an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nThrough less than rigourous means, one can determine that the equation\n\nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will use a tool called Mathematical induction.\nThis works by first proving the equation true for one value of n, know as n_0 called the basis. Then proving it for all $ n &gt; n_0$. We assume the statement is true for all values n_0 to n - 1 inclusive.\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#lines-in-the-plane",
    "href": "qmd/bookrev/towerhanoi.html#lines-in-the-plane",
    "title": "The Tower of Hanoi",
    "section": "Lines in the Plane",
    "text": "Lines in the Plane\nOur next problem is on the plane. What is the maximum number L_n of regions defined by n lines on a plane. This problem was first solved by Jacob Steiner in 1826. If we take a similar approach to the last section, starting with smaller cases:\n\nL_0 = 1\\\\\nL_1 = 2\\\\\nL_2 = 4\n\nWe might come to the natural conclusion that L_n = 2^n. And this would be true if each line cut each region in half; but adding a third line makes it clear that we can only split as most 3 regions, giving us L_3 = 7. We realize that a new line on the plane adds k extra regions if and only if it intersects k old regions, and the line intersects k regions if and only if it hits the previous lines in k-1 places. Two lines can intersect in at most one point. So the new line can intersect the n - 1 lines at n-1 places. Thus the upper bound for this problem is\n\nL_n \\leq L_{n-1} + n \\quad \\text{for} n &gt; 0.\n\nFurthermore it’s easy to change this into equality by adding the restriction that none of the n lines are parrall, and that three lines do not intersect at the same point. This ensures that each new line n intersects every other line at some new point splitting the region. Our recurrence relation is then\n\nL_0 = 1;\\\\\nL_n = L_{n-1} + n,\\quad \\text{for } n &gt; 0.\n\\tag{4}\nOne can verify there are no silly mistakes by checking our established values of L_0,L_1 and L_2. All checks out, so we buy the recurrence relation. Now we need a general formula.\nThrough some trial and error, we can unfold L_n into\n\nL_n = L_0 + 1 + 2 + \\cdots + n\n\nLetting\n\nS_n = 1 + 2 + \\cdots + n\n\nWe get the ‘closed form’\n\nL_n = 1 + S_n\n\nBut this just replaces one recurrence for another. It is said that in 1786, when Guass was nine years old, he had found a closed form of S_n using the following trick\n\\begin{array}{ll}\n&S_n &=  &1  &+ &2 &+ \\cdots + &(n - 1) &+ &n\\\\\n+&S_n &=  &n  &+ &(n-1) &+ \\cdots + &2 &+ &1\\\\\n\\hline\n2&S_n &= &(n+1) &+ &(n+1) &+ \\cdots + &(n+1) &+ &(n+1)\n\\end{array}\\\\\nNotice how 2S_n is now just equal to n copies of (n + 1), therefore\n\nS_n = \\frac{n(n+1)}{2}, \\quad \\text{for } n \\geq 0\n\\tag{5}\nGiving us our closed form\n\nL_n = \\frac{n(n+1)}{2} + 1, \\quad \\text{for } n \\geq 0.\n\\tag{6}\nOne might consider this a proof, despite the handwavy techniques used in its derivation. A proof by induction is simple, so we might as well give ourselves some stricter standards. The induction is proved with\n\nL_n = \\frac{(n-1)n}{2} + 1 + n = \\frac{n(n+1)}{2} + 1\n\nThus we have no doubt (6) is correct.\nWe can now look at a vairation of the line problem. Suppose instead of straight lines each line has a zig in it. What is the maximum number Z_n of regions determined by n. One can see Z_1 = 2 and Z_2 = 7.\nFrom some thought and small cases, one notices that a line with a zig is simply two lines who don’t extend past their intersection point. We can arrange these zigged lines such that the intersection point is far enough from the other lines that we only lose two regions per line. Thus\n\nZ_n = L_2n - 2n = 2n(2n - 1)/2 + 1 - 2n\\\\\nZ_n = 2n^2 - n + 1 \\quad \\text{for } n \\geq 0.\n\\tag{7}"
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#the-josephus-problem",
    "href": "qmd/bookrev/towerhanoi.html#the-josephus-problem",
    "title": "The Tower of Hanoi",
    "section": "The Josephus Problem",
    "text": "The Josephus Problem\nThe Josephus problem is actually an ancient problem dating back to the first century. The problem has n people standing in a circle. Each person kills the person directly to their left, until there is only one left. We want to find the position of the surviving player.\nWe can easily see J(1) = 1. When there is an even number 2n of players, note that all the even numbers die the first round. Our circle would then resemble a circle of size n, where each players number has been doubled and then had 1 subtracted from it. That is\n\nJ(2n) = 2J(n) - 1\n\nNow if we do a similar thing with an odd number of survivors, we see\n\nJ(2n + 1) = 2J(n) + 1\n\nThis can be used to define a recurrence relation\n\nJ(1) = 1\\\\\nJ(2n) = 2J(n) - 1\\\\\nJ(2n + 1) = 2J(n) + 1\n\\tag{8}\nThis recurrence is much more effienct than our previous ones. As if we wanted to calculate a large n, we would need far fewer than n steps to get our solution (Around \\log_2n steps).\nThrough some trial and error, we can arrive at the following equation\n\nJ(2^m + l) = 2l + 1\n\\tag{9}\nWhich can be solved by induction.\n\nBinary Representation\nBecause powers of 2 played such an important role in finding our solution, one might want to look at n in it’s base 2 reprensentation. Suppose\n\nn = (b_mb_{m-1}\\ldots b_1b_0)_2\n\nNote that b_m is always 1. Letting n = 2^m + l, we have\n\nn = (1b_{m-1}\\ldots b_1b_0)_2\\\\\nl = (0b_{m-1}\\ldots b_1b_0)_2\\\\\n2l = (b_{m-1}\\ldots b_1b_00)_2\\\\\n2l + 1 = (b_{m-1}\\ldots b_1b_01)_2\\\\\nJ(n) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\nThus\n\nJ((1b_{m-1}\\ldots b_1b_0)_2) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\\tag{10}\nThis means we can find J(n) by doing a one-bit cyclic shift left on n. Which is insanely simple given the amount of work it was to find a solution in base 10! For example, if n = 1101_2 then J(n) = 1011_2. Note this breaks when J(1011_2) = 111_2\nIf we repeatedly apply J to a number n, we will eventually produce a number consisting of bits which are exclusivly 1, whos value is 2^{v(n)} - 1 where v(n) is the number of bits of value 1 in the binary representation of n. Because v(13) = 3,\n\nJ(J(\\cdots J(13)\\cdots)) = 2^3 - 1 = 7.\n\nHow many iterations of J does it take to get this fixed value? No idea.\n\n\nGenerilized Josephus Problem\nWhat would happen if we generilized (8) with different constants? How would that change our closed form solutions. Lets investiagte this with a more general recurrence\n\\begin{array}{ll}\nf(1) &=& \\alpha;\\\\\nf(2n) &=& 2f(n) + \\beta;\\\\\nf(2n + 1) &=& 2f(n) + \\gamma;\n\\end{array}\n\n\\tag{11}\nOur recurrence J(n) had constants \\alpha = 1, \\beta = -1 and \\gamma = 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#the-problem",
    "href": "qmd/bookrev/towerhanoi.html#the-problem",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\n\n\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html",
    "href": "qmd/concrete/recurrent/towerhanoi.html",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nAnd thus T_n = 2^n - 1 for all n.\n\n\nSo we get\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#the-problem",
    "href": "qmd/concrete/recurrent/towerhanoi.html#the-problem",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nAnd thus T_n = 2^n - 1 for all n.\n\n\nSo we get\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#linear-problem",
    "href": "qmd/concrete/recurrent/towerhanoi.html#linear-problem",
    "title": "The Tower of Hanoi",
    "section": "Linear Problem",
    "text": "Linear Problem\nNow that we have an understanding for the general problem, we can begin making some alterations. In the linear problem, we label the pegs A,B and C. A disk can only be moved from peg A to peg B, and peg B to peg C.\nWe are tasked with finding the shortest number of moves to get a tower of size n from peg A to peg C. Let this minimum be given by L(n).\nThe only way to move the bottom disk n is to have the entire tower of n-1 disks on peg C. Then we can move disk n onto peg B. The only way to move the disk forward again is if the n-1 tower is on peg A now. We can now move disk n to peg C, and the tower back onto peg C. This gives us the following recurrence\n\nL(0) = 0\\\\\nL(n) = 3L(n-1) + 2\n\nUsing our previous simplification trick, let U(n) = L(n) + 1.\n\nU(n) = L(n) + 1 = 3L(n-1) + 3 = 3(L(n-1) + 1) = 3U(n-1)\\\\\n\nThus we get the closed formula\n\nL(n) = 3^n - 1"
  },
  {
    "objectID": "qmd/concrete/intro.html",
    "href": "qmd/concrete/intro.html",
    "title": "Concrete Mathematics",
    "section": "",
    "text": "Concrete mathematics is basically just discrete mathematics with a cooler name. These are my notes on the book.\n\nTable of Contents\n1 - Recurrent Problems\n  1.1 - The Tower of Hanoi\n  1.2 - Lines in the Plane\n  1.3 - The Josephus Problem\n2 - Structure and Representation\n3 - Matching\n4 - Subgraphs\n5 - Trees\n6 - Connectivity\n7 - Planarity\n8 - Coloring\n9 - Flows\n10 - Hamilton Cycles"
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html",
    "href": "qmd/concrete/recurrent/recprob.html",
    "title": "Recurrent Problems",
    "section": "",
    "text": "This chapter of ‘Concrete Mathematics’ explores recurrence problems."
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html#the-tower-of-hanoi",
    "href": "qmd/concrete/recurrent/recprob.html#the-tower-of-hanoi",
    "title": "Recurrent Problems",
    "section": "The Tower of Hanoi",
    "text": "The Tower of Hanoi\nThe Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nThe authors present the solution throught the use of two techniques. The authors first look at small cases of the problem, and then create a variable T_n to analyze.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in Equation 1 is called a recurrence. Defined as giving an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nThrough less than rigourous means, one can determine that the equation\n\nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will use a tool called Mathematical induction.\nThis works by first proving the equation true for one value of n, know as n_0 called the basis. Then proving it for all $ n &gt; n_0$. We assume the statement is true for all values n_0 to n - 1 inclusive.\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html#lines-in-the-plane",
    "href": "qmd/concrete/recurrent/recprob.html#lines-in-the-plane",
    "title": "Recurrent Problems",
    "section": "Lines in the Plane",
    "text": "Lines in the Plane\nOur next problem is on the plane. What is the maximum number L_n of regions defined by n lines on a plane. This problem was first solved by Jacob Steiner in 1826. If we take a similar approach to the last section, starting with smaller cases:\n\nL_0 = 1\\\\\nL_1 = 2\\\\\nL_2 = 4\n\nWe might come to the natural conclusion that L_n = 2^n. And this would be true if each line cut each region in half; but adding a third line makes it clear that we can only split as most 3 regions, giving us L_3 = 7. We realize that a new line on the plane adds k extra regions if and only if it intersects k old regions, and the line intersects k regions if and only if it hits the previous lines in k-1 places. Two lines can intersect in at most one point. So the new line can intersect the n - 1 lines at n-1 places. Thus the upper bound for this problem is\n\nL_n \\leq L_{n-1} + n \\quad \\text{for} n &gt; 0.\n\nFurthermore it’s easy to change this into equality by adding the restriction that none of the n lines are parrall, and that three lines do not intersect at the same point. This ensures that each new line n intersects every other line at some new point splitting the region. Our recurrence relation is then\n\nL_0 = 1;\\\\\nL_n = L_{n-1} + n,\\quad \\text{for } n &gt; 0.\n\\tag{4}\nOne can verify there are no silly mistakes by checking our established values of L_0,L_1 and L_2. All checks out, so we buy the recurrence relation. Now we need a general formula.\nThrough some trial and error, we can unfold L_n into\n\nL_n = L_0 + 1 + 2 + \\cdots + n\n\nLetting\n\nS_n = 1 + 2 + \\cdots + n\n\nWe get the ‘closed form’\n\nL_n = 1 + S_n\n\nBut this just replaces one recurrence for another. It is said that in 1786, when Guass was nine years old, he had found a closed form of S_n using the following trick\n\\begin{array}{ll}\n&S_n &=  &1  &+ &2 &+ \\cdots + &(n - 1) &+ &n\\\\\n+&S_n &=  &n  &+ &(n-1) &+ \\cdots + &2 &+ &1\\\\\n\\hline\n2&S_n &= &(n+1) &+ &(n+1) &+ \\cdots + &(n+1) &+ &(n+1)\n\\end{array}\\\\\nNotice how 2S_n is now just equal to n copies of (n + 1), therefore\n\nS_n = \\frac{n(n+1)}{2}, \\quad \\text{for } n \\geq 0\n\\tag{5}\nGiving us our closed form\n\nL_n = \\frac{n(n+1)}{2} + 1, \\quad \\text{for } n \\geq 0.\n\\tag{6}\nOne might consider this a proof, despite the handwavy techniques used in its derivation. A proof by induction is simple, so we might as well give ourselves some stricter standards. The induction is proved with\n\nL_n = \\frac{(n-1)n}{2} + 1 + n = \\frac{n(n+1)}{2} + 1\n\nThus we have no doubt (6) is correct.\nWe can now look at a vairation of the line problem. Suppose instead of straight lines each line has a zig in it. What is the maximum number Z_n of regions determined by n. One can see Z_1 = 2 and Z_2 = 7.\nFrom some thought and small cases, one notices that a line with a zig is simply two lines who don’t extend past their intersection point. We can arrange these zigged lines such that the intersection point is far enough from the other lines that we only lose two regions per line. Thus\n\nZ_n = L_2n - 2n = 2n(2n - 1)/2 + 1 - 2n\\\\\nZ_n = 2n^2 - n + 1 \\quad \\text{for } n \\geq 0.\n\\tag{7}"
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html#the-josephus-problem",
    "href": "qmd/concrete/recurrent/recprob.html#the-josephus-problem",
    "title": "Recurrent Problems",
    "section": "The Josephus Problem",
    "text": "The Josephus Problem\nThe Josephus problem is actually an ancient problem dating back to the first century. The problem has n people standing in a circle. Each person kills the person directly to their left, until there is only one left. We want to find the position of the surviving player.\nWe can easily see J(1) = 1. When there is an even number 2n of players, note that all the even numbers die the first round. Our circle would then resemble a circle of size n, where each players number has been doubled and then had 1 subtracted from it. That is\n\nJ(2n) = 2J(n) - 1\n\nNow if we do a similar thing with an odd number of survivors, we see\n\nJ(2n + 1) = 2J(n) + 1\n\nThis can be used to define a recurrence relation\n\nJ(1) = 1\\\\\nJ(2n) = 2J(n) - 1\\\\\nJ(2n + 1) = 2J(n) + 1\n\\tag{8}\nThis recurrence is much more effienct than our previous ones. As if we wanted to calculate a large n, we would need far fewer than n steps to get our solution (Around \\log_2n steps).\nThrough some trial and error, we can arrive at the following equation\n\nJ(2^m + l) = 2l + 1\n\\tag{9}\nWhich can be solved by induction.\n\nBinary Representation\nBecause powers of 2 played such an important role in finding our solution, one might want to look at n in it’s base 2 reprensentation. Suppose\n\nn = (b_mb_{m-1}\\ldots b_1b_0)_2\n\nNote that b_m is always 1. Letting n = 2^m + l, we have\n\nn = (1b_{m-1}\\ldots b_1b_0)_2\\\\\nl = (0b_{m-1}\\ldots b_1b_0)_2\\\\\n2l = (b_{m-1}\\ldots b_1b_00)_2\\\\\n2l + 1 = (b_{m-1}\\ldots b_1b_01)_2\\\\\nJ(n) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\nThus\n\nJ((1b_{m-1}\\ldots b_1b_0)_2) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\\tag{10}\nThis means we can find J(n) by doing a one-bit cyclic shift left on n. Which is insanely simple given the amount of work it was to find a solution in base 10! For example, if n = 1101_2 then J(n) = 1011_2. Note this breaks when J(1011_2) = 111_2\nIf we repeatedly apply J to a number n, we will eventually produce a number consisting of bits which are exclusivly 1, whos value is 2^{v(n)} - 1 where v(n) is the number of bits of value 1 in the binary representation of n. Because v(13) = 3,\n\nJ(J(\\cdots J(13)\\cdots)) = 2^3 - 1 = 7.\n\nHow many iterations of J does it take to get this fixed value? No idea.\n\n\nGenerilized Josephus Problem\nWhat would happen if we generilized (8) with different constants? How would that change our closed form solutions. Lets investiagte this with a more general recurrence\n\\begin{array}{ll}\nf(1) &=& \\alpha;\\\\\nf(2n) &=& 2f(n) + \\beta;\\\\\nf(2n + 1) &=& 2f(n) + \\gamma;\n\\end{array}\n\n\\tag{11}\nOur recurrence J(n) had constants \\alpha = 1, \\beta = -1 and \\gamma = 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#cyclic-problem",
    "href": "qmd/concrete/recurrent/towerhanoi.html#cyclic-problem",
    "title": "The Tower of Hanoi",
    "section": "Cyclic Problem",
    "text": "Cyclic Problem\nImagine that you could only make clockwise moves. That is, A to B, B to C, and C to A. We let Q(n) be the minimum number of moves to get a tower of size n from peg A to peg B, and R(n) to reverse Q(n), that is get a tower from peg B to A.\nFor this problem, we will define Q and R in terms of each other, and solve the recurrence in a later chapter. Starting with Q(n), one can notice by moving the top n-1 disks back, the largest disk forward, and then the top n-1 disks back, we get\n\nQ(0) = 0\\\\\nQ(n) = 2R(n-1) + 1\n\nSimilary for R(n), we can move the top n-1 back a peg, the bottom disk forward a peg, the top n-1 back to their starting peg, move the bottom peg once more, and then move the top n-1 back. This gets us\n\nR(n) = R(n-1) + 1 + Q(n-1) + 1 + R(n-1)\\\\\nR(n) = 2R(n-1) + Q(n-1) + 2\\\\\nR(n) = Q(n) + Q(n-1) + 1"
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#multiple-disks",
    "href": "qmd/concrete/recurrent/towerhanoi.html#multiple-disks",
    "title": "The Tower of Hanoi",
    "section": "Multiple disks",
    "text": "Multiple disks\nWhat if we have a tower of 2n disks of n sizes. That is we have two disks of each size, which are indistinguishable. After a little tinkering it’s clear that it is never beneficial to split the disks up, therefore the optimal solution is just doubling our initial solution. Letting D(n) be the optimal number of moves to move a stack,\n\nD(n) = 2T(n).\n\nThis problem becomes interesting if we let the two disks be distinguishable, and we wish to create the original tower. Let the minimum number of moves for this tower be DD(n). One may think this could be easily by moving the top n-1 towers in this fashion, move the bottom two disks, move n-1 back, move the bottom two, and then the top n-1 back on top. This gives us\n\nDD(n) = 3DD(n-1) + 4\n\nUnfortunetly induction immeditly fails, as DD(1) is 3. Notice that if we move all the disks of any size k an even number of times, they’ll be oriented right. We can minimize DD(n) by moving the bottom disks 3 times into the right orientation, and all the others an even number of times. Try it out, and notice how we get the following\n\nDD(n) = 4D(n-1) + 3\n\nThis works with induction, and can be simplified to give us\n\\begin{array}{ll}\nDD(n) &= 4D(n-1) + 3 = 8T(n-1) + 3 = 8(2^{n-1} - 1) + 3\\\\\n&=  2^{n+2} - 5 = 2^n - 1\n\\end{array}"
  },
  {
    "objectID": "qmd/logic/formalsystem.html",
    "href": "qmd/logic/formalsystem.html",
    "title": "Formal Systems",
    "section": "",
    "text": "A formal system consists of a formal language, with strict rules on what symbols are allowed and how to connect them, combined with a deductive system, containing axioms and rules for deducing true statements.\nOf course, without knowledge of what a language or deductive system is, this definition is useless."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#formal-languages",
    "href": "qmd/logic/formalsystem.html#formal-languages",
    "title": "Formal Systems",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the disctintion is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#deduction-apparatus",
    "href": "qmd/logic/formalsystem.html#deduction-apparatus",
    "title": "Formal Systems",
    "section": "Deduction apparatus",
    "text": "Deduction apparatus"
  },
  {
    "objectID": "qmd/logic/formalsystem.html#deductive-apparatus",
    "href": "qmd/logic/formalsystem.html#deductive-apparatus",
    "title": "Formal Systems",
    "section": "Deductive apparatus",
    "text": "Deductive apparatus\nA deductive apparatus is a set of axioms and rules of inference which are used to deduce one true statement from another. The standard deductive apparatus is shown below. I don’t quite understand these so i’ll mostly brush over them.\n\n\n\n\n\n\nStandard deductive apparatus\n\n\n\nThe axioms and inferences listed are the standard for first-order logic.\nLogical Axioms\n\nAll tautologies\nUniversal specification\n\\forall x (P \\implies Q) \\implies (\\forall x P \\implies \\forall x Q)\nP \\implies \\forall x P\nDefinition of \\exists\nx = x\nSubstitution of equals\n\nRules of inference\nRules of inference are used to deduce a true statement from a previous. There is typically only one rule of inference.\n\nModus ponens"
  },
  {
    "objectID": "qmd/logic/theorem.html",
    "href": "qmd/logic/theorem.html",
    "title": "Formal Theories",
    "section": "",
    "text": "A theory is a set of formulas T in a formal language. We can take these theories as axioms, and combine them with a formal system belonging to first-order logic to create a first-order theory.\nWe’re long overdue for an example, so lets examine the two most popular first-order theories, Zermelo-Fraenkel set theory, and Peano arithmetic."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#deductive-systems",
    "href": "qmd/logic/formalsystem.html#deductive-systems",
    "title": "Formal Systems",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example1\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#footnotes",
    "href": "qmd/logic/formalsystem.html#footnotes",
    "title": "Formal Systems",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis section is copied from Wikipedia almost verbatim.↩︎"
  },
  {
    "objectID": "qmd/logic/formalsystem.html#formal-systems",
    "href": "qmd/logic/formalsystem.html#formal-systems",
    "title": "Formal Systems",
    "section": "Formal systems",
    "text": "Formal systems\nThe first formal system we"
  },
  {
    "objectID": "qmd/logic/formalsystem.html#first-order-logic",
    "href": "qmd/logic/formalsystem.html#first-order-logic",
    "title": "Formal Systems",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part."
  },
  {
    "objectID": "qmd/logic/theorem.html#example",
    "href": "qmd/logic/theorem.html#example",
    "title": "Formal Theories",
    "section": "Example",
    "text": "Example\nBelow is an example of a formal proof done in PA. Note the immense amount of pain that went into crafting it.\n\n\n\n\n\n\nLemma (Conjunction introduction)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash A          &\\quad &\\textbf{}\\\\\n&\\vdash B          &\\quad &\\textbf{}\\\\\n&\\vdash A \\land B          &\\quad &\\textbf{Conjunction introduction}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nLemma (Symmetry of equality)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash \\forall x \\forall y (x = y \\rightarrow y = x)          &\\quad &\\textbf{Symmetry of equality}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nLemma (Transitivity of equality)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash \\forall x \\forall y \\forall z (x = y \\rightarrow (y = z \\rightarrow x = z))          &\\quad &\\textbf{Transitivity of equality}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nLemma (Conjunction introduction)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash A          &\\quad &\\textbf{}\\\\\n&\\vdash B          &\\quad &\\textbf{}\\\\\n&\\vdash A \\land B          &\\quad &\\textbf{Conjunction introduction}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nTheorem (Commutative property of addition)\n\n\n\nPA \\vdash \\forall x \\forall y\\,(x + y = y + x)\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe’ll prove the theorem through induction on x. By axiom A7 we want to show\n(1)\\quad PA \\vdash \\forall y\\,(\\overline{0} + y = y + \\overline{0})\n(2)\\quad PA \\vdash \\forall y\\,(x + y = y + x) \\rightarrow \\forall y\\,(S(x) + y = y + S(x))\nWe start by proving (1). We’ll first prove the statement\nPA \\vdash \\forall y\\,(\\overline{0} + y = y).\nBy axiom A7 we want to show\n(1.1) \\quad PA \\vdash (\\overline{0} + \\overline{0} = \\overline{0})\n(1.2) \\quad PA \\vdash (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))\nWe can prove (1.1)\n\\begin{alignat*}{2}\nPA &\\vdash \\forall x(x + \\overline{0} = x)          &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x) \\rightarrow (\\overline{0} + \\overline{0} = \\overline{0})          &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash (\\overline{0} + \\overline{0} = \\overline{0})          &\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nTo prove (1.2), let \\phi be the formula (\\overline{0} + y = y)\n\\begin{alignat*}{2}\nPA \\cup \\phi &\\vdash (\\overline{0} + y = y)          &\\quad &\\text{}\\\\\nPA \\cup \\phi &\\vdash \\forall x \\forall y (x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\phi &\\vdash \\forall x \\forall y (x + S(y) = S(x + y)) \\rightarrow \\overline{0} + S(y) = S(\\overline{0} + y)         &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\phi &\\vdash \\overline{0} + S(y) = S(\\overline{0} + y)         &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\phi &\\vdash \\overline{0} + y = y \\rightarrow S(\\overline{0} + y) = S(y)          &\\quad &\\textbf{I9}\\\\\nPA \\cup \\phi &\\vdash S(\\overline{0} + y) = S(y)          &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\phi &\\vdash \\overline{0} + S(y) = S(y)          &\\quad &\\textbf{Transitivity of equality}\\\\\nPA &\\vdash (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))&\\quad &\\textbf{Deductive theorem}\\\\\n\\end{alignat*}\nLet \\phi_{1.1} be (\\overline{0} + \\overline{0} = \\overline{0}) and \\phi_{1.2} be (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))\n\\begin{alignat*}{2}\nPA &\\vdash (\\overline{0} + \\overline{0} = \\overline{0})          &\\quad &\\textbf{1.1}\\\\\nPA &\\vdash (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))          &\\quad &\\textbf{1.2}\\\\\nPA &\\vdash \\phi_{1.1} \\land \\phi_{1.2}          &\\quad &\\textbf{Conjunction introduction}\\\\\nPA &\\vdash (\\phi_{1.1} \\land \\phi_{1.2}) \\rightarrow \\forall y (\\overline{0} + y = y)&\\quad &\\textbf{A7}\\\\\nPA &\\vdash \\forall y (\\overline{0} + y = y)&\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nNow we prove the equivalence to (1).\n\\begin{alignat*}{2}\nPA &\\vdash \\forall x (x + \\overline{0} = x)    &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x (x + \\overline{0} = x) \\rightarrow y + \\overline{0} = y   &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash y + \\overline{0} = y   &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash y = y + \\overline{0}   &\\quad &\\textbf{Symmetry of equality}\\\\\nPA &\\vdash \\forall y (\\overline{0} + y = y) \\rightarrow \\overline{0} + y = y &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash \\overline{0} + y = y   &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash \\overline{0} + y = y + \\overline{0}   &\\quad &\\textbf{Transitivity of equality}\\\\\nPA &\\vdash \\overline{0} + y = y + \\overline{0} \\rightarrow \\forall y \\, (\\overline{0} + y = y + \\overline{0})   &\\quad &\\textbf{Q7}\\\\\nPA &\\vdash \\forall y\\,(\\overline{0} + y = y + \\overline{0})   &\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nNow we can prove (2). We’ll start by proving a prerequisite\nPA \\vdash \\forall y \\,(S(x) + y = S(x + y))\nBy A7 we want to show\n(2.1) \\quad PA \\vdash S(x) + \\overline{0} = S(x + \\overline{0})\n(2.2) \\quad PA \\vdash S(x) + y = S(x + y) \\rightarrow S(x) + S(y) = S(x + S(y))\nWe can first prove (2.1)\n\\begin{alignat*}{2}\nPA &\\vdash \\forall x(x + \\overline{0} = x)          &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x) \\rightarrow S(x) + \\overline{0} = S(x)        &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash S(x) + \\overline{0} = S(x)        &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x)          &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x) \\rightarrow x + \\overline{0} = x        &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash x + \\overline{0} = x        &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash x + \\overline{0} = x \\rightarrow S(x + \\overline{0}) = S(x)      &\\quad &\\textbf{I9}\\\\\nPA &\\vdash S(x + \\overline{0}) = S(x)        &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash S(x) = S(x + \\overline{0})        &\\quad &\\textbf{Symmetry of equality}\\\\\nPA &\\vdash S(x) + \\overline{0} = S(x + \\overline{0})        &\\quad &\\textbf{Transitivity of equality}\\\\\n\\end{alignat*}\nThen (2.2). Let \\psi be the formula (S(x) + y = S(x + y))\n\\begin{alignat*}{2}\nPA \\cup \\psi &\\vdash S(x) + y = S(x + y)          &\\quad &\\text{}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y)) \\rightarrow   S(x) + S(y) = S(S(x) + y)    &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\psi &\\vdash S(x) + S(y) = S(S(x) + y)    &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y)) \\rightarrow   x + S(y) = S(x + y)    &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\psi &\\vdash x + S(y) = S(x + y)    &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\psi &\\vdash S(x + y) = x + S(y)    &\\quad &\\textbf{Symmetry of equality}\\\\\nPA \\cup \\psi &\\vdash S(x) + y = x + S(y)     &\\quad &\\textbf{Transitivity of equality}\\\\\nPA \\cup \\psi &\\vdash S(x) + y = x + S(y) \\rightarrow S(S(x) + y) = S(x + S(y))     &\\quad &\\textbf{I9}\\\\\nPA \\cup \\psi &\\vdash S(S(x) + y) = S(x + S(y))     &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\psi &\\vdash S(x) + S(y) = S(x + S(y))     &\\quad &\\textbf{Transitivity of equality}\\\\\nPA &\\vdash S(x) + y = S(x + y) \\rightarrow S(x) + S(y) = S(x + S(y))     &\\quad &\\textbf{Deductive theorem}\\\\\n\\end{alignat*}\nLet (2.1) and (2.2) be \\psi_{2.1} and \\psi_{2.2} respectively.\n\\begin{alignat*}{2}\nPA &\\vdash S(x) + \\overline{0} = S(x + \\overline{0})        &\\quad &\\textbf{2.1}\\\\\nPA &\\vdash S(x) + y = S(x + y) \\rightarrow S(x) + S(y) = S(x + S(y))     &\\quad &\\textbf{2.2}\\\\\nPA &\\vdash   \\psi_{2.1} \\land \\psi_{2.2}      &\\quad &\\textbf{Conjunction introduction}\\\\\nPA &\\vdash (\\psi_{2.1} \\land \\phi_{2.2}) \\rightarrow \\forall y (S(x) + y = S(x + y))&\\quad &\\textbf{A7}\\\\\nPA &\\vdash \\forall y (S(x) + y = S(x + y))&\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nLet this formula be denoted \\pi\nNow we can prove (2). Let \\zeta be the formula \\forall y(x + y = y + x)\n\\begin{alignat*}{2}\nPA \\cup \\zeta &\\vdash \\forall y(x + y = y + x)          &\\quad &\\text{}\\\\\nPA \\cup \\zeta &\\vdash \\forall y (S(x) + y = S(x + y))         &\\quad &\\pmb\\pi\\\\\nPA \\cup \\zeta &\\vdash \\forall y (S(x) + y = S(x + y)) \\rightarrow S(x) + y = S(x + y)         &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\zeta &\\vdash  S(x) + y = S(x + y)         &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash \\forall y(x + y = y + x) \\rightarrow x + y = y + x         &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\zeta &\\vdash x + y = y + x         &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash x + y = y + x \\rightarrow S(x + y) = S(y + x)        &\\quad &\\textbf{I9}\\\\\nPA \\cup \\zeta &\\vdash S(x + y) = S(y + x)        &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash S(x) + y = S(y + x)        &\\quad &\\textbf{Transitivity of equality}\\\\\nPA \\cup \\zeta &\\vdash \\forall x \\forall y(x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\zeta &\\vdash \\forall x \\forall y(x + S(y) = S(x + y)) \\rightarrow   y + S(x) = S(y + x)    &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\zeta &\\vdash y + S(x) = S(y + x)    &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash S(y + x) = y + S(x)   &\\quad &\\textbf{Symmetry of equality}\\\\\nPA \\cup \\zeta &\\vdash S(x) + y = y + S(x)   &\\quad &\\textbf{Transitivity of equality}\\\\\nPA \\cup \\zeta &\\vdash S(x) + y = y + S(x) \\rightarrow \\forall y (S(x) + y = y + S(x))   &\\quad &\\textbf{Q7}\\\\\nPA \\cup \\zeta &\\vdash \\forall y (S(x) + y = y + S(x))   &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash \\forall y(x + y = y + x) \\rightarrow \\forall y (S(x) + y = y + S(x))   &\\quad &\\textbf{Deductive theorem}\\\\\n\\end{alignat*}\nAnd finally, let \\gamma_1 and \\gamma_2 be (1) and (2) respectively.\n\\begin{alignat*}{2}\nPA &\\vdash \\forall y\\,(\\overline{0} + y = y + \\overline{0})          &\\quad &\\pmb\\gamma_1\\\\\nPA &\\vdash \\forall y\\,(x + y = y + x) \\rightarrow \\forall y\\,(S(x) + y = y + S(x))          &\\quad &\\pmb\\gamma_2\\\\\nPA &\\vdash \\gamma_1 \\land \\gamma_2          &\\quad &\\textbf{Conjunction introduction}\\\\\nPA &\\vdash (\\gamma_1 \\land \\gamma_2) \\rightarrow \\forall y \\forall x(x + y = y + x)  &\\quad &\\textbf{A7}\\\\\nPA &\\vdash \\forall y \\forall x(x + y = y + x) &\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}"
  },
  {
    "objectID": "qmd/logic/theorem.html#proof",
    "href": "qmd/logic/theorem.html#proof",
    "title": "Formal theories",
    "section": "Proof",
    "text": "Proof\nNow that we have knowledge of what a first-order theory is, lets look at how to prove statements with them. We first need to give the definition of what proof even means.\n\n\n\n\n\n\nDefinition\n\n\n\nLet T be a set of first-order formulas. A proof from T is a finite sequence of formulas such that every step is either a logical axiom, a member of T, or a result of one of our rules of inference. A proof a formula P from T is given when P is the last step of a proof from T.\n\n\nIf we can prove P from a theory T, we say T proves P, denoted T \\vdash P\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varnothing \\vdash P, then P is derivable from only our deductive apparatus, and we call P a law of logic.\nTwo formulas P and Q are called logically equivalent if \\vdash (P \\leftrightarrow Q)\n\n\nWe denote the set of theorems (statements provable from T) in T as Thm(T).\n\n\n\n\n\n\nDefinition\n\n\n\nIf Thm(T_1) \\subseteq Thm(T_2), which is the same as T_2 \\vdash T_1, we say that T_1 is a subtheory of T_2, and T_2 is an extension of T_1. If Thm(T_1) = Thm(T_2) then T_1 and T_2 are equivalent.\n\n\nLots of boring and tedious notation, but such is life. The great thing about proofs is that they are computable, meaning there exist a machine, i.e. computer program, that can verify the validity of any proof. This does not mean that a computer can create a proof however, just that given one, they can check its accuracy.\nOne of the great things about first-order logic is that provability and truth are equivalent. That is, if there exist a formula P, we can construct it from T with a proof, if and only if P and all statements in T are true!"
  },
  {
    "objectID": "qmd/logic/theorem.html#formal-proofs",
    "href": "qmd/logic/theorem.html#formal-proofs",
    "title": "Formal Theories",
    "section": "Formal proofs",
    "text": "Formal proofs\nNow that we have knowledge of what a first-order theory is, lets look at how to prove statements with them. We first need to give the definition of what a proof.\n\n\n\n\n\n\nDefinition\n\n\n\nLet T be a set of first-order formulas. A proof from T is a finite sequence of formulas such that every step is either a logical axiom, a member of T, or a result of one of our rules of inference. A proof a formula P from T is given when P is the last step of a proof from T.\n\n\nIf we can prove P from a theory T, we say T proves P, denoted T \\vdash P\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varnothing \\vdash P, then P is derivable from only our deductive apparatus, and we call P a law of logic.\nTwo formulas P and Q are called logically equivalent if \\vdash (P \\leftrightarrow Q)\n\n\nWe denote the set of theorems (statements provable from T) in T as Thm(T).\n\n\n\n\n\n\nDefinition\n\n\n\nIf Thm(T_1) \\subseteq Thm(T_2), which is the same as T_2 \\vdash T_1, we say that T_1 is a subtheory of T_2, and T_2 is an extension of T_1. If Thm(T_1) = Thm(T_2) then T_1 and T_2 are equivalent.\n\n\nLots of boring and tedious notation, but such is life. The great thing about proofs is that they are computable, meaning there exist a machine, i.e. computer program, that can verify the validity of any proof. This does not mean that a computer can create a proof however, just that given one, they can check its accuracy.\nOne of the great things about first-order logic is that provability and truth are equivalent. That is, if there exist a formula P, we can construct it from T with a proof, if and only if P and all statements in T are true!\n\n\n\n\n\n\nDefinition\n\n\n\nWe say a theory T is consistent if no contradiction can be derived from it. A formula P is said to be independent of T if neither P nor \\lnot P can be proved from T. We call T complete if no sentence (formula with no free variables) of its language is independent of T."
  },
  {
    "objectID": "qmd/logic/theorem.html#meta",
    "href": "qmd/logic/theorem.html#meta",
    "title": "Formal Theories",
    "section": "Meta",
    "text": "Meta"
  },
  {
    "objectID": "qmd/logic/theorem.html#metatheorems",
    "href": "qmd/logic/theorem.html#metatheorems",
    "title": "Formal Theories",
    "section": "Metatheorems",
    "text": "Metatheorems\nMetatheorems are theorems about first-order logic. The following two metatheorems are the most notable.\n\n\n\n\n\n\nTheorem (Deduction Theorem)\n\n\n\nIf T \\cup \\{P\\} \\vdash Q then T \\vdash (P \\rightarrow Q)\n\n\nWhich means, if T and P prove Q, then T proves that P implies Q.\n\n\n\n\n\n\nTheorem (Universal generalization)\n\n\n\nIf T \\vdash P(x), and x is not a free variable, then T \\vdash \\forall x \\,P(x)"
  },
  {
    "objectID": "qmd/logic/theorem.html#first-order-theories",
    "href": "qmd/logic/theorem.html#first-order-theories",
    "title": "Formal Theories",
    "section": "First-order theories",
    "text": "First-order theories\nZF and PA are two examples of first-order theories. They use different symbols, so they require different languages.\n\n\n\n\n\n\n\n\nFirst-order language\n\\mathcal{L}_\\text{ZF}\n\\mathcal{L}_\\text{PA}\n\n\n\n\nConnectives\n\\land, \\lor, \\implies, \\iff, \\lnot\n\\land, \\lor, \\implies, \\iff, \\lnot\n\n\nQuantifiers\n\\forall, \\exists\n\\forall, \\exists\n\n\nVariables\nv_1,v_2,v_3 ect.\nv_1,v_2,v_3 ect.\n\n\nConstants\n\\varnothing (the empty set)\n\\overline{0} (zero)\n\n\nOperations -\nNone\nS (successor, degree 1) + (addition, degree 2), \\cdot (multiplication, degree 2)\n\n\nRelations -\n\\in (belongs to, degree 2)\n= (equality, degree 2)\n\n\nParentheses -\n), (\n), (\n\n\n\nBoth languages have the same syntax for combining symbols into formulas. They also use the same deductive system (any system equivalent to the example shown in the last section). We’ll delve deeper into Zermelo-Fraenkel set theory later, so we’ll examine Peano arithmetic as the example for the rest of the section.\nPeano arithmetic is a first-order theory, so it combines our formal system with a theory, consisting of formulas we define to be true.\n\n\n\n\n\n\nAxioms in Peano arithmetic\n\n\n\nThe first six axioms listed are rather simple. Note that \\overline{0} \\not = 0, as \\overline{0} is a formal symbol, not a number.\nA1. \\forall x \\,(\\overline{0} \\not = S(x))\nA2. \\forall x,y \\,(S(x) = S(y) \\rightarrow x = y)\nA3. \\forall x \\,(x + \\overline{0} = x)\nA4. \\forall x \\forall y \\,(x + S(y) = S(x + y))\nA5. \\forall x \\,(x \\cdot \\overline{0} = \\overline{0})\nA6. \\forall x,y \\,(x \\cdot S(y) = x \\cdot y + x)\nHowever, the seventh axiom poses a problem for first-order logic. We want an axiom allowing us to use induction. For this we’ll have to use something called an axiom schema, an infinite list of axioms, one for each formula \\phi which can be constructed in PA.\nA7. [\\phi(\\overline{0}) \\land \\forall n (\\phi(n) \\rightarrow \\phi(S(n)))] \\rightarrow \\forall n \\phi(n)\n\n\nThis has two drawbacks. The first of which being PA is not finite axiomatizable, meaning we need an infinite amount of axioms to define PA. This is annoying, but such is life. The second and more serious drawback is as follows. Each formula \\phi can be thought of a set of numbers n such that \\phi(n) is true. There exist an uncountable amount of sets n, but only a countable amount of formulas \\phi can be constructed. Therefore, our induction may prove inadequate for some theorems. This can rectified with second-order logic, which will be discussed later."
  },
  {
    "objectID": "qmd/matrix/unitone.html",
    "href": "qmd/matrix/unitone.html",
    "title": "Fundementals",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#subsection-1",
    "href": "qmd/matrix/unitone.html#subsection-1",
    "title": "Unit one",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#subsection-2",
    "href": "qmd/matrix/unitone.html#subsection-2",
    "title": "Unit one",
    "section": "Subsection 2",
    "text": "Subsection 2\nIf x,y \\in \\mathbb{R}^m, then\n\\begin{align*}\nx^T y = \\begin{pmatrix}\nx_1 & \\cdots & x_m\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\n\\end{pmatrix} = x \\cdot y =\n\\sum^m_{i = 1}x_iy_i\n\\end{align*}\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the unit vector in the direction of x (if x \\not = 0)\n\n\\hat{x} = \\frac{x}{|x|}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe say x is perpendicular to y, denoted x \\perp y, if x \\cdot y = 0\n\n\n\n\n\n\n\n\nFact (Law of cosines)\n\n\n\nLet \\alpha be the angle between our vectors x and y. Then\n\n\\cos\\alpha = \\frac{x \\cdot y}{|x||y|}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#dot-product",
    "href": "qmd/matrix/unitone.html#dot-product",
    "title": "Fundementals",
    "section": "Dot product",
    "text": "Dot product\nIf x,y \\in \\mathbb{R}^m, then\n\\begin{align*}\nx^T y = \\begin{pmatrix}\nx_1 & \\cdots & x_m\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\n\\end{pmatrix} = x \\cdot y =\n\\sum^m_{i = 1}x_iy_i\n\\end{align*}\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the unit vector in the direction of x (if x \\not = 0)\n\n\\hat{x} = \\frac{x}{|x|}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe say x is perpendicular to y, denoted x \\perp y, if x \\cdot y = 0\n\n\n\n\n\n\n\n\nFact (Law of cosines)\n\n\n\nLet \\alpha be the angle between our vectors x and y. Then\n\n\\cos\\alpha = \\frac{x \\cdot y}{|x||y|}\n\n\n\n\n\n\n\n\n\nTheorem (Schwarz inequality)\n\n\n\nFor all x,y \\in \\mathbb{R}^T\n\n|x \\cdot y| \\leq |x||y|\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the orthagonal component of a column vector x\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\{\\text{All $y$ in $\\mathbb{R}^m$ perpendicular to $x$}\\}\n\\end{align*}\nsymbollically\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\left\\{y =\n\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_m\n\\end{pmatrix}\n\n\\colon\n\nx_1 y_1 + \\cdots + x_m y_m = 0\n\\right\\}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#basics",
    "href": "qmd/matrix/unitone.html#basics",
    "title": "Fundementals",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/diffeq/unitone.html",
    "href": "qmd/diffeq/unitone.html",
    "title": "Unit one",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/diffeq/unitone.html#basics",
    "href": "qmd/diffeq/unitone.html#basics",
    "title": "Unit one",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/diffeq/unitone.html#dot-product",
    "href": "qmd/diffeq/unitone.html#dot-product",
    "title": "Unit one",
    "section": "Dot product",
    "text": "Dot product\nIf x,y \\in \\mathbb{R}^m, then\n\\begin{align*}\nx^T y = \\begin{pmatrix}\nx_1 & \\cdots & x_m\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\n\\end{pmatrix} = x \\cdot y =\n\\sum^m_{i = 1}x_iy_i\n\\end{align*}\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the unit vector in the direction of x (if x \\not = 0)\n\n\\hat{x} = \\frac{x}{|x|}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe say x is perpendicular to y, denoted x \\perp y, if x \\cdot y = 0\n\n\n\n\n\n\n\n\nFact (Law of cosines)\n\n\n\nLet \\alpha be the angle between our vectors x and y. Then\n\n\\cos\\alpha = \\frac{x \\cdot y}{|x||y|}\n\n\n\n\n\n\n\n\n\nTheorem (Schwarz inequality)\n\n\n\nFor all x,y \\in \\mathbb{R}^T\n\n|x \\cdot y| \\leq |x||y|\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the orthagonal component of a column vector x\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\{\\text{All $y$ in $\\mathbb{R}^m$ perpendicular to $x$}\\}\n\\end{align*}\nsymbollically\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\left\\{y =\n\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_m\n\\end{pmatrix}\n\n\\colon\n\nx_1 y_1 + \\cdots + x_m y_m = 0\n\\right\\}\n\\end{align*}\n\nSubspaces"
  },
  {
    "objectID": "qmd/diffeq/unitone.html#subspaces",
    "href": "qmd/diffeq/unitone.html#subspaces",
    "title": "Unit one",
    "section": "Subspaces",
    "text": "Subspaces"
  },
  {
    "objectID": "qmd/matrix/unitone.html#subspaces",
    "href": "qmd/matrix/unitone.html#subspaces",
    "title": "Fundementals",
    "section": "Subspaces",
    "text": "Subspaces\n\n\n\n\n\n\nDefinition\n\n\n\nA subspace V of \\mathbb{R}^m is a subset closed under addition and scalar multiplication.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe column space of a matrix A_{(m \\times n)} is \\text{Range}(A \\colon \\mathbb{R}^n \\rightarrow \\mathbb{R}^m)\n\n\nWe can use these definitions to prove some facts about subspaces.\n\n\n\n\n\n\nClaim\n\n\n\nThe function A \\colon \\mathbb{R}^n \\to \\mathbb{R}^m has linearity.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWrite later\n\n\n\n\n\n\n\n\n\nClaim\n\n\n\n\\text{ColSp}(A) is a subspace of \\mathbb{R}^m\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose we have to vertices in the column space\n\nAv, Av^\\prime\n\nNote we then have\nAv + Av^\\prime = A(v + v^\\prime) \\in \\text{Range}(A) = \\text{ColSp}(A)\nand\n\\lambda(Av) = A(\\lambda v)\nFufilling the requirements for a subspace.\n\n\n\nIt might help to look at some examples\n\n\n\n\n\n\nExample\n\n\n\nDo column space examples\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nSuppose v_1,\\ldots,v_n are all vectors in \\mathbb{R}^m. Then\n\n\\text{Span} \\{ v_1,\\ldots,v_n \\} = \\{ \\text{All linear combinations of } v_i \\}\n\n\n\n\n\n\n\n\n\nClaim\n\n\n\nThe \\text{Span}\\{v_1,\\ldots,v_n\\} is a subspace of \\mathbb{R}^m\n\n\n\n\n\n\n\n\nClaim\n\n\n\nThe \\text{ColSp}(A) = \\text{Span}\\{\\text{Columns of }A\\}\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA set \\{v_1,\\ldots,v_n\\} in \\mathbb{R}^m is linearly dependent if for some k, v_k \\in \\text{Span}\\{v_1,\\ldots,v_{k-1}\\}. Otherwise we say the set is linearly independent\n\n\nSuppose we have a matrix A with a rank of 1. This means that our \\text{ColSp}(A) is 1 dimensional.\n\n\n\n\n\n\nDefinition\n\n\n\nThe \\text{RowSp}(A) = \\text{Span}\\{\\text{Transposes of Rows}\\} = \\text{ColSp}(A^T)\n\n\nIf the \\text{ColSp}(A) is one dimensional, than so is \\text{RowSp}(A). This is because\n\nA = vc^T = expand this later"
  },
  {
    "objectID": "qmd/pde/introduction.html",
    "href": "qmd/pde/introduction.html",
    "title": "Partial differential equations",
    "section": "",
    "text": "Partial differential equations is the study of functions with partial derivatives, and two or more independent variables. PDE’s are incredibly useful models, and appear in almost every natural science.\nThe way that heat is transferred through material is given by a PDE, known as the Heat transfer equation\n\\frac{\\partial u}{\\partial t} = a \\frac{\\partial^2u}{\\partial x^2}\nThe equation of the displacment in a wave over time can be given by a PDE,\n\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2u}{\\partial x^2}\nAnd the Poisson equation, used in a wide variety of fields in physics.\n\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2} = P(x,y)"
  },
  {
    "objectID": "qmd/pde/introduction.html#table-of-contents",
    "href": "qmd/pde/introduction.html#table-of-contents",
    "title": "Partial differential equations",
    "section": "Table of contents",
    "text": "Table of contents"
  },
  {
    "objectID": "qmd/numanal/formalsystem.html",
    "href": "qmd/numanal/formalsystem.html",
    "title": "Numerical Analysis",
    "section": "",
    "text": "A formal system consists of a formal language, with strict rules on what symbols are allowed and how to connect them, combined with a deductive system, containing axioms and rules for deducing true statements.\n\n\n\n\n\n\nDefinition\n\n\n\nA formal system is a mathematical structure consisting of\n\nA formal language\nA deductive system"
  },
  {
    "objectID": "qmd/pde/unitone.html",
    "href": "qmd/pde/unitone.html",
    "title": "Heat equation",
    "section": "",
    "text": "We start with a review of ordinary differential equations."
  },
  {
    "objectID": "qmd/pde/unitone.html#subsection-1",
    "href": "qmd/pde/unitone.html#subsection-1",
    "title": "Heat equation",
    "section": "Subsection 1",
    "text": "Subsection 1"
  },
  {
    "objectID": "qmd/numanal/floatingpoint.html",
    "href": "qmd/numanal/floatingpoint.html",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/numanal/floatingpoint.html#floating-point",
    "href": "qmd/numanal/floatingpoint.html#floating-point",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/matrix/unitone.html#matrix-multiplication",
    "href": "qmd/matrix/unitone.html#matrix-multiplication",
    "title": "Fundementals",
    "section": "Matrix multiplication",
    "text": "Matrix multiplication\nSuppose we have two matricies A_{(m\\times n)} and Z_{(l\\times m)}. Recall the function definition of a matrix. Then\n\nZ \\circ A \\colon \\mathbb{R}^n \\to \\mathbb{R}^l\n\n\n\n\n\n\n\nClaim\n\n\n\nZ \\circ A is linear\n\n\n\n\n\n\n\n\nProof\n\n\n\n(Z \\circ A)(v_1 + v_2) = Later\n\n\nSo Z \\circ A is some (l \\times n) matrix, which can be computed as follows.\n\\begin{align*}\nZ \\circ A\n\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_n\n\\end{pmatrix}\n\n&=\n\nZ\\left(A \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_n\n\\end{pmatrix}\\right)\\\\\n\n&=\n\nZ\\left( x_1 \\text{Col}_1 A + \\cdots + x_n \\text{Col}_n A \\right)\\\\\n\n&=\n\n\\begin{pmatrix}\nZ\\text{Col}_1 A & \\cdots & Z \\text{Col}_n A\n\\end{pmatrix}\n\n\\end{align*}\nThus we have a fomula to compose two matrices. Matrix multiplication is associative because it’s function composition. There are three ways that we multiply matrices, each giving the same result.\n\n\\text{Column view:} \\quad  ZA = (Z\\text{Col}_1 A  \\cdots  Z \\text{Col}_n A)\\\\\n\\text{Row-Column view:} \\quad (ZA)_{ij} = (\\text{Row}_{i}Z) \\cdot (\\text{Col}_j A)\\\\\n\\text{Row view:} \\quad  ZA = \\text{Row}_1(Z)A\\\\\n\\text{Column-Row view:} \\quad (ZA)_{ij} = (\\text{Col}_1 Z)(\\text{Row}_1 A) + \\cdots + (\\text{Col}_m Z)(\\text{Row}_m A)\n\n\nRow-column decomposition\nLet A = CR. Construct C as follows.\n\\begin{align*}\n\\text{Col}_1 C &= \\text{First non-$0$ column of $A$}\\\\\n\\text{Col}_2 C &= \\text{First column of $A$ not parallel to } \\text{Col}_1 A\\\\\n&\\vdots\\\\\n\\text{Col}_r C &= \\text{First column of $A$ not in Span}\\{\\text{Col}_1C, \\cdots, \\text{Col}_{r-1} C\\}\\\\\n\\end{align*}\nThus C is an (m \\times r) matrix, whose column space is identitcal to that of A."
  },
  {
    "objectID": "qmd/pde/heatEquation.html",
    "href": "qmd/pde/heatEquation.html",
    "title": "Heat equation",
    "section": "",
    "text": "We start with a review of ordinary differential equations."
  },
  {
    "objectID": "qmd/pde/heatEquation.html#subsection-1",
    "href": "qmd/pde/heatEquation.html#subsection-1",
    "title": "Heat equation",
    "section": "Subsection 1",
    "text": "Subsection 1"
  },
  {
    "objectID": "qmd/diffeq/fode.html",
    "href": "qmd/diffeq/fode.html",
    "title": "First order differential equations",
    "section": "",
    "text": "A first order differential equation is an equation in the form\ny^\\prime = f(x,y).\nThere is no general solution to a first order differential equation, so we’ll have to examine special cases ."
  },
  {
    "objectID": "qmd/diffeq/fode.html#linear-equations",
    "href": "qmd/diffeq/fode.html#linear-equations",
    "title": "First order differential equations",
    "section": "Linear Equations",
    "text": "Linear Equations\nConsider the general first order linear equation,\n\ny^\\prime + p(x)y = g(x),\n\nwhere p(x) and g(x) are continous functions on some interval. Lucky for us, a general solution exists!\n\n\n\n\n\n\nTheorem\n\n\n\nThe general solution for a first order linear differential equation is\n\ny = \\frac{1}{\\mu(x)}\\left(\\int \\mu(x) g(x) dx + C\\right)\n\nwhere\n\n\\mu(x) = \\exp \\left(\\int p(x) dx\\right)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe first need to consider a function \\mu(x) such that\n\n\\mu(x) p(x) = \\mu^\\prime (x)\n\nOn the assumption that \\mu(x) exists,\n\n\\mu(x)y^\\prime + \\mu^\\prime(x)y = \\mu(x)g(x).\n\nNotice that the LHS of the equation looks suspiciously like the product rule, so\n\n(\\mu(x)y(x))^\\prime = \\mu(x)g(x).\n\nIntegrating and swapping some terms around allows us to isolate y(x)\n\n\\mu(x)y(x) + C = \\int \\mu(x)g(x) dx\\\\\ny(x) = \\frac{1}{\\mu(x)}\\left(\\int \\mu(x)g(x) dx + C\\right)\n\nWhich gives us our general solution! We just need to find an explicit function \\mu(x).\n\n\\mu(x)p(x) = \\mu^\\prime(x)\\\\\np(x) = \\frac{\\mu^\\prime(x)}{\\mu(x)}\n\nNotice the RHS is the general solution of the derivative \\ln f(x)\n\np(x) = \\left( \\ln \\mu(x) \\right)^\\prime\\\\\n\\int p(x) = \\ln \\mu(x)\\\\\n\\mu(x) = \\exp \\left( \\int p(x) dx \\right)\n\nThus we have proved out general solution\n\n\nAn Initial value problem is a first order differential equation together with an initial condition, for example\n\\begin{cases}\n      y^\\prime + ay = 0\\\\\n      y(0) = 2\n\\end{cases}\nUsing the formula we just proved, the solution to the first equation is simply\n\ny = Ce^{-ax}.\n\nBut when given an initial condition, we have to pick a value of C such that y(0) = 2\n\ny(0) = Ce^{-a0} = C \\implies C = 2  \n\nSo we get the answer to our IVP\n\ny = 2e^{-ax}"
  },
  {
    "objectID": "qmd/diffeq/fode.html#seperable-equations",
    "href": "qmd/diffeq/fode.html#seperable-equations",
    "title": "First order differential equations",
    "section": "Seperable Equations",
    "text": "Seperable Equations\nConsider the equation\n\nM(x) + N(y)y^\\prime = 0\n\nWhere M(x) and N(y) are continous functions. Not every first order differential equation can be wrote like this, but if it can, we call the equation seperable.\n\n\n\n\n\n\nTheorem\n\n\n\nThe implicit solution for a first order seperable differential equation is given by\n\n\\int M(x) dx = \\int -N(y) dy\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can seperate our equation such that all the x terms are on one side\n\nM(x) = -N(y)y^\\prime \\implies M(x) = -N(y)\\frac{dy}{dx}\n\nIntegrate both sides by x \n\\int M(x) dx = \\int -N(y)\\frac{dy}{dx} dx\n\nUse a dummy substitution u = y(x), giving\n\ndu = y^\\prime(x) dx = \\frac{dy}{dx} dx \\\\\n\\int M(x) dx = \\int -N(u) du\n\nThen for ease of notation, simply let u = y\n\n\\int M(x) dx = \\int -N(y) dy\n\n\n\nFor example\n\n\n\n\n\n\nExample\n\n\n\nThe equation\n\ny^\\prime =  6y^2x\n\ncan be seperated into\n\n\\frac{y^\\prime}{y^2} - 6x =  0.\n\nThus, M(x) = 6x and N(y) = \\frac{1}{y^2}, and we get our implicit solution\n\n\\int -6x dx = \\int -\\frac{1}{y^2} dy\\\\\n \n-3x^2 + C = \\frac{1}{y}\\\\\n\nWhich can easily be converted into our explicit solution\n\ny = \\frac{1}{C - 3x^2}"
  },
  {
    "objectID": "qmd/numanal/fundementals.html",
    "href": "qmd/numanal/fundementals.html",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#floating-point",
    "href": "qmd/numanal/fundementals.html#floating-point",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#taylor-series",
    "href": "qmd/numanal/fundementals.html#taylor-series",
    "title": "Fundementals",
    "section": "Taylor series",
    "text": "Taylor series\nThe taylor expansion of a function f(x) is given by\n\nf(x) = \\sum^m_{k=0} \\frac{f^{(k)}(x)(x-x_0)^k}{k!} + \\frac{f^{(m + 1)}(c)(x-x_0)^{m+1}}{(m+1)!}\n\n\n\n\n\n\n\nExample\n\n\n\nTake the function f(x) = e^x We can taylor expand it to get\n\nf(x) = e^x = 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\cdots + \\frac{x^k}{k!} + \\frac{e^cx^{k+1}}{k+1!}\n\n\n\nWe can also write the Taylor series\n\nf(x + h) = \\sum^m_{k=0} \\frac{h^kf^{(k)}(x)}{k!}\n\n\n\n\n\n\n\nExample\n\n\n\nFind the error\n\\begin{align*}\ny^\\prime(x) &= ay(x) + by(x + h) + \\varepsilon\\\\\ny^\\prime(x) &= ay(x) + b\\left(y(x) - hy^\\prime(x) + \\frac{h^2}{2}y^{\\prime\\prime}(c_1)\\right) + \\varepsilon\\\\\ny^\\prime(x) &= (a+b)y(x) - bhy^\\prime(x) + \\frac{bh^2}{2}y^{\\prime\\prime}(c_1) + \\varepsilon\\\\\n\\end{align*}\nSo\n\na = -b\\quad b = -\\frac{1}{h}\\quad\n\nThus we get\n\ny^\\prime(x) = \\frac{y(x+h) - y(x)}{h} + \\varepsilon\n\nwith an error \n\\varepsilon = -\\frac{h}{2}y^{\\prime\\prime}(c_1).\n\n\n\nWhen we plug these numbers into the computer however, we are going to have an error as we have only 52 digits of precision. This gives us the machine error \\epsilon. So if we wanted to numerically approximate the derivative\n\ny^\\prime(x) = \\frac{y(x+h) - y(x) + 2\\epsilon y}{h} + \\varepsilon\n\nThis gives us the total error, the sum of the machine error, and the taylor error.\n\n\\varepsilon_T = \\epsilon + \\varepsilon\n\n\n\\varepsilon_T = \\frac{2\\epsilon |y|}{2h} + \\frac{2h^2}{12}|y^{\\prime\\prime\\prime}(x)|\n\nBy computing the derivative, we can find the smallest total error.\n\n\\frac{d\\varepsilon_T}{dh} = -\\frac{1}{h^2}\\epsilon |y| + \\frac{h}{3}|y^{\\prime\\prime\\prime}| = 0\n\nSolving for h\n\nh_{opt} =\\left(\\frac{3\\epsilon |y|}{|y^{\\prime\\prime\\prime}|}\\right)^\\frac{1}{3}\n\nFor example, lets try the function y = e^x. This gives us an optimal error\n\nh_{opt} = \\left( 3 \\times 2^{-52} \\frac{e^x}{e^x} \\right)^\\frac{1}{3}\n\n\n\n\n\n\n\nExample\n\n\n\nLets find the optimal value of h using a different error.\n\n\\varepsilon = -\\frac{h}{2}y^{\\prime\\prime}(c_1)\n\nWe can rewrite our equation\n\ny^\\prime(x) = \\frac{y(x+h) - y(x) + 2\\epsilon y}{h} + -\\frac{h}{2}y^{\\prime\\prime}(c_1)\n\nThen\n\n\\varepsilon_T = \\frac{2\\epsilon |y|}{h} + \\frac{h}{2}y^{\\prime\\prime}\n\nTaking the derivative\n\n\\frac{d \\varepsilon_T}{dh} = -\\frac{2\\epsilon |y|}{h^2} + \\frac{1}{2}y^{\\prime\\prime} = 0\n\nWe get\n\n\\frac{2\\epsilon |y|}{h^2} = \\frac{1}{2}y^{\\prime\\prime}\n\nThus\n\nh_{opt} = \\left(\\frac{4\\epsilon |y|}{|y^{\\prime\\prime}|}\\right)^\\frac{1}{2}\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLets find the error of the following expression\n\ny^{\\prime\\prime} = ay(x-h) + by(x) + cy(x+h) + \\varepsilon\\\\\n\n\\begin{align*}\ny^{\\prime\\prime} &= a\\left(y(x)-hy^\\prime(x) + \\frac{h^2}{2}y^{\\prime\\prime}(x) - \\frac{h^3}{6}y^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!}y^{(4)}(x) \\right)\\\\\n&+ by(x) \\\\\n&+ c\\left(y(x)+hy^\\prime(x) + \\frac{h^2}{2}y^{\\prime\\prime}(x) + \\frac{h^3}{6}y^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!}y^{(4)}(x) \\right)\n\\end{align*}\nThus\n\\begin{align*}\n(a + b + c) = 0\\\\\nh(c-a) = 0\\\\\n\\frac{h^2}{2}(a-c) = 1\n\\end{align*}\nThus we have constants\n\nc = a\\quad a = \\frac{1}{h^2} \\quad b = -\\frac{2}{h^2}\n\nAnd we’re left with the error\n\\begin{align*}\n\\varepsilon = -\\frac{h^2}{2y}\\left(y^{(4)}(c_1)+y^{(4)}(c_2)\\right)\n\\end{align*}\nThus we have\n\ny^{\\prime\\prime}(x) = \\frac{y(x-h)-2y(x)+y(x+h)}{h^2} + \\varepsilon\n\nLets find the optimal error. First we include the machine error\n\n\\epsilon_m = \\frac{4\\epsilon |y|}{h^2}\n\nCombine with our function error \n\\varepsilon_{T} = \\frac{4\\epsilon |y|}{h^2} +  \\frac{h^2}{2y}\\left(y^{(4)}\\right)\n\nContinue rest later.\n\n\nExample again\n\n\n\n\n\n\nExample\n\n\n\nTaylor expand f(x) = (1+x)^{1/2}\nWe get clearly\n\nf^{(k)}(x) = \\frac{(-1)^{k+1}}{2^k}(3\\cdot 5\\cdots (2k-3))(1+x)^{\\frac{-2k-1}{2}}\n\nSo our taylor expansion\n\nf(x) = (1+x)^{1/2} = 1 + \\frac{x}{2} - \\frac{1}{2^2}\\frac{x^2}{2!} + \\frac{3}{2^3}\\frac{x^3}{3!} \\cdots + \\frac{-1^{k+1}}{2^k}(1\\cdot 3\\cdot 5\\cdots (2k-3))\\frac{x^k}{k!}"
  },
  {
    "objectID": "qmd/diffeq/fode.html#exact-equations",
    "href": "qmd/diffeq/fode.html#exact-equations",
    "title": "First order differential equations",
    "section": "Exact Equations",
    "text": "Exact Equations"
  },
  {
    "objectID": "qmd/logic/intro.html",
    "href": "qmd/logic/intro.html",
    "title": "Introduction to Mathematical Logic",
    "section": "",
    "text": "Mathematical logic is the study of formal reasoning and logic within mathematical systems. The study of logic typically consists of the construction of a formal system, and then investigating what statements can be made true or false in that system."
  },
  {
    "objectID": "qmd/logic/intro.html#table-of-contents",
    "href": "qmd/logic/intro.html#table-of-contents",
    "title": "Introduction to Mathematical Logic",
    "section": "Table of contents",
    "text": "Table of contents\n\nFormal Systems"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html",
    "href": "qmd/logic/formal-systems/formal-language.html",
    "title": "Formal languages",
    "section": "",
    "text": "To begin with constructing a formal system, we need to first need to know what symbols our logic will be using, and how to connect them. These properties are given by a formal language.\nSymbols, are individual elements used in a language. These symbols concatenate to form formulas (sometimes called words or sentences). The collection of all symbols and formulas in a language, is called an alphabet.\nA formal language is often given a syntax, rules for how symbols can be combined. If a formula can be constructed using the syntax attributed to the language, it is called a well-formed formula, often abbreviated wff.\nWith these definitions, we define a"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#formal-languages",
    "href": "qmd/logic/formal-systems/formal-language.html#formal-languages",
    "title": "Formal language",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the distinction is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#deductive-systems",
    "href": "qmd/logic/formal-systems/formal-language.html#deductive-systems",
    "title": "Formal language",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example2\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#first-order-logic",
    "href": "qmd/logic/formal-systems/formal-language.html#first-order-logic",
    "title": "Formal language",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part."
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#footnotes",
    "href": "qmd/logic/formal-systems/formal-language.html#footnotes",
    "title": "Formal languages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis example was given by Noam Chomsky in his thesis The logical structure of linguistic theory↩︎"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#first-order-languages",
    "href": "qmd/logic/formal-systems/formal-language.html#first-order-languages",
    "title": "Formal languages",
    "section": "First order languages",
    "text": "First order languages\nFor a more in-depth look at a formal language, lets take a dive into first-order language. I’ll use the slightly obscure notation used in [Ebbinghaus, Flum, Thomas], as I personally feel they take a very formal approach to developing a formal language.\nThe alphabet of a first-order language has the following symbols\n\nConnectives - \\land, \\lor, \\rightarrow, \\leftrightarrow, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3, \\cdots, v_n\nEquality - The equal sign ‘=’\nParentheses - Right ) and left (.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\n\nFor readability sake, parenthesis occur in different sizes, or occasionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nThe first five groups listed are denoted \\mathbb{A}, and S denotes the unique operations, relations, and constants in the language. The set S determines the unique first-order language. We denote the shared alphabet \\mathbb{A}_S = \\mathbb{A} \\cup S.\nNow we can begin constructing the syntax for first-order languages. We start by defining terms\n\n\n\n\n\n\nDefinition\n\n\n\nS-terms are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(T1) Every variable is an S-term.\n(T2) Every constant is an S-term.\n(T3) If f is an operator of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then ft_1,t_2,\\dots,t_n is an S-term.\n\n\nThe set of all S-terms is denoted T^S. Through repeated applications of the three rules above, we can create larger terms. For example\n\\begin{alignat*}{2}\n& c_1 & \\quad &(T2)\\\\\n& v_1    &\\quad &(T1)\\\\\n& gc_1v_1   &\\quad &(T3) \\text{ with $c_1$ and $v_1$ applied to $g$}\n\\end{alignat*}\nSo gc_1v_1 is an S-term. Most of the time this is wrote g(c_1,v_1), but to keep things formal we’ll use the objectively worse notation for now. We will however introduce shorthand later. Now that we have S-terms, we can start creating formulas.\n\n\n\n\n\n\nDefinition\n\n\n\nS-formulas are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(F1) If t_1 and t_2 are S-terms, then t_1 = t_2 is an S-formula.\n(F2) If p is a relation of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then pt_1,t_2,\\dots,t_n is an S-formula.\n(F3) If \\phi is an S-formula, then \\lnot\\phi is also an S-formula.\n(F4) If \\phi and \\psi are S-formulas, then (\\phi \\land \\psi), (\\phi \\lor \\psi), (\\phi \\rightarrow \\psi), (\\phi \\leftrightarrow \\psi) are also S-formulas.\n(F5) If \\phi is an S-formula, and x is a variable, then \\forall x \\phi and \\exists x \\phi are also S-formula.\n\n\nS-formula formed from (F1) or (F2) are known as atomic formula as they don’t use any other formula in their language. Note that an S-formula is simply another word for a wff.\nWe can now introduce some new vocabulary\n\n\n\n\n\n\nDefinition\n\n\n\nGiven the S-formulas (wffs) \\phi, \\psi we have the following vocabulary\n\n\\lnot \\varphi is called the negation of \\phi\n(\\phi \\land \\psi) is called the conjunction of \\phi and \\psi\n(\\phi \\lor \\psi) is called the disjunction of \\phi and \\psi\n(\\phi \\rightarrow \\psi) is called the implication of \\phi and \\psi\n(\\phi \\leftrightarrow \\psi) is called the bi-implication of \\phi and \\psi\n\n\n\nWe denote the set of S-formulas with \\mathcal{L}^S. This set is called the first-order language associated with the symbol set S. And just like that we’ve created a first-order lanaguage! Lot’s of rather tricky notation, but the overall concept is no different than our example in the beginning.\nIt is worht nothing that the collection of all first-order languages is denoted \\mathcal{L}_1, and it will be a commonly used example."
  },
  {
    "objectID": "qmd/abstract/abstract.html",
    "href": "qmd/abstract/abstract.html",
    "title": "Basics",
    "section": "",
    "text": "Basic facts about sets, relations, and functions."
  },
  {
    "objectID": "qmd/abstract/abstract.html#relations",
    "href": "qmd/abstract/abstract.html#relations",
    "title": "Basics",
    "section": "Relations",
    "text": "Relations\nA binary relation on a set A is a subset R of A \\times A. We denote a ~ b \\rightarrow (a,b) \\in \\mathbb{R}.\nWe say ~ is an equivalence relation if it satisfies the following properties\n\n~ is reflexive, if \\forall a \\in A a ~ a\n~ is symmetric, if \\forall a,b \\in A a~ b \\rightarrow b ~ a\n~ is transitive, if \\forall a,b,c \\in A a ~ b \\land b ~ c \\rightarrow a ~ c\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf a,b \\in \\mathbb{Z} and a \\not = 0, we say a divides b if \\exists c \\in \\mathbb{Z} such that ac = b. This is denoted\n\na | b"
  },
  {
    "objectID": "qmd/abstract/intro.html",
    "href": "qmd/abstract/intro.html",
    "title": "Intro",
    "section": "",
    "text": "Its like algebra but more abstract ig idk"
  },
  {
    "objectID": "qmd/basics/abstract.html",
    "href": "qmd/basics/abstract.html",
    "title": "Basics",
    "section": "",
    "text": "Basic facts about sets, relations, and functions."
  },
  {
    "objectID": "qmd/basics/abstract.html#relations",
    "href": "qmd/basics/abstract.html#relations",
    "title": "Basics",
    "section": "Relations",
    "text": "Relations\nA binary relation on a set A is a subset R of A \\times A. We denote a ~ b \\rightarrow (a,b) \\in \\mathbb{R}.\nWe say ~ is an equivalence relation if it satisfies the following properties\n\n~ is reflexive, if \\forall a \\in A a ~ a\n~ is symmetric, if \\forall a,b \\in A a~ b \\rightarrow b ~ a\n~ is transitive, if \\forall a,b,c \\in A a ~ b \\land b ~ c \\rightarrow a ~ c\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf a,b \\in \\mathbb{Z} and a \\not = 0, we say a divides b if \\exists c \\in \\mathbb{Z} such that ac = b. This is denoted\n\na | b\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet ~ be an equivalence relation. The equivalence class of a \\in A is defined\n\n[a] = \\{x \\in A | x ~ a\\}\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nFind the equivalance classes of \n[x] = \\{y \\in \\mathbb{Z} \\mid 2 \\mid y - x\\}\n\nIf x is even then \\exists n \\in \\mathbb{Z} such that x = 2n.\n\n2 \\mid y - x = 2 \\mid y - 2n \\rightarrow \\exists m \\in \\mathbb{Z}, y = 2m\n\nIf x is odd then \\exists n \\in \\mathbb{Z} such that x = 2n + 1.\n\n2 \\mid y - x = 2 \\mid y - 2n + 1 \\rightarrow \\exists m \\in \\mathbb{Z}, y = 2m + 1\n\nThus we have two equivalance classes for x, [0] and [1]."
  },
  {
    "objectID": "qmd/basics/abstract.html#properties-of-the-integers",
    "href": "qmd/basics/abstract.html#properties-of-the-integers",
    "title": "Basics",
    "section": "Properties of the integers",
    "text": "Properties of the integers\nProperties of the set of integers, \\mathbb{Z}\n\n\n\n\n\n\nDefinition\n\n\n\nIf a,b \\in \\mathbb{Z} \\backslash \\{0\\}, then there exists a unique positive integer d, such that\n\nd \\mid a, \\; d \\mid b\nIf e \\mid a, \\; e \\mid b then e \\mid d.\n\nWe call d the greatest common divisor, denoted gcd(a,b).\n\n\n\n\n\n\n\n\nTheorem (The division algorithm)\n\n\n\nIf a,b \\in \\mathbb{Z}, b \\not = 0 then there uniquly exists q,r \\in \\mathbb{Z} such that a = qb + r.\nNote 0 \\leq r \\leq \\lvert b \\rvert\nWe call q the quoitent, and r the remainder.\n\n\nThe Eucldean algorithm provides the greatest common divisor of two non-zero integers by iterating the division algorithm.\n\\begin{align*}\na &= q_0 b + r_0\\\\\nb &= q_1 r_0 + r_1\\\\\nr_0 &= q_2 r_1 + r_2\\\\\n&\\vdots\\\\\nr_{n-2} &= q_n r_{n-1} + r_n\\\\\nr_{n-1} &= q_{n+1}r_n\n\\end{align*}\nIf m &lt; n, then r_m &gt; r_n. We have r_n = gcd(a,b).\n\n\n\n\n\n\nTheorem\n\n\n\nWhen using the Euclidean algorithm \ngcd(a,b) = gcd(b,r_0)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nRearrange\nr_0 = a - q_0 b\nIf d \\mid a and d \\mid b then d \\mid a - q_0b \\rightarrow d \\mid r_0.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nGiven a,b \\in \\mathbb{Z}, \\exists u,v \\in \\mathbb{Z} such that au + bv = gcd(a,b).\n\n\nWe basically just go backwords. Not that interesting.\n\n\n\n\n\n\nDefinition\n\n\n\nAn integer p &gt; 1 is prime if and only if it’s only positive divisors are p and 1.\n\n\n\n\n\n\n\n\nEuclids lemma\n\n\n\nGiven p as prime, for any a,b \\in \\mathbb{Z}\n\np \\mid ab \\implies p \\mid a \\lor p \\mid b\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe know p \\mid ab. If p \\mid a then gcd(a,p) = 1.\nThus we have integers u,v such that au + pv = 1.\nThen we multiply by b, giving p \\mid bau and p \\mid bpv.\n\n\n\n\n\n\n\n\nTheorem (Fundemental theorem of arithmatic)\n\n\n\nIf n \\in \\mathbb{Z} and n &gt; 1, then n can be factored into a unique product of prime numbers.\n\nn = p_1^{\\alpha_1}p_2^{\\alpha_2}p_3^{\\alpha_3}\\cdots p_s^{\\alpha_s}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThere exists infinitly many primes."
  },
  {
    "objectID": "qmd/matrix/unittwo.html",
    "href": "qmd/matrix/unittwo.html",
    "title": "Unit two",
    "section": "",
    "text": "We can put a matrix into upper triangular form as follows\n\\begin{align*}\nAx = b \\rightarrow\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2\\\\\nb_3\n\\end{pmatrix}\n\\end{align*}\n\\begin{align*}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2 - 2b_1\\\\\nb_3 - b_2 + b_1\n\\end{pmatrix}\n\\end{align*}\nNote that we can rewrite this as an elementary row operation matrix\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n-2 & 1 & 0\\\\\n-1 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\\end{align*}\nWe call that first matrix e_1. Now we get\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & -1 & 1\n\\end{pmatrix}\ne_1 A =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix}\n\\end{align*}\nGiving us\n\ne_2 e_1 (Ax = b) \\rightarrow Ux = b^\\prime\n\nLet\n\nL = e_1^{-1}e_2^{-1}\n\nWe then have\n\nLU = A\n\nNow take for example the matrix\n\nA = \\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 6 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix}\n\nNotice it has the same e_1. However, this gives\n\ne_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 0 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\nWhich we can preform a row change to get\n\nF_1E_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 13\\\\\n0 & 0 & 6\n\\end{pmatrix}\n\nWhere F_1 is not a lower triangular matrix.\n\nF_1 = \\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 0 & 1\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\nThis creates\n\nE_1^{-1}F_1^{-1}U = A\n\nGiving us LPU decomposition."
  },
  {
    "objectID": "qmd/matrix/unittwo.html#elimination",
    "href": "qmd/matrix/unittwo.html#elimination",
    "title": "Unit two",
    "section": "",
    "text": "We can put a matrix into upper triangular form as follows\n\\begin{align*}\nAx = b \\rightarrow\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2\\\\\nb_3\n\\end{pmatrix}\n\\end{align*}\n\\begin{align*}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2 - 2b_1\\\\\nb_3 - b_2 + b_1\n\\end{pmatrix}\n\\end{align*}\nNote that we can rewrite this as an elementary row operation matrix\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n-2 & 1 & 0\\\\\n-1 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\\end{align*}\nWe call that first matrix e_1. Now we get\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & -1 & 1\n\\end{pmatrix}\ne_1 A =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix}\n\\end{align*}\nGiving us\n\ne_2 e_1 (Ax = b) \\rightarrow Ux = b^\\prime\n\nLet\n\nL = e_1^{-1}e_2^{-1}\n\nWe then have\n\nLU = A\n\nNow take for example the matrix\n\nA = \\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 6 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix}\n\nNotice it has the same e_1. However, this gives\n\ne_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 0 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\nWhich we can preform a row change to get\n\nF_1E_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 13\\\\\n0 & 0 & 6\n\\end{pmatrix}\n\nWhere F_1 is not a lower triangular matrix.\n\nF_1 = \\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 0 & 1\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\nThis creates\n\nE_1^{-1}F_1^{-1}U = A\n\nGiving us LPU decomposition."
  },
  {
    "objectID": "qmd/pde/introduction copy.html",
    "href": "qmd/pde/introduction copy.html",
    "title": "PDE",
    "section": "",
    "text": "When given the equation f(x) = 0, and f is a noninvertable function. We can apply newtons method. Take x_k to be close to our solution. Then we use the following \nx_{k+1} = x_k + \\delta\n\nWhere \\delta is the error. By taylor expanding f(x), we can get the following formula\n\nx_{k+1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#newtons-method",
    "href": "qmd/pde/introduction copy.html#newtons-method",
    "title": "PDE",
    "section": "",
    "text": "When given the equation f(x) = 0, and f is a noninvertable function. We can apply newtons method. Take x_k to be close to our solution. Then we use the following \nx_{k+1} = x_k + \\delta\n\nWhere \\delta is the error. By taylor expanding f(x), we can get the following formula\n\nx_{k+1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#second-order-linear-constant-coefficients",
    "href": "qmd/pde/introduction copy.html#second-order-linear-constant-coefficients",
    "title": "PDE",
    "section": "Second Order Linear Constant Coefficients",
    "text": "Second Order Linear Constant Coefficients\nThe general equation is\n\\begin{cases}\n      (p(x)y^{\\prime})^\\prime + q(x)y + \\lambda r(x)y = 0 \\\\\n      \\alpha_1 y(a) + \\beta_1 y^\\prime(a) = 0 \\\\\n      \\alpha_2 y(b) + \\beta_2 y^\\prime(b) = 0\n\\end{cases}\n\n\n\n\n\n\nTheorem\n\n\n\nAll eigenfunctions are orthagonal.\n\n\\int_a^b R(x)y_i(x)y_j(x)\\,dx = 0, \\iff y_i \\not = y_j\n\n\n\nTake the equation\n\\begin{cases}\n      y^{\\prime\\prime} + \\lambda y = 0 \\\\\n      y(0) = 0 \\\\\n      y(1) + y^\\prime(1) = 0\n\\end{cases}\nSolving the equation gets us\n\ny_i(x) = \\sin\\left(x\\sqrt{\\lambda}\\right)\n\nLet s_i = \\sqrt{\\lambda_i}. We can then plug this into our integral and get\n\n\\int_0^1 \\sin(s_i x) \\sin(s_j x)\\, dx.\n\nUsing wolframalpha,\n\n\\frac{b\\cos(b)\\sin(a) - a\\cos(a)\\sin(b)}{a^2 - b^2}\n\nUsing the equation\n\ns_i\\cos(s_i) + \\sin s_i = 0\n\nWe can simplify and get\n\n\\frac{b\\cos(b)\\sin(a) - a\\cos(a)\\sin(b)}{a^2 - b^2} = 0"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/intro.html",
    "href": "qmd/abstract/intro-to-groups/intro.html",
    "title": "Axioms and examples",
    "section": "",
    "text": "We start by defining what a binary operation\n\n\n\n\n\n\nDefinition\n\n\n\nA binary operation \\star on a set G is a function \\star \\colon G \\to G, such that \\star is associative.\n\n\nFor example, the ‘+’ operation is a binary operation on \\mathbb{Z}, as for all a and b in \\mathbb{Z}, a + b is also in \\mathbb{Z}.\n\nNote the following properties\n\n\n\n\n\n\nProposition\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n\nThe identity element e of G is unique.\nFor each a \\in G, there exist a unique a^{-1}.\n(a^{-1})^{-1} = a for all a \\in G.\n(a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\nThe identity element e of G is unique.\n\nSuppose there exists two identity elements e_1 and e_2. By the axiom of identity e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n\nFor each a \\in G, there exist a unique a^{-1}.\n\nSuppose b and c are both inverses of a and let e be the indentity of G. By the inverse axiom a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html",
    "href": "qmd/abstract/intro-to-groups/axioms.html",
    "title": "Definitions and basic properties",
    "section": "",
    "text": "This section examines the definitions and important properties of groups."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html#order",
    "href": "qmd/abstract/intro-to-groups/axioms.html#order",
    "title": "Definitions and basic properties",
    "section": "Order",
    "text": "Order\nAs always, we start with a definition.\n\n\n\n\n\n\nDefinition\n\n\n\nFor a group G and x \\in G, the order of x is the smallest positive integer n such that x \\star x \\star x \\cdots \\star x = e, where that composition consists of n copies of x.\n\n\nNote that we notate x \\star x \\star x \\cdots as x^n. We also denote the order of x as |x|.\nFor example, for any group G such that e is an identity, |e| = 1. All non-zero elements of \\mathbb{Z}, \\mathbb{Q} or \\mathbb{R} under addition have order infinity."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html",
    "title": "Symmetric Groups",
    "section": "",
    "text": "Symmetric groups are groups based on symmetries of certain mathematical objects and structures."
  },
  {
    "objectID": "qmd/matrix/unittwo.html#computing-inverses",
    "href": "qmd/matrix/unittwo.html#computing-inverses",
    "title": "Unit two",
    "section": "Computing inverses",
    "text": "Computing inverses\nSuppose we have an n \\times n matrix A. If A^{-1} exists, then there exists a sequence of row operations R such that R(A) = I. Thus\n\nR(\\,A \\mid I\\,) = R(\\, I \\mid A^{-1}\\,).\n\n\nLet A be an invertible square matrix of size n. Recall that A has an LU decomposition if and only if every upperleft square submatrix of A is invertable. (As you’ll never need row exchanges)\nWe can repeatedly apply row operations on A to arrive at U. Thus\n\nA = LU\n\nClaim, If L_1^{-1} is a lower matrix with some coefficients, L is the same with the negation of those coefficients. Remember that all LU decompositions are exact.\nTwo uppper triangular matrices when multiplied will have their diagonals multiplied.\n\nLDU decomposition\nIf A is an (n \\times n) invertable matrix with an LU factorization, then A has a factor LDU such that L is a lower triangular, D is a diagonal consisting of pivots, U is a unipotent upper triangular matrix. Note tha LDU is unique."
  },
  {
    "objectID": "qmd/matrix/unittwo.html#transpose",
    "href": "qmd/matrix/unittwo.html#transpose",
    "title": "Unit two",
    "section": "Transpose",
    "text": "Transpose\nThere is a fun relation\n\n(AB)^T = B^T A^T\n\nAnd another\n\n(A^T)^{-1} = (A^{-1})^T = A^{-T}\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe matrix A_{n \\times n} is symmetric if A^T = A.\n\n\nIf A_{m\\times n} then AA^T is m \\times m and symmetric, and A^TA is n \\times n and symmetric.\nThis is because\n\n(AA^T)^T = (A^T)^TA^T = AA^T\n\nNote that if S is a symmetric matrix that has an LU decomposition, then LDU is actually LDL^T.\n\nS= LDU\n \nS = U^T D^T L^T\n\n\nPLU decomposition\nLet A be an arbitrary n\\times n invertable matrix. There there exists a unique factorizatio A = PLU such that P is a permutation matrix, L is a lower triangular with 1’s on the diagonal. U is upper triangular. They don’t alone give uniqueness though.\nA = (PLP^{-1})PU is something."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#newtons-method",
    "href": "qmd/numanal/fundementals.html#newtons-method",
    "title": "Fundementals",
    "section": "Newtons method",
    "text": "Newtons method\n\n\n\n\n\n\nExample\n\n\n\nWrite the Newton Iteration to solve\n\nx = \\cos x\n\nNote that\n\nf(x) = x - \\cos x\n\n\nf^\\prime(x) = 1 + \\sin x\n\nSo\n\nx_{m+1} = x_m - \\frac{x_m - \\cos x_m}{1 + \\sin x_m}\n\n\n\nRemember that the error of Newtons method is approximatly equal to the multiplicity of the root\n\n\\varepsilon_{m+1} \\approxeq \\varepsilon_m^2 \\bigg\\lvert \\frac{f^{\\prime\\prime}(a)}{2f^\\prime(a)} \\bigg\\rvert\n\n\n\n\n\n\n\nExample\n\n\n\nWrite the Newton Iteration to solve\n\nf(x) = x^\\alpha\\quad \\alpha&gt;0\n\nWe want to write newtons iteration with an initial guess x_0 \\not = 0, and find for what values of \\alpha does newtons iteration converge to root?\nFirst\n\nx_{m+1} x_m - \\frac{x^\\alpha_m}{\\alpha x^{\\alpha-1}_m} = x_m\\left(1-\\frac{1}{\\alpha}\\right)\n\nThis will converge if\n\n-1 &lt; 1 - \\frac{1}{\\alpha} &lt; 1\n\nThus\n\n\\frac{1}{\\alpha} &lt; 2 \\implies \\alpha &gt; \\frac{1}{2}\n\n\n\nProvided the multiplicity of the root is 1, it converges quadratically. Otherwise the newton method converges linearly, with the rate equal to S = \\frac{m-1}{m}.\nLets assume you can’t calculate the derivative. We instead use the approximation\n\nf^\\prime(x) \\approx \\frac{f(x + h)-f(x)}{h}\n\nOr we use the secant method.\n\nf^\\prime(x_m) \\approx \\frac{f(x_m) - f(x_{m-1})}{x_m - x_{m-1}}\n\nThis is useful when f(x_m) is expensive to compute, but the disadvantage is the convergence is slightly slower.\n\n\\varepsilon_{m+1} \\approx \\varepsilon_m^\\alpha \\bigg\\lvert \\frac{f^{\\prime\\prime}(r)}{2f^\\prime(r)}\\bigg\\rvert\n\nCombination of Newton and Bisection\nFirst we draw a secant line from the points a to b. This gives us an equation\n\ny = f(a) + (x - a)\\frac{f(b)-f(a)}{b-a}\n\nWhich gives us\n\nx = \\frac{a(f(b)-f(a))(b-a)}{f(b)-f(a)} = \\frac{af(b)-bf(a)}{f(b)-f(a)}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#dihedral-groups",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#dihedral-groups",
    "title": "Symmetric Groups",
    "section": "Dihedral groups",
    "text": "Dihedral groups\nAn important example of a group comes from symmetries of geometric objects, most notably, polygons.\nLets take a hexagon, and apply an operation s, which reflects it along a line of symmetry. We could also apply an operation r, which rotates the hexagon by \\pi / 3 radians. These operations swap the location of the vertices of the hexagon.\n\n\n\n\n\n\n(Insert picture of a hexagon being rotated and symetry)\n\n\n\n\n\nIf we represent the orignal labelling of the vertices as\n\n\\{1,2,3,4,5,6\\}\n\nThen we can represent our operations r and s as the permutations\n\nr = \\{2,3,4,5,6,1\\} \\quad s = \\{1,6,5,4,3,2\\}\n\n\n\n\n\n\n\nDefinition\n\n\n\nA symmetry is a reordering of the vertices on a geometric shape such that their structure remains. We typically denote a symmetry with \\sigma.\n\n\nFor polygons in 2-space, we say that the ‘structure’ of the polygon remains if it can be transferred to 3-space, rotated, and then placed back into 2-space.\nThus our operations r and s are symmetries of the polygon. They can be combined to produce additional symmetries. The set of all possible symmetries on a n-polygon is denoted D_{2n}.\n\n\n\n\n\n\nDefinition\n\n\n\nThe set of symmetries on an n-polygon is denoted D_{2n}, and called the dihedral group of order 2n.\n\n\nWe will prove that D_{2n} is indeed a group later, but for now it can be taken as fact. D_{2n} has 2n symmetries, all of which can be constructed via compositions of our symmetries r and s.\n\n\n\n\n\n\nExample\n\n\n\nLets examine the group D_{12}, the symmetries of a hexagon.\nFirst lets look at our possible rotations r. Let e be the orignal labelling of the vertices, and r be defined\n\nr \\colon \\{1,2,3,4,5,6\\} \\to \\{2,3,4,5,6,1\\}\n\nWe can repeatedly compose r to construct the following symmetries\n\ne, r, r^2, r^3, r^4, r^5.\n\nNote that r^6 = r^0 = e, thus |r| = 6.\nNext we can look at our reflections. Let s be defined\n\ns \\colon \\{1,2,3,4,5,6\\} \\to \\{1,6,5,4,3,2\\}\n\nNote that s^2 = e. Combining s and r, we can create \ns, sr, sr^2, sr^3, sr^5, sr^6\n\nGiving us six new symmetries. This gives us a total of 12 symmmetries in D_{12}.\n\n\nIt should be noted that D_{12} is not abelian, which can be clearly be seen with\n\nrs = \\{6,5,4,3,2,1\\} = sr^5 \\quad sr = \\{2,1,6,5,4,3\\}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#symmetric-groups",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#symmetric-groups",
    "title": "Symmetric Groups",
    "section": "Symmetric Groups",
    "text": "Symmetric Groups\nLets define a new symmetric group \\Omega.\n\n\n\n\n\n\nDefinition\n\n\n\nWe define a set \\Omega by the following rules\nLet \\Omega \\not = \\varnothing.\nLet S_\\Omega be the set of all bijections from \\Omega \\to \\Omega, called a permutation.\nLet \\sigma,\\tau be permutations of \\Omega.\n\n\nThis gives \\Omega, and more precisly S_\\Omega some interesting properties.\n\nThe identity of S_\\Omega is the permutation 1 where 1(a) = a\\, \\forall a \\in \\Omega.\nSince function composition is associative, the operation is associative.\nEvery permutation has an inverse since it’s a bijection. Take \\sigma\\colon \\Omega \\to \\Omega, then \\sigma^{-1} \\colon \\Omega \\to \\Omega and \\sigma \\circ \\sigma^{-1} = 1\n\nTherefore, (S_\\Omega, \\circ) is a group and its called the symmetric group on \\Omega. Usually we take \\Omega as the first n natural numbers.\n\n\n\n\n\n\nExample\n\n\n\nLets examine \\Omega = \\{1,2,3\\}.\nWe have \\sigma \\in S_3, which we define by\n\n\\sigma \\colon \\{1,2,3\\} \\to \\{2,3,1\\}.\n\nThis is represented in shorthand by\n\n\\sigma \\colon (1\\,2\\,3)\n\nWe can also define a permutation \\tau \\in S_3 By\n\n\\tau \\colon \\{1,2,3\\} \\to \\{2,1,3\\}\n\nWhich is represented in shorthand by\n\n\\tau \\colon (1\\,2)(3) \\text{ or } \\tau \\colon (1\\,2)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA cycle is a string of integers representing an element of S_n which cyclicly permutes the integers.\nEg. (1\\,2\\,3), (1\\,2)(3)::: {.callout-note icon=“false”} ## Definition\nD_{2n} with these operations is called the dihedral group of order 2n.\n\n\n\n\n\n\n\n\nExample\n\n\n\nContinuing to examine S_3, we know that there exist 3! = 6 total permutations of the set. We can denote the identity permutation\n\n(1)(2)(3)\n\nWe have three example where we leave one number untouched \n(1)(2\\,3), (2)(1\\,3), (3)(1\\,2)\n\nAnd two examples where we permute every number\n\n(1\\,2\\,3), (1\\,3\\,2)\n\n\n\nFor any \\sigma \\in S_n, the cycle decomposition of \\sigma^{-1} is obtained by writing the numbers in cycle of the cycle decomposition of \\sigma is in reverse order. For example, given\n\n\\sigma \\colon (1\\,2\\,3),\\quad \\sigma^{-1} \\colon (3\\,2\\,1)\n\nWhen composing in S_n, we read from right to left, for example, if we were in S^4, and given \n\\sigma \\colon (1\\,2\\,3)(4),\\quad \\tau \\colon (1\\,2)(3\\,4)\n\nWe can get \\sigma \\circ \\tau by combining the two. Rather tedious, but we eventually get\n\n\\sigma \\circ \\tau \\colon (1\\to 3)(2\\to 2)(3\\to4)(4\\to1) = (1\\,3\\,4)(2)\n\nNote that S_n is non-abelian for all n\\geq3. That being said, disjoint cycles will commute. The order of an element \\sigma \\in S_n is the l.c.m of the lengths in it’s cycle decomposition.\nA trasposition is an element of length 2."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#example-2",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#example-2",
    "title": "Symmetric Groups",
    "section": "Example",
    "text": "Example\nContinuing to examine S_3, we know that there exist 3! = 6 total permutations of the set. We can denote these\n\n(1)(2)(3), (1)(2\\,3), (2)(1\\,3), (3)(1\\,2)\n\n:::"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#homomorphisms-and-isomorphisms",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#homomorphisms-and-isomorphisms",
    "title": "Symmetric Groups",
    "section": "Homomorphisms and Isomorphisms",
    "text": "Homomorphisms and Isomorphisms"
  },
  {
    "objectID": "qmd/matrix/unittwo.html#permutation-matrices",
    "href": "qmd/matrix/unittwo.html#permutation-matrices",
    "title": "Unit two",
    "section": "Permutation matrices",
    "text": "Permutation matrices\n\n\n\n\n\n\nDefinition\n\n\n\nA permutation matrix is a matrix that permutes the order of the rows when left multiplied, and the columns when right multiplied.\n\n\nThe columns of P are the columns of I permuted. That is to say P is a product of exchange matricies.\nIf P is a permutation matrix, then P is invertible, and P^{-1} = P^T.\nThis is because\n\\begin{align*}\n(P^TP)_{ij} &= (Row_i P^T)\\cdot(Col_j P)\\\\\n&= (Col_i P) \\cdot (Col_j P)\n\\end{align*}\nThus we have 0 if i\\not = j, and 1 if i=j.\nTake the 3\\times3 matrix P sending Row 1 \\to Row 2 \\to Row 3\n\\begin{align*}\nP = \\begin{pmatrix}\n0 & 0 & 1\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\\end{align*}\nWe get this by thinking “What puts Row 3 into Row 1”, which is the following\n\nP = e_1e^T_3\n\nWhich can be repeated\n\nP = e_1e^T_3 + e_2e^T_1 + e_3e_2^T\n\nRecall the PLU decomposition of an invertible matrix A.\nIf A = PLU, then PLP^{-1} is also lower triangular, and the LPU decomposition is (PLP^{-1})PU.\nSuppose I want to turn the following matrix into upper triangular format\n\\begin{align*}\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n* & * & *\n\\end{pmatrix}\n\\end{align*}\nI would need to switch Row 1 and Row 3. This can be accomplished by the matrix P^{-1}\n\\begin{align*}\nP^{-1} = \\begin{pmatrix}\n0 & 0 & 1\\\\\n0 & 1 & 0\\\\\n1 & 0 & 0\n\\end{pmatrix}\n\\end{align*}\nAnd then we would want to apply another matrix to generate a pivot in Row 2 (Assuming Row 1 \\not= Row 2). Thus U = L^{-1}P^{-1}A.\n\\begin{align*}\nL^{-1} = \\begin{pmatrix}\n1 & 0 & 0\\\\\n* & 1 & 0\\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\end{align*}\nThrough algebra A = PLU. Now lets use our fact earlier to get (PLP^{-1})PU.\nWe have the following steps in our algorithm\n\nFind A = LPU\nTo find A = PLU, apply LU decomposition to P^TA\n\nFirst, apply lower triangular row operations to have only one non-zero entry in column 1, giving you the first pivot row.\nSecond, apply lower triangular row operations to leave only one non-zero entry in column 2, ignoring the first privot row.\nContinue, arriving at L^{-1}A = PU where L^{-1} is the row operations applied. So taking our old matrix.\n\\begin{align*}\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n* & * & *\n\\end{pmatrix}\n\\end{align*}\nWe can delete the * in the thrid row of column 1 with the matrix\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & * & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n* & * & *\n\\end{pmatrix}\\to\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n0 & * & *\n\\end{pmatrix}\n\\end{align*}\nThis gives us L^{-1}A = PU. But what is P? P is simply the permutation matrix consisting on non-zero entries in the pivot locations.\n\\begin{align*}\nP = \\begin{pmatrix}\n0 & 0 & 1\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\\end{align*}\nNow lets apply LU decomposition to P^TA In order to get the right L and U."
  },
  {
    "objectID": "qmd/matrix/unitthree.html",
    "href": "qmd/matrix/unitthree.html",
    "title": "Unit three",
    "section": "",
    "text": "We have vector spaces\n\n\\mathbb{R}^n \\text{ (scalars are in $\\mathbb{R}$) }\n\n\n\\mathbb{C}^n \\text{ (scalars are in $\\mathbb{C}$) }\n\nAnd subspaces, subsets of \\mathbb{R}^n closed under addition and scalar multiplication.\n\nx_1,x_2 \\in S \\implies c_1x_1 + c_2x_2 \\in S \\quad\\forall c_1,c_2 \\in \\mathbb{R}\n\nFun fact, Ax = b can be solved for x if and only if b \\in \\text{Col}(A), that meaning b is a linear combination of the columns of A."
  },
  {
    "objectID": "qmd/matrix/unitthree.html#vector-spaces-subspaces",
    "href": "qmd/matrix/unitthree.html#vector-spaces-subspaces",
    "title": "Unit three",
    "section": "",
    "text": "We have vector spaces\n\n\\mathbb{R}^n \\text{ (scalars are in $\\mathbb{R}$) }\n\n\n\\mathbb{C}^n \\text{ (scalars are in $\\mathbb{C}$) }\n\nAnd subspaces, subsets of \\mathbb{R}^n closed under addition and scalar multiplication.\n\nx_1,x_2 \\in S \\implies c_1x_1 + c_2x_2 \\in S \\quad\\forall c_1,c_2 \\in \\mathbb{R}\n\nFun fact, Ax = b can be solved for x if and only if b \\in \\text{Col}(A), that meaning b is a linear combination of the columns of A."
  },
  {
    "objectID": "qmd/matrix/unitthree.html#section-3.2",
    "href": "qmd/matrix/unitthree.html#section-3.2",
    "title": "Unit three",
    "section": "Section 3.2",
    "text": "Section 3.2\nLet A of size m \\times n be an arbitrary matrix.\nWe have\n\n\\text{Null}(A) = \\{x \\in \\mathbb{R}^n \\mid Ax = 0\\}\n\nIf \\text{Null}(A) is a subspace of \\mathbb{R}^n, then linearity applies.\nFact. Ax = 0 if and only if x \\perp \\text{RowSp}(A).\nWe say \\text{Null}(A) = \\text{Row}(A)^\\perp. How do we find \\text{Null}(A)? Row operations on A don’t affect the null space.\nA strategy to find the null space on A is to convert A into reduced row echelon form R. The row space remains the same so the null space remains the same. The column spaces however are entirely different.\nConverting to RREF is simple. So I won’t write it down."
  },
  {
    "objectID": "qmd/geometry/geometry.html",
    "href": "qmd/geometry/geometry.html",
    "title": "Geometry",
    "section": "",
    "text": "We have the following identities\n\n\\sin(\\alpha + \\beta) = \\sin(\\alpha)\\cos(\\beta) + \\sin(\\beta)\\cos(\\alpha)\n\n\n\\sin(\\alpha - \\beta) = \\sin(\\alpha)\\cos(\\beta) - \\sin(\\beta)\\cos(\\alpha)\n\n\n\\cos(\\alpha + \\beta) = \\cos(\\alpha)\\cos(\\beta) - \\sin(\\alpha)\\sin(\\beta)\n\n\n\\cos(\\alpha - \\beta) = \\cos(\\alpha)\\cos(\\beta) + \\sin(\\alpha)\\sin(\\beta)\n\n\n\n\n\n\n\nTheorem (De Moivre’s Theorem)\n\n\n\nA complex number raised to an integer power is given by \nZ^n = \\left(r(\\cos\\theta + i\\sin\\theta)\\right)^n= r^n(\\cos n\\theta + i\\sin\\theta)\n\n\n\nSo for example, if we were given the complex number\n\nZ = 2(\\cos\\theta + i \\sin \\theta)\n\nWe could easily compute\n\nZ^2 = 4(\\cos 2\\theta + i \\sin\\theta)\n\n\n\n\n\n\n\nProof\n\n\n\nWe begin a proof by induction. We have our base case\n\nn = 1 \\quad Z^1 = r^1(\\cos 1\\theta + i\\sin\\theta) = Z\n\nAssume the statement holds for k, then\n\\begin{align*}\nZ^{k+1} &= Z^kZ = \\left(r^k(\\cos k\\theta + i\\sin\\theta)\\right)\\left(r(\\cos \\theta + i\\sin\\theta)\\right)\\\\\n&= r^{k+1}\\bigg( \\left( \\cos k \\theta \\cos \\theta - \\sin \\theta \\sin \\theta \\right) + \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad i \\left( \\sin \\theta \\cos \\theta + \\cos k\\theta \\sin \\theta \\right)\\bigg)\\\\\n&= r^{k+1}(\\cos (k+1)\\theta + i\\sin\\theta)\n\\end{align*}"
  },
  {
    "objectID": "qmd/geometry/geometry.html#formal-languages",
    "href": "qmd/geometry/geometry.html#formal-languages",
    "title": "Geometry",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the disctintion is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/geometry/geometry.html#deductive-systems",
    "href": "qmd/geometry/geometry.html#deductive-systems",
    "title": "Geometry",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example1\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/geometry/geometry.html#first-order-logic",
    "href": "qmd/geometry/geometry.html#first-order-logic",
    "title": "Geometry",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part."
  },
  {
    "objectID": "qmd/geometry/geometry.html#footnotes",
    "href": "qmd/geometry/geometry.html#footnotes",
    "title": "Geometry",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis section is copied from Wikipedia almost verbatim.↩︎"
  },
  {
    "objectID": "qmd/todo/todo.html#latin",
    "href": "qmd/todo/todo.html#latin",
    "title": "Todo",
    "section": "Latin",
    "text": "Latin\nM. Tullī Cicerō, quid agis? Istī prō multīs factīs malīs poenās dare nunc dēbent; eōs enim ad mortem dūcere dēbēs, quod Rōmam in multa perīcula trāxērunt. Saepe Rōmānī in hāc cīvitāte etiam cīvēs morte multāvērunt. Sed nōn dēbēs cōgitāre hōs malōs esse cīvēs, nam numquam in hāc urbe prōditōrēs patriae iūra cīvium tenuērunt; hī iūra sua āmīsērunt. Populus Rōmānus tibi magnās grātiās aget, M. Tullī, sī istōs cum virtūte nunc multābis.\nM. Tulli Cicero, what are you doing? Those men now ought to pay for their many evil deeds; you ought to lead them to death, because they dragged rome into multiple troubles. Often the state has punished Roman citizens by death. But you ought to think these evil men citizens, the betrayers of the Fatherland have never been citizens; these men have lost their rights as citizens. The Roman people will give you many great thanks, M. Tulli, if you now punish those men with virtue."
  },
  {
    "objectID": "qmd/measure/porous.html",
    "href": "qmd/measure/porous.html",
    "title": "Porous sets",
    "section": "",
    "text": "There are several ways to define a small set, like Meager and Measure-zero. Porous sets are an alternate way to measure how small a set is."
  },
  {
    "objectID": "qmd/measure/porous.html#definition",
    "href": "qmd/measure/porous.html#definition",
    "title": "Porous sets",
    "section": "Definition",
    "text": "Definition\nA set is porous if every interval I in \\mathbb{R} contains an interval I_2 completly missing the set, such that |I_2| = \\alpha |I| where 0 &lt; \\alpha &lt; 1.\nFormalizing this definition requires a few steps.\n\n\n\n\n\n\nDefinition\n\n\n\nLet E be a set in \\mathbb{R}, and x \\in \\mathbb{R}. The right porosity of E at x is denoted p^+(E,x) and is given by\n\np^+(E,x) = \\limsup_{\\varepsilon \\to 0^+} \\frac{k}{k+h}\n\nwhere (x + h, x + h + k) \\cap E = \\varnothing, h + k &lt; \\varepsilon and h,k &gt; 0, and \\sup refers to the lowest greater bound. Similary, the left porosity of E, denoted p^-(E,x) is defined by (x - h - k, x - h) \\cap E = \\varnothing\nThen the porosity of E at x is defined by\n\np(E,x) = \\max\\{p^-(E,x),p^+(E,x)\\}\n\nIt is clear the value of p is inbetween [0,1]. We say that E is porous at \\bf x if p(E,x) &gt; 0, and that E is porous if p(E,x) &gt; 0 for all x \\in E.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAre the following sets porous at x?\n\nIs the set E = [0,1] porous at x = \\frac{1}{2}?\n\nLet’s start by trying to find the left porosity of E at x. It’s clear that when \\varepsilon &lt; \\frac{1}{2}, no values of h,k satisfy (x + h, x + h + k) \\cap E = \\varnothing, h + k &lt; \\varepsilon. Therefore, the set does not have a defined left porosity. Similary the set does not have a defined right porosity, so the set is not porous at x = \\frac{1}{2}.\n\nIs the set E = C porous at x = \\frac{1}{3}?\n\nIn this case C refers to the Cantor ternary set. At x = \\frac{1}{3}, it is clear that p^+(C,\\frac{1}{3}) = 1, because h can get arbitrarily small while completly avoiding C. Because p^- can’t possibly be greater than 1, p(C,\\frac{1}{3}) = 1, and the Cantor ternary set is porous at x = \\frac{1}{3}."
  },
  {
    "objectID": "qmd/measure/porous.html#beta-porous",
    "href": "qmd/measure/porous.html#beta-porous",
    "title": "Porous sets",
    "section": "Beta-porous",
    "text": "Beta-porous\n\n\n\n\n\n\nDefinition\n\n\n\nLet A \\subseteq \\mathbb{R}, \\beta \\in (0,1). Then A is \\beta-porous iff for every (a,b) \\  in \\mathbb{R}, \\exists(a^\\prime,b^\\prime) \\subseteq (a,b) such that (b^\\prime - a^\\prime) = \\beta(b-a)"
  },
  {
    "objectID": "qmd/measure/porous.html#f-porous",
    "href": "qmd/measure/porous.html#f-porous",
    "title": "Porous sets",
    "section": "f-porous",
    "text": "f-porous\nA set A is f-porous if for some f, there exists an \\varepsilon_n such that for all intervals |J| \\subset |I|, there exists an interval |K| \\subset |J| such that $$\n\n\n\n\n\n\nTheorem\n\n\n\nA set A is f-porous \\forall f iff A is discrete\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf a set is discrete, then we can\nBy way of contradition, assume A is not discrete, and f-porous for every f. Then\n\n\\exists x \\in A \\mid \\forall \\varepsilon &gt; 0,\\quad \\mathcal{B}(x,\\varepsilon) - \\{x\\} \\cap A \\not = \\varnothing\n\nWithout loss of generality, let\n\n\\lvert x - x_{n-1} \\rvert &lt; \\lvert x - {x_n}\\rvert\n\nand\n\n|x_{n-1} - x_n| &lt; \\frac{x_n - x}{2}\n\nFor each n \\in \\mathbb{N}, let f_n be such that\n\nf_n(|x_n - x|) &gt; |x_n - x_{n+1}|\n\nWe choose a random interval x \\in I \\subset \\mathbb{R}, and let \\varepsilon_{I,n} &gt; 0 be this intervals associated epsilon for any f_n.\nLet J \\subset I such that |J| &lt; \\varepsilon_{I,n} and n \\in \\mathbb{N}.\nNeed to show that |x_n - x_{n-1}| &lt; |x_n - x|/2. Can’t prove.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose A is uncountable. Uncountable sets have the property that there exists some point x that is a limit point from both sides, symbollically.\n\n\\exists x \\in A \\mid \\forall \\varepsilon &gt; 0\n\n\n(x-\\varepsilon,x) \\cap A \\not = \\varnothing \\land (x, x + \\varepsilon) \\cap A \\not = \\varnothing\n\nWe can now construct a continually decreasing sequence. Let \\{x_n\\} \\to x. Without loss of generality, let\n\n|x - x_n{+1}| &lt; |x_{n+1} - x_n|\n\nRepeating for y. approaching from the oppsite side.\nLet \\ell n = |x_n - y_n|, c_n = |y_n - y_{n+1}| and m_n = |x_n - x_{n+1}|.\nLet I \\subseteq \\mathbb{R}, x \\in I. For each n \\in \\mathbb{N}, let\n\nf_n = \\mathbb{R}^+ \\to \\mathbb{R}^+ \\mid f_n(\\ell n) &gt; \\max\\{c_n,m_n\\}\n\nAnd let \\varepsilon_{I_n} be the associated value of epsilon. Let J \\subset I and n \\in \\mathbb{N} such that |J| &lt; \\varepsilon_{I,n}.\nLet J be such that x_n,y_n \\in J. Since f_n is a decreasing function,\n\nf_n(|J|) &gt; f_n(\\ell n) &gt; \\max\\{c_n,m_n\\}\n\nBecause either c_n or m_n is the biggest hole in (y_n,x_n), there is clearly no hole bigger than \\max\\{c_n,m_n\\}. Thus a contradiction, and if a set is f-porous for every f, then A is not uncountable."
  },
  {
    "objectID": "qmd/measure/research.html",
    "href": "qmd/measure/research.html",
    "title": "Porous sets",
    "section": "",
    "text": "There are several ways to define a small set, like Meager and Measure-zero. Porous sets are an alternate way to measure how small a set is."
  },
  {
    "objectID": "qmd/measure/research.html#nowhere-dense-sets",
    "href": "qmd/measure/research.html#nowhere-dense-sets",
    "title": "Porous sets",
    "section": "Nowhere dense sets",
    "text": "Nowhere dense sets\n\n\n\n\n\n\nDefinition\n\n\n\nA set A is nowhere dense (nwd) if for every interval I, there exists a subinterval J \\subset I such that\n\nJ \\cap A = \\varnothing\n\n\n\nThus, a set is nowhere dense if the set is full of ‘holes’. Lets look at an example of a nowhere dense set.\n\n\n\n\n\n\nExample\n\n\n\nLets see if the set \\mathbb{Z} is nowhere dense. Take any interval I = (a,b).\n\nIf I \\cap \\mathbb{Z}, then we are done. If I contains any point x \\in \\mathbb{Z}, we can construct subinterval J such that x \\not \\in J.\nThere are a finite amount of integers in any interval I, so this process can be repeated until J \\cap \\mathbb{Z} = \\varnothing.\n\n\nAnd an example of a not-nwd set\n\n\n\n\n\n\nExample\n\n\n\nThe set \\mathbb{Q} is dense in \\mathbb{R}. This means that for any interval I = (a,b), there exists a q \\in \\mathbb{Q} such that q \\in I. This means that every subinterval J will intersect \\mathbb{Q}, and \\mathbb{Q} is not a nowhere dense set."
  },
  {
    "objectID": "qmd/measure/research.html#f-porous-sets",
    "href": "qmd/measure/research.html#f-porous-sets",
    "title": "Porous sets",
    "section": "f-porous sets",
    "text": "f-porous sets\nWe define a set to be f-porous as follows\n\n\n\n\n\n\nDefinition\n\n\n\nLet f \\colon \\mathbb{R}^+ \\to \\mathbb{R}^+ such that f(x) &lt; \\frac{x}{2}.\nA set A is f-porous if and only if \\forall I, \\exists \\varepsilon_I &gt; 0 such that for any\nJ \\subseteq I where |J| &lt; \\varepsilon_I, \\exists K \\subseteq J such that |K| = f(|J|) and\nK \\cap A =\\varnothing.\n\n\nLets take for example the set of all integers \\mathbb{Z} and test if the function is f-porous for\n\nf(x) = \\frac{x}{3}.\n\nFor any interval I = (a,b), there should exists an \\varepsilon_I such that |J| &lt; \\varepsilon_I. We want to choose \\varepsilon_I such that |K| = f(|J|). I’ll choose\n\n\\varepsilon_I = 1.\n\nWe want to show that for any J \\subset I where J &lt; 1, there exists an interval K \\subseteq J such that |K| = f(|J|) and K \\cap A = \\varnothing.\nIf J does not intersect \\mathbb{Z}, we are done. J intersects the set at most once, as |J| &lt; 1 and the elements in \\mathbb{Z} are spaced apart by a length of 1. The intersection point between J and \\mathbb{Z} will be denoted x.\nWe want to find a K \\subseteq J of length |K| = f(|J|) = \\frac{|J|}{3} for every J. We can explicitly construct K by dividing J into three equal subintervals J_1, J_2, J_3 each with length \\frac{|J|}{3}. Because x is the singular intersection point, let K = J_n for whichever J_n \\cap \\mathbb{Z} = \\varnothing.\nThus, we have proved \\mathbb{Z} is f-porous for f(x) = \\frac{x}{3}.\n\n\n\n\n\n\nTheorem\n\n\n\nA set is f-porous if and only if the set is nowhere dense.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf a set A is f-porous for some f, then clearly the set is nowhere dense, as for any interval I, we have some interval K which misses the set.\nThe harder direction is proving that for some nowhere dense A, that A is f-porous. We will need to construct a function f for any arbitrary nowhere dense set.\nTake any interval I = (a,b). Lets divide the interval into three equal subintervals\n\nI_1 = (a,\\frac{b-a}{3})\\quad I_2 = (\\frac{b-a}{3},\\frac{2(b-a)}{3}) \\quad I_3 = (\\frac{2(b-a)}{3},b)\n\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf a set A is f-porous for every f, then A is countable."
  },
  {
    "objectID": "qmd/logic/intro.html#formal-languages",
    "href": "qmd/logic/intro.html#formal-languages",
    "title": "Introduction to Mathematical Logic",
    "section": "Formal languages",
    "text": "Formal languages"
  },
  {
    "objectID": "qmd/logic/intro.html#deductive-systems",
    "href": "qmd/logic/intro.html#deductive-systems",
    "title": "Introduction to Mathematical Logic",
    "section": "Deductive systems",
    "text": "Deductive systems"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-system.html",
    "href": "qmd/logic/formal-systems/formal-system.html",
    "title": "Formal languages",
    "section": "",
    "text": "A formal system consists of a formal language along with a deductive system."
  },
  {
    "objectID": "qmd/logic/formal-systems/deductive-system.html",
    "href": "qmd/logic/formal-systems/deductive-system.html",
    "title": "Deductive systems",
    "section": "",
    "text": "I"
  },
  {
    "objectID": "qmd/logic/formal-systems/deductive-system.html#first-order-languages",
    "href": "qmd/logic/formal-systems/deductive-system.html#first-order-languages",
    "title": "Formal languages",
    "section": "First order languages",
    "text": "First order languages\nFor a more in-depth look at a formal language, lets take a dive into first-order language. I’ll use the slightly obscure notation used in [Ebbinghaus, Flum, Thomas], as I personally feel they take a very formal approach to developing a formal language.\nThe alphabet of a first-order language has the following symbols\n\nConnectives - \\land, \\lor, \\rightarrow, \\leftrightarrow, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3, \\cdots, v_n\nEquality - The equal sign ‘=’\nParentheses - Right ) and left (.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\n\nFor readability sake, parenthesis occur in different sizes, or occasionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nThe first five groups listed are denoted \\mathbb{A}, and S denotes the unique operations, relations, and constants in the language. The set S determines the unique first-order language. We denote the shared alphabet \\mathbb{A}_S = \\mathbb{A} \\cup S.\nNow we can begin constructing the syntax for first-order languages. We start by defining terms\n\n\n\n\n\n\nDefinition\n\n\n\nS-terms are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(T1) Every variable is an S-term.\n(T2) Every constant is an S-term.\n(T3) If f is an operator of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then ft_1,t_2,\\dots,t_n is an S-term.\n\n\nThe set of all S-terms is denoted T^S. Through repeated applications of the three rules above, we can create larger terms. For example\n\\begin{alignat*}{2}\n& c_1 & \\quad &(T2)\\\\\n& v_1    &\\quad &(T1)\\\\\n& gc_1v_1   &\\quad &(T3) \\text{ with $c_1$ and $v_1$ applied to $g$}\n\\end{alignat*}\nSo gc_1v_1 is an S-term. Most of the time this is wrote g(c_1,v_1), but to keep things formal we’ll use the objectively worse notation for now. We will however introduce shorthand later. Now that we have S-terms, we can start creating formulas.\n\n\n\n\n\n\nDefinition\n\n\n\nS-formulas are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(F1) If t_1 and t_2 are S-terms, then t_1 = t_2 is an S-formula.\n(F2) If p is a relation of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then pt_1,t_2,\\dots,t_n is an S-formula.\n(F3) If \\phi is an S-formula, then \\lnot\\phi is also an S-formula.\n(F4) If \\phi and \\psi are S-formulas, then (\\phi \\land \\psi), (\\phi \\lor \\psi), (\\phi \\rightarrow \\psi), (\\phi \\leftrightarrow \\psi) are also S-formulas.\n(F5) If \\phi is an S-formula, and x is a variable, then \\forall x \\phi and \\exists x \\phi are also S-formula.\n\n\nS-formula formed from (F1) or (F2) are known as atomic formula as they don’t use any other formula in their language. Note that an S-formula is simply another word for a wff.\nWe can now introduce some new vocabulary\n\n\n\n\n\n\nDefinition\n\n\n\nGiven the S-formulas (wffs) \\phi, \\psi we have the following vocabulary\n\n\\lnot \\varphi is called the negation of \\phi\n(\\phi \\land \\psi) is called the conjunction of \\phi and \\psi\n(\\phi \\lor \\psi) is called the disjunction of \\phi and \\psi\n(\\phi \\rightarrow \\psi) is called the implication of \\phi and \\psi\n(\\phi \\leftrightarrow \\psi) is called the bi-implication of \\phi and \\psi\n\n\n\nWe denote the set of S-formulas with \\mathcal{L}^S. This set is called the first-order language associated with the symbol set S. And just like that we’ve created a first-order lanaguage! Lot’s of rather tricky notation, but the overall concept is no different than our example in the beginning."
  },
  {
    "objectID": "qmd/logic/formal-systems/deductive-system.html#footnotes",
    "href": "qmd/logic/formal-systems/deductive-system.html#footnotes",
    "title": "Formal languages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis example was given by Noam Chomsky in his thesis The logical structure of linguistic theory↩︎"
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html",
    "title": "Truth and Semantics",
    "section": "",
    "text": "We now know how to create a formal language, and how to create new formulas in said system. However, as of now these formulas are merely strings of symbols with no meaning or truth attached to them. Logic isn’t very useful without truth, so lets establish some way of assigning truth to a formula."
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#first-order-languages",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#first-order-languages",
    "title": "Truth and Semantics",
    "section": "First order languages",
    "text": "First order languages\nFor a more in-depth look at a formal language, lets take a dive into first-order language. I’ll use the slightly obscure notation used in [Ebbinghaus, Flum, Thomas], as I personally feel they take a very formal approach to developing a formal language.\nThe alphabet of a first-order language has the following symbols\n\nConnectives - \\land, \\lor, \\rightarrow, \\leftrightarrow, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3, \\cdots, v_n\nEquality - The equal sign ‘=’\nParentheses - Right ) and left (.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\n\nFor readability sake, parenthesis occur in different sizes, or occasionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nThe first five groups listed are denoted \\mathbb{A}, and S denotes the unique operations, relations, and constants in the language. The set S determines the unique first-order language. We denote the shared alphabet \\mathbb{A}_S = \\mathbb{A} \\cup S.\nNow we can begin constructing the syntax for first-order languages. We start by defining terms\n\n\n\n\n\n\nDefinition\n\n\n\nS-terms are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(T1) Every variable is an S-term.\n(T2) Every constant is an S-term.\n(T3) If f is an operator of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then ft_1,t_2,\\dots,t_n is an S-term.\n\n\nThe set of all S-terms is denoted T^S. Through repeated applications of the three rules above, we can create larger terms. For example\n\\begin{alignat*}{2}\n& c_1 & \\quad &(T2)\\\\\n& v_1    &\\quad &(T1)\\\\\n& gc_1v_1   &\\quad &(T3) \\text{ with $c_1$ and $v_1$ applied to $g$}\n\\end{alignat*}\nSo gc_1v_1 is an S-term. Most of the time this is wrote g(c_1,v_1), but to keep things formal we’ll use the objectively worse notation for now. We will however introduce shorthand later. Now that we have S-terms, we can start creating formulas.\n\n\n\n\n\n\nDefinition\n\n\n\nS-formulas are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(F1) If t_1 and t_2 are S-terms, then t_1 = t_2 is an S-formula.\n(F2) If p is a relation of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then pt_1,t_2,\\dots,t_n is an S-formula.\n(F3) If \\phi is an S-formula, then \\lnot\\phi is also an S-formula.\n(F4) If \\phi and \\psi are S-formulas, then (\\phi \\land \\psi), (\\phi \\lor \\psi), (\\phi \\rightarrow \\psi), (\\phi \\leftrightarrow \\psi) are also S-formulas.\n(F5) If \\phi is an S-formula, and x is a variable, then \\forall x \\phi and \\exists x \\phi are also S-formula.\n\n\nS-formula formed from (F1) or (F2) are known as atomic formula as they don’t use any other formula in their language. Note that an S-formula is simply another word for a wff.\nWe can now introduce some new vocabulary\n\n\n\n\n\n\nDefinition\n\n\n\nGiven the S-formulas (wffs) \\phi, \\psi we have the following vocabulary\n\n\\lnot \\varphi is called the negation of \\phi\n(\\phi \\land \\psi) is called the conjunction of \\phi and \\psi\n(\\phi \\lor \\psi) is called the disjunction of \\phi and \\psi\n(\\phi \\rightarrow \\psi) is called the implication of \\phi and \\psi\n(\\phi \\leftrightarrow \\psi) is called the bi-implication of \\phi and \\psi\n\n\n\nWe denote the set of S-formulas with \\mathcal{L}^S. This set is called the first-order language associated with the symbol set S. And just like that we’ve created a first-order lanaguage! Lot’s of rather tricky notation, but the overall concept is no different than our example in the beginning."
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#footnotes",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#footnotes",
    "title": "Truth and Semantics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis example was given by Noam Chomsky in his thesis The logical structure of linguistic theory↩︎"
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#truth-assignment-in-proposition-logic",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#truth-assignment-in-proposition-logic",
    "title": "Truth and Semantics",
    "section": "Truth Assignment in Proposition logic",
    "text": "Truth Assignment in Proposition logic\nIn order to keep things simple, we’ll be using propositional logic as our example for truth assignment. Proposition logic contains no quantifiers, functions, relations, or equality, so it’ll be simple to work with. Of course a formal definition of propositional logic will be given later, but for now it serves as a simple example for truth.\n\n\n\n\n\n\nDefinition\n\n\n\nA truth value is some value relating to the truth of a statement.\n\n\nMost logic contains only two truth values, truth denoted T or 1, and falsity denoted F or 0. There is however no limit to the amount of truth values one could have.\n\n\n\n\n\n\nDefinition\n\n\n\nA truth assignment is some function v such that for the set of terms T^S\n\nv \\colon T^S \\to \\{T,F\\}\n\n\n\nThus a truth assignment would take every term, and assign the term as either true or false. It is important to note that v only assigns truth to terms. This is to avoid seemingly contradictory statements like\n\nv(p \\land q) = T\\quad v(p) = F,\n\nwhich treats the ‘And’ operator very differently from common expection. The solution to this to define a function \\overline{v}, which operates on the set of wff for a language\n\n\\overline{v} \\colon \\mathcal{L}^S \\to \\{T,F\\},\n\nand assigns the correct truth value to each formula. We define this function such that for any term p, \\overline{v}(p) = v(p). We define our operators using truth tables, which gives the truth value for each operator depending on the truth value of the terms.\n\\begin{array}{|c c c c c c c|}\n% |c c|c| means that there are three columns in the table and\n% a vertical bar ’|’ will be printed on the left and right borders,\n% and between the second and the third columns.\n% The letter ’c’ means the value will be centered within the column,\n% letter ’l’, left-aligned, and ’r’, right-aligned.\np & q & \\lnot p & p \\land q & p \\lor q & p \\rightarrow q & p \\leftrightarrow q\\\\ % Use & to separate the columns\n\\hline % Put a horizontal line between the table header and the rest.\nT & T & F & T & T & T & T\\\\\nT & F & F & F & T & F & F\\\\\nF & T & T & F & T & T & F\\\\\nF & F & T & F & F & T & T\\\\\n\\end{array}\nThis is the standard truth table, used in almost all of classical logic. There exists seperate tables for systems with more than two truth values of course, but you’ll (likely) never see the \\land operator defined differently from the table above.\nOf course this is just how truth is defined in propositional logic. Truth is defined very different in logical systems like intuitionistic logic."
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#semantic-consequence",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#semantic-consequence",
    "title": "Truth and Semantics",
    "section": "Semantic consequence",
    "text": "Semantic consequence\nNow that we have an example of a truth assignment, we can work with more general notions of truth.\n\n\n\n\n\n\nDefinition\n\n\n\nWe say a truth assignment v satisfies \\varphi if and only if \\overline{v}(\\varphi) = T.\n\n\nThis leads to our next definition\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\Gamma and \\varphi be sets of wff. We say \\varphi is a Semantic consequence of \\Gamma if and only if every truth assignment that satisfies \\Gamma also satisfies \\varphi. This is denoted\n\n\\Gamma \\models \\varphi\n\n\n\nThus, this simply means if \\Gamma is true, \\varphi is too. We define a tautology \\tau if\n\n\\models \\tau\n\nMeaning that \\tau is always true regardless of the truth assignment used. An example of a tautology in classic logic is the Law of the excluded middle, denoted\n\nP \\lor \\lnot P\n\nWhich is clearly true for all truth values P in propositional logic. However there are systems like intuitionistic logic where truth is defined in a way rejecting the Law of the excluded middle."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html",
    "title": "Homomorphisms and Isomorphisms",
    "section": "",
    "text": "In this section we define what it means for two groups to be equivalent, i.e. have the same group-theoretic structure."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-homomorphisms",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-homomorphisms",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Properties of homomorphisms",
    "text": "Properties of homomorphisms\nNow we can be to look at some of the properties of homomorphisms.\n\n\n\n\n\n\nProposition 1.2.1\n\n\n\nLet \n(G, \\star) \\quad (H, \\diamond) \\quad (M, \\square).\n\nAlso let\n\nf \\colon G \\rightarrow H,\\quad g \\colon H \\rightarrow M\n\nbe homomorphisms. Then\n\ng \\circ f \\colon G \\rightarrow M\n\nis a homomorphism.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe proof is just a few lines of algebra\n\\begin{align*}\ng(f(x \\star y)) &= g(f(x) \\diamond f(y))\\\\\n&= g(f(x))\\, \\square \\,g(f(y)))\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.2.2\n\n\n\nLet\n\n\\varphi \\colon G \\rightarrow H\n\nbe a homomorphism. Let e_H,e_G be the identity of H and G respectivly. Then\n\n\\varphi(e_G) = e_H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy algebra\n\\begin{align*}\ne_G &= e_Ge_G\\\\\n\\varphi(e_G) = \\varphi&(e_Ge_G) = \\varphi(e_G)\\varphi(e_G)\\\\\n(\\varphi(e_G))^{-1}\\varphi(e_G) &= (\\varphi(e_G))^{-1}\\varphi(e_G)\\varphi(e_G)\\\\\ne_H &= e_H\\varphi(e_G)\\\\\ne_H &= \\varphi(e_G) \\quad\\square\n\\end{align*}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf \\varphi \\colon G \\rightarrow H is an isomorphism, then\n\nThe cardinality of G and H are equivalent\nIf G is abelian, then H is abelian\nFor all x in G, the order of x is the order of \\varphi(x)\n\n\n\nWe will prove the third proposition using the following lemma\n\n\n\n\n\n\nLemma\n\n\n\nLet \\varphi \\colon G \\rightarrow H be a homomorphism. Then\n\n\\varphi(x^n) = \\varphi(x)^n \\quad \\forall n \\in \\mathbb{Z}\n\n\n\nNow the proof of the third proposition\n\n\n\n\n\n\nProof\n\n\n\nWe have three cases for this proposition\nCase 1:\nCase 2:\nSuppose the order |x| = \\infty, |\\phi(x)| = n &lt; \\infty\nNote that \n\\varphi (x^n) = \\varphi (x)^n = e_H\n\nBecause\n\n\\varphi (e_G) = e_H\n\nBy the injective property (which we can use because we have a bijection), we have\n\nx^n = e_G\n\nThus |x| \\leq n &lt; \\infty. Thus |x| and |\\varphi(x)| must either both be finite or infinite.\nCase 3:\nSuppose |x| = n, |\\varphi(x)| = m. Then\n\n\\varphi(x)^n = \\varphi(x^n) = \\varphi(e_G) = e_H \\implies m \\leq n.\n\nSimilarly,\n\n\\varphi (e_G)= e_H = \\varphi (x)^m = \\varphi(x^m) \\implies m \\geq n\n\nThus\n\nm = n\n\n\n\nWe denote an isomorphism \\cong. If there does not exist an isomorphism, we denote \\not \\cong.\nLets take the following groups S_3 and \\mathbb{Z}/6\\mathbb{Z}. There does not exist an isomorphism between these two, as S_3 is abelian, and \\mathbb{Z}/6\\mathbb{Z} is not. Thus\n\nS_3 \\not \\cong \\mathbb{Z}/6\\mathbb{Z}\n\nThere is however, an isomorphism between D_6 and S_3.\nLet\n\nD_6 = \\{r,s \\mid r^3 = s^2 = 1, sr = r^{-1}s\\}\n\nWe can map\n\nS_3 \\rightarrow D_6\n\n\n(1\\,2\\,3) \\rightarrowtail r\n\n\n(1\\,2) \\rightarrowtail s\n\nWhich maps the generators to each other. Thus\n\nD_6 \\cong S_3"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Subgroups",
    "text": "Subgroups\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same notation.\nThis is notated\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLets look at some subgroups\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n(\\mathbb{Q}\\backslash \\{0\\},x) \\leq (\\mathbb{R}\\backslash\\{0\\},x)\n\n\n\nIf G is a group, and H = G, or H = \\{e_G\\}, these are both subgroups of G.\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric. This the relation is not an equivalence relation.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/geometry/geometry.html#trigonmetric-identities",
    "href": "qmd/geometry/geometry.html#trigonmetric-identities",
    "title": "Geometry",
    "section": "",
    "text": "We have the following identities\n\n\\sin(\\alpha + \\beta) = \\sin(\\alpha)\\cos(\\beta) + \\sin(\\beta)\\cos(\\alpha)\n\n\n\\sin(\\alpha - \\beta) = \\sin(\\alpha)\\cos(\\beta) - \\sin(\\beta)\\cos(\\alpha)\n\n\n\\cos(\\alpha + \\beta) = \\cos(\\alpha)\\cos(\\beta) - \\sin(\\alpha)\\sin(\\beta)\n\n\n\\cos(\\alpha - \\beta) = \\cos(\\alpha)\\cos(\\beta) + \\sin(\\alpha)\\sin(\\beta)\n\n\n\n\n\n\n\nTheorem (De Moivre’s Theorem)\n\n\n\nA complex number raised to an integer power is given by \nZ^n = \\left(r(\\cos\\theta + i\\sin\\theta)\\right)^n= r^n(\\cos n\\theta + i\\sin\\theta)\n\n\n\nSo for example, if we were given the complex number\n\nZ = 2(\\cos\\theta + i \\sin \\theta)\n\nWe could easily compute\n\nZ^2 = 4(\\cos 2\\theta + i \\sin\\theta)\n\n\n\n\n\n\n\nProof\n\n\n\nWe begin a proof by induction. We have our base case\n\nn = 1 \\quad Z^1 = r^1(\\cos 1\\theta + i\\sin\\theta) = Z\n\nAssume the statement holds for k, then\n\\begin{align*}\nZ^{k+1} &= Z^kZ = \\left(r^k(\\cos k\\theta + i\\sin\\theta)\\right)\\left(r(\\cos \\theta + i\\sin\\theta)\\right)\\\\\n&= r^{k+1}\\bigg( \\left( \\cos k \\theta \\cos \\theta - \\sin \\theta \\sin \\theta \\right) + \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad i \\left( \\sin \\theta \\cos \\theta + \\cos k\\theta \\sin \\theta \\right)\\bigg)\\\\\n&= r^{k+1}(\\cos (k+1)\\theta + i\\sin\\theta)\n\\end{align*}"
  },
  {
    "objectID": "qmd/geometry/geometry.html#eulers-identity",
    "href": "qmd/geometry/geometry.html#eulers-identity",
    "title": "Geometry",
    "section": "Eulers identity",
    "text": "Eulers identity\nEuler made some crazy identity thingamabob that goes\n\ne^{i\\pi} = -1\n\nWe want to prove this identity. We can start by taylor expanding e, \\cos and \\sin giving\n\ne^x = 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\frac{x^3}{3!} \\cdots\n \n\\cos x = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} \\cdots\n\n\n\\sin x = \\frac{x}{1!} - \\frac{x^3}{3!} + \\frac{x^5}{5!} \\cdots\n\nAllow us to expand e^{xi}, giving\n\ne^{xi} = 1 + \\frac{ix}{1!} - \\frac{x}{2!} - \\frac{ix^3}{3!} + \\frac{x^4}{4!} + \\frac{ix^5}{5!} \\cdots\n\nWhich is clearly\n\ne^{xi} = \\cos x + i\\sin x\n\nThus\n\ne^{\\pi i} = \\cos \\pi + i \\sin \\pi\n\n\ne^{\\pi i} = -1"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#centralizers-normalizers-center",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#centralizers-normalizers-center",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Centralizers, Normalizers, Center",
    "text": "Centralizers, Normalizers, Center\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G.\nThe Centralizer of A in G is a set of elements of G that commute with all elements of A. This is denoted\n\nC_G(A) = \\{g \\in G \\mid gag^{-1} = a, \\; \\forall a \\in A\\}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe centralizer of a subset A of G is a subgroup of G. Symbollically \nC_G(A) \\leq G\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe know\n\ne \\in C_G(A)\n\nThus we can fufill the first property of a subgroup C_G(A) \\not = \\varnothing. Now, let x,y \\in C_G(A). We see\n\ny^{-1}yayy^{-1} = y^{-1}ay\n\n\na = y^{-1}ay = y^{-1}a(y^{-1})^{-1}\n\nThus y^{-1} \\in C_G(A).\nNow we wish to show xy \\in C_G(A)\n\n(xy)a(xy)^{-1} = xyay^{-1}x^{-1}\n\nBecause x,y \\in C_G(A), we have xy \\in C_G(A). Thus\n\nC_G(A) \\leq G\n\n\n\nNext\n\n\n\n\n\n\nDefinition\n\n\n\nThe center of G is denoted\n\nZ(G) = \\{g \\in G \\mid gx = xg,\\, \\forall x \\in G\\}\n\n\n\nThe center of G is the centralizer where A = G. Clearly Then\n\nZ(G) = C_G(G)\n\n\nZ(G) \\leq G\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G, such that g \\in G.\n\ngAg^{-1} = \\{gag^{-1} \\mid a \\in A\\}\n\n\n\nWe use this definition immeditally\n\n\n\n\n\n\nDefinition\n\n\n\nThe normalizer of A in G is denoted\n\nN_G(A) = \\{g \\in G \\mid gAg^{-1} = A\\}\n\n\n\nNote that C_G(A) \\leq N_G(A).\nIf G is abelian, then\n\nZ(G) = G, \\quad C_G(A) = G, \\quad N_G(A) = G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G = D_8, and our subset A = \\{e,r,r^2,r^3\\}.\nWe want to find C_{D_8}\nWe know that A \\subset C_{D_8}(A) because rotations are commutative, that meaning\n\nr^ir^j = r^{i+j} = r^{j+i} = r^jr^i\n\nWe know that sr \\not = rs, so s\\not \\in C_{D_8}(A). We now need to check the remaining elements of D_8, sr,sr^2,sr^3.\nBecause C_{D_8}(A) \\leq D_8 we have\n\nsr^i \\in C_{D_8}(A) \\implies sr^ir^{-1} = s \\in C_{D_8}\n\nWhich is a contradiction, thus\n\nC_{D_8}(A) = A\n\nNow lets find N_{D_8}(A).\nBecause C_{D_8} \\leq N_{D_8}, we know A \\subseteq N_{D_8}(A). We have then\n\nsAs^{-1} = \\{ses^{-1},srs^{-1},sr^2s^{-1},sr^3s^{-1}\\}\n\nTake as a fact r^is = sr^{-1}. Thus\n\nsAs^{-1} = \\{e,r^3,r^2,r\\}\n\nThus s \\in N_{D_8}. We need now check sr^i. Because N_{D_8}(A) \\leq D_8, we have that sr^i is in the normalizer. Thus\n\nN_{D_8}(A) = D_8\n\nWe now wish to find the center of D_8. Since\n\nZ(D_8) \\leq C_{D_8}(A)\n\nWe know that Z(D_8) \\subseteq A.\nWe can check these four elements of A to see if their commutative with everything. We have\n\nrs = sr^{-1} \\not =sr\n\nThus r is not commutative with s, and is not in the center.\n\nr^2s = sr^{-2} = sr^2\n\nSo r^2 commutes with s. Now we check if it commutes with sr^i.\n\nr^2sr^i = sr^{-2}r^i = sr^ir^{-2}\n\nThus our center is \nZ(D_8) = \\{e,r^2\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/matrix/unitthree.html#section-3.4",
    "href": "qmd/matrix/unitthree.html#section-3.4",
    "title": "Unit three",
    "section": "Section 3.4",
    "text": "Section 3.4\nRecall that for vectors v_1,\\cdots,v_n in R^n.\n\n\\text{Span}(\\{v_1,\\ldots,v_n\\}) is the set of all linear combinations of v_1 to v_n.\nv_1,\\ldots,v_n are linearly dependent if \\exists c_1,\\ldots,c_n not all zero such that c_1v_1,\\ldots,c_nv_n = 0.\nIf the vectors are not linearly dependent, then they are linearly independent.\n\n\n\n\n\n\n\nTheorem 3.4.1\n\n\n\nSuppose v_1,\\ldots,v_n are linearly independent in \\mathbb{R}^m and \nw \\in \\mathbb{R}^m, w \\not \\in \\text{Span}(\\{v_1,\\ldots,v_n\\})\n\nThen \\{v_1,\\ldots,v_n,w\\} is linearly independent.\n\n\n\n\n\n\n\n\nProof 3.4.1\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 3.4.2\n\n\n\nSuppose v_1,\\ldots,v_n are linearly dependent in \\mathbb{R}^m. Then for some j\n\n\\text{Span}\\{v_1,\\ldots,v_{j-1},v_{j+1},\\ldots,v_n\\} = \\text{Span}\\{v_1,\\ldots,v_n\\}\n\n\n\n\n\n\n\n\n\nProof 3.4.2\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 3.4.3\n\n\n\nSuppose v_1,\\ldots,v_n are linearly dependent in \\mathbb{R}^m for n&gt;m, then the vectors are linearly dependent.\n\n\n\n\n\n\n\n\nProof 3.4.3\n\n\n\nSet\n\\begin{align*}\nA = \\begin{pmatrix}\n1 & & 1\\\\\nv_1 & \\cdots & v_n\\\\\n1 & & 1\n\\end{pmatrix}\n\\end{align*}\nNote n&gt;m \\implies \\text{Null}(A) \\not = \\varnothing, by row reduction. Thus there exist some Ac = 0, c \\not = 0. So the vectors are linearly dependent\n\n\n\n\n\n\n\n\nDefinition (Basis)\n\n\n\nLet V be a subspace of \\mathbb{R}^m. A basis of V is a linearly independent set of vectors v_1,\\ldots,v_r \\in V such that their span is equal to the span of V.\n\n\n\n\n\n\n\n\nTheorem 3.4.4\n\n\n\n\nAny linearly independent subset of V can be enlarged to a basis.\nAny subset of V which spans V can be shrunk to a basis.\n\n\n\n\n\n\n\n\n\nProof 3.4.4\n\n\n\nSuppose \\{w_i,\\ldots,w_s\\} are linearly independent in V. If their span is V, done. If not, take w_{s+1} in V, not in the span. Then w_i,\\ldots,w_{s+1} is linearly independent. By Fact 3.4.3, this terminates at some r \\leq m.\nGiven a set S of vectors which span V, let T be a subset of S of minimal size which spans V. S is linearly independent.\n\n\n\n\n\n\n\n\nTheorem 3.4.5\n\n\n\nSuppose V is a subspace of \\mathbb{R}^m. Let\n\nu_1,\\ldots,u_p span V\nw_1,\\ldots,u_r are linearly independent in V.\n\nUsing only vectors belonging to u, we can enlarge w to a basis.\n\n\n\n\n\n\n\n\nProof 3.4.5\n\n\n\nIf w spans V, we are done. If not, there exists some u not in \\text{Span}(w). Add u to w, and repeat until w spans V.\n\n\n\n\n\n\n\n\nTheorem 3.4.6\n\n\n\nSuppose V is a subspace of \\mathbb{R}^m, such that w_1,\\ldots,w_r is a basis of V. Suppose we also have u_1,\\ldots,u_p \\in V, p &gt; r. Then u_1,\\ldots,u_p are linearly dependent.\n\n\n\n\n\n\n\n\nProof 3.4.6\n\n\n\nWe want c's in \\mathbb{R}, not all 0, such that u_1c_1 + \\cdots + u_pc_p = 0. Because w is a basis, we have\n\nu_1 = w_1A_{11} + \\cdots + w_r A_{r1}\n \nu_2 = w_1A_{12} + \\cdots + w_r A_{r2}\n\n\n\\vdots\n \nu_p = w_1A_{1p} + \\cdots + w_r A_{rp}\n\nMultipliying each u_i by c_i, we get\n\nu_1c_1 + \\cdots + u_pc_p = w_1(Ac)_1 + \\cdots + w_p(Ac)_p\n\nBecause p &gt; r, we have a non empty null space, thus we prove that the c we want exists.\n\n\n\n\n\n\n\n\nTheorem 3.4.7\n\n\n\nSuppose V is a subspace of \\mathbb{R}^m. All bases of V are the same size, which is called the dimension of V.\n\n\n\n\n\n\n\n\nProof 3.4.7\n\n\n\nSuppose we have two bases w and u of size r and p respecitvly. If r &gt; p, then by fact 3.4.6, w would not be a basis. If p &lt; r, then u would not be a basis. Thus r = p."
  },
  {
    "objectID": "qmd/matrix/unitthree.html#section-3.5",
    "href": "qmd/matrix/unitthree.html#section-3.5",
    "title": "Unit three",
    "section": "Section 3.5",
    "text": "Section 3.5\n\n\n\n\n\n\nTheorem 3.5.1\n\n\n\nLet A be an (m\\times n) matrix. Row operations on A do not change the row space. Thus\n\n\\text{RowSp(EA) = RowSp(A)}\n\nIf E is an invertable matrix. Similarly for column space,\n\n\\text{ColSp(AE) = ColSp(A)}.\n\n\n\n\n\n\n\n\n\nProof 3.5.1\n\n\n\nEach row operation on A merely takes a linear combination of rows and and replaces some row with it. Thus the span of the rows remains the same.\n\n\n\n\n\n\n\n\nTheorem 3.5.2\n\n\n\nLet E be an (m\\times m) invertable matrix, V a subspace of \\mathbb{R}^m. Then EV = \\{Ev \\mid v \\in V\\} is also a subspace, and E maps bases of V to bases of EV.\n\n\n\n\n\n\n\n\nProof 3.5.2\n\n\n\nBecause c_1w_1, + \\cdots + c_rw_r = 0, We have Ew = E0 = 0. Thus Ew is linearly independent and a basis.\n\n\n\n\n\n\n\n\nTheorem 3.5.3\n\n\n\nRow operations do not change the dimension of the column space, nor the span of the column space. The same applies to column operations.\n\n\n\n\n\n\n\n\nProof 3.5.3\n\n\n\nThis immeditally follows from 3.5.2. After applying row operations we are left with EA.\n\n\\text{ColSp}(Ea) = E\\text{ColSp}(A).\n\nThe same applies to column operations.\n\n\n\n\n\n\n\n\nTheorem 3.5.4\n\n\n\nSuppose v_1,\\ldots,v_p in \\mathbb{R}^\\ell have span V.\n\n\n\n\n\n\n\n\nProof 3.5.4\n\n\n\nThis immeditally follows from 3.5.2. After applying row operations we are left with EA.\n\n\\text{ColSp}(Ea) = E\\text{ColSp}(A).\n\nThe same applies to column operations.\n\n\n\n\n\n\n\n\nTheorem 3.5.5\n\n\n\nThe row space and column space of any matrix A have the same dimension\n\n\n\n\n\n\n\n\nProof 3.5.5\n\n\n\nLet A_{m\\times n} be a linear map A \\colon \\mathbb{R^n} \\to \\mathbb{R}^m\nOur null space of A has dimension n - r, while our row space has dimension r. Note that\n\n\\text{Image}(A) = A(\\mathbb{R}^n) = \\text{ColSp}(A)\n\n\n\nNote that\n\n\\text{Rank}(A) = \\text{Rank}(A^T)\n\nThe dimension of our \\text{Null}(A) = n-r, where the basis is our special solutions.\nThe Nullspace matrix of the checkers matrix is\n\nA negated rowspace with the standard basis tacked on."
  },
  {
    "objectID": "qmd/pde/introduction copy.html#laplaces-equation",
    "href": "qmd/pde/introduction copy.html#laplaces-equation",
    "title": "PDE",
    "section": "Laplaces Equation",
    "text": "Laplaces Equation\nGiven the PDE\n\nu_{xx} + u_{yy} = 0\n\nWe rewrite using the \\overline{\\nabla} operator, defined\n\n\\overline{\\nabla} = \\frac{\\partial}{\\partial x}\\hat{i} + \\frac{\\partial}{\\partial y}\\hat{j} + \\frac{\\partial}{\\partial z}\\hat{k}\n\nRecall\n\n\\overline{\\nabla}^2u = 0\n\nWe have from the divergence theorem\n\n-k\\iint\\limits_S \\overline{\\nabla}u \\cdot \\hat{u}\\,dS = -k\\iiint\\limits_V \\overline{\\nabla}u \\, dV"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#example-of-an-ill-posed-problem",
    "href": "qmd/pde/introduction copy.html#example-of-an-ill-posed-problem",
    "title": "PDE",
    "section": "Example of an ill posed problem",
    "text": "Example of an ill posed problem\nIf given a problem like\n\\begin{cases}\n      u_{xx} + u_{yy} = 0 \\\\\n      u(0,y) = u(\\pi,y) = 0 \\\\\n      u(x,0) = 1\\\\\n      \\frac{\\partial x}{\\partial y}(x,0) = 0\n\\end{cases}\nWe see that the fourier series diverges, and there is no solution for y &gt; 0.\nEllipitcal equations need to have boundary conditions upon their boundary, unlike parabloic or hyperbolic equations.\nOccasionally when we have a problem with a shperical boundary like a circle, we will need to set up a boundary problem in polar coordinates."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#interpolation",
    "href": "qmd/numanal/fundementals.html#interpolation",
    "title": "Fundementals",
    "section": "Interpolation",
    "text": "Interpolation\nGiven m points (x_1,y_1) through (x_m,y_m), we want to find a continous function P_{m-1}(x) such that for all i = 1,\\ldots,m\n\nP_{m-1}(x_i) = y_i\n\nWe can find this function through Lagrange interpolation.\nDefine\n\nL_k(x) = \\frac{(x-x_1)(x-x_2)\\cdots(x-x_{k-1})(x-x_{k+1})\\cdots(x-x_m)}{(x_k-x_1)(x_k-x_2)\\cdots(x_k - x_{k-1})(x_k - x_{k+1})\\cdots(x_k - x_m)}\n\nWe can clearly see that\n\nL_k(x_k) = 1,\\quad L_k(x_i) = 0\n\nAnd that L_k is a polynomial of degree m-1. Here we can define\n\nP_{m-1}(x) = y_1L_1(x) + \\cdots + y_mL_m(x)\n\nAs a polynomial of degree \\leq m-1. This is called the Lagrange polynomial. This gives us a function P_{m-1}(x) such that\n\nP_{m-1}(x_i) = y_1L_1(x_i) + \\cdots + y_mL_m(x_i) = y_i\n\nWhich is pretty cool. But even better, this has the special property. Assume there exists some true function f(x) that we are interpolating at a finite amount of points through P_{m-1}(x). Then we have the error\n\ny(x) - P_{m-1}(x) = \\frac{y^{(m)}(c)}{m!}(x-x_1)(x-x_2)\\cdots(x-x_m)\n\nWhere c \\in (x_1,x_m). Note that we can make m as large as we want by adding more points, and due to the m! in the denominator, we can make our P_{m-1}(x) accurate incredibly quickly.\n\n\n\n\n\n\nExample\n\n\n\nInterpolate y(x) = \\sin(x) using interpolation points\n\nx_1 = 0\\; x_2 = \\frac{\\pi}{2} \\; x_3 = \\pi\n\nAnd compute the error.\nWe can see\n\ny_1 = 0 \\; y_2 = 1 \\; y_3 = 0\n\nWe therefore want a polynomial of degree two that interpolates the function.\n\nP_2(x) = y_1L_1 + y_2L_2 + y_3L_3\n\n\nP_2(x) = (0)\\frac{(x-\\pi /2)(x-\\pi)}{(0 - \\pi/2)(0-\\pi)} + (1)\\frac{(x-0)(x-\\pi)}{(\\pi /2 - 0)(\\pi /2 - \\pi)} + (0)\\frac{(x-0)(x- \\pi /2)}{(\\pi - 0) (\\pi - \\pi / 2)}\n\n\nP_2(x) = -x(x-\\pi)\\frac{4}{\\pi^2}\n\nThus we have a function that approximates \\sin(x) using a parabola. Now we need to compute the error.\n\n\\varepsilon = \\frac{f^{(m)}(c)}{m!}(x-x_1)\\cdots(x-x_m)\n\n\n\\varepsilon = \\frac{-\\cos(c)}{6}(x-0)\\left(x-\\frac{\\pi}{2}\\right)(x-\\pi)\n\nTaking the absolute value, and the maximum value of cosine, we get our error \n|\\varepsilon| \\leq \\frac{1}{6}|x\\left(x-\\frac{\\pi}{2}\\right)(x-\\pi)|\n\nWe can find the maximum error taking the derivative of \\varepsilon\n\n\\varepsilon^{\\prime} = 3x^2 + 3\\pi x + \\frac{\\pi^2}{2} = 0\n\nWe get\n\nx_{\\text{max}} = \\frac{-3\\pi \\pm \\pi \\sqrt{3}}{6}\n\n\n\nDefine the function\n\nh(x) = y(x) - P_{m-1}(x) - c(x-x_i)(x-x_2)\\cdots(x-x_m)\n\nThis has the property that for any i \\in 1,\\ldots,m\n\nh(x_i) = 0\n\nWe can choose a constant c such that for any x^* \\in (x_1,x_m)\n\nh(x^*) = 0\n\nThis gives us a function with m+1 zeros, specifically a polynomial of degree m+1. We can use Rolle’s theorem in order to get a function h^\\prime(x) which has m roots. We can repeat this process until h^{(m)}(x) has one zero. That being\n\nh^{(m)}(c) = 0 = y^{(m)}(c) - 0 - C(m!)\n\nThus\n\nC = \\frac{y^{(m)}(c)}{m!}\n\nThat directly leads to our error formula\n\ny(x) - P_{m-1}(x) = \\frac{y^{(m)}(c)}{m!}(x-x_1)(x-x_2)\\cdots(x-x_m)\n\nYou can choose specific x_1,x_2,x_3 in order to make the error as small as possible."
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.2",
    "href": "qmd/matrix/unitfour.html#section-4.2",
    "title": "Unit four",
    "section": "Section 4.2",
    "text": "Section 4.2"
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.4",
    "href": "qmd/matrix/unitfour.html#section-4.4",
    "title": "Unit four",
    "section": "Section 4.4",
    "text": "Section 4.4"
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.5",
    "href": "qmd/matrix/unitfour.html#section-4.5",
    "title": "Unit four",
    "section": "Section 4.5",
    "text": "Section 4.5\nSuppose we have a matrix A_{m,n}. This acts as a function mapping \\mathbb{R}^n to \\mathbb{R}^m.\n\n\n\n\n\n\nFact\n\n\n\nA matrix A maps \\text{RowSp}(A) bijectivly to \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProposition\n\n\n\nSuppose x_1,\\ldots,x_r is a basis of \\text{RowSp}(A). Then Ax_1,\\ldots,Ax_r is a basis of \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose c_1Ax_1,\\ldots,c_rAx_r = 0. then\n\nA(c_1x_1,\\ldots,c_rx_r) = 0\n\nAll c_i must be zero as x_1,\\ldots,x_r is a basis. Thus Ax is independent.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pseudoinverser of A, A^+ is basically\n\nA|_{\\text{RowSp}(A)} \\colon \\text{RowSp}(A) \\to \\text{ColSp}(A)\n\n\n\nNote that when we multiply A^+A, we get an n\\times n matrix. Lets look at what happens to each subspace under A^+A.\nThe Null space disapears, as A maps \\text{NullSp}(A) \\to 0. The row space is restored. Thus we have an interesting map\n\nA^+A|_{\\text{Row(A)}} = P_{\\text{Row}(A)}\n\nWe also have\n\nAA^A|_{\\text{Col(A)}} = P_{\\text{Col}(A)}\n\nSomewhat suprisingly, (A^+)^+ = A. Every subspace of A is the same under A^T and A^+.\n\n\n\n\n\n\nExample\n\n\n\nIf A_{(n\\times n)} is invertible, Then\n\nA^+ = A^{-1}.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 2\\\\\n0 & 0\n\\end{pmatrix}\n\\end{align*}\nThen\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 0\\\\\n\\frac{1}{2} & 0\n\\end{pmatrix}\n\\end{align*}\nNote that\n\\begin{align*}\nAA^+ =\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 0\n\\end{pmatrix}= P_{\\text{Col}(A)}\n\\end{align*}\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\na & 0\\\\\n0 & 0\\\\\n0 & b\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitfour.html",
    "href": "qmd/matrix/unitfour.html",
    "title": "Unit four",
    "section": "",
    "text": "Recall that\n\nv \\perp w \\iff  |v+w|^2 = |v|^2 + |w|^2\n\nWhich only occurs when\n\nv\\cdot w = 0\n\nAs\n\n|v+w|^2 = (v + w) \\cdot (v + w) = v \\cdot v + 2(v\\cdot w) + w\\cdot w\n\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nTake V any subspace of \\mathbb{R}^n. Then\n\nV^\\perp = \\{x \\in \\mathbb{R}^n \\mid x \\cdot v = 0, \\forall v \\in V\\}\n\n\n\nBecause the dot product is linear, we know that V^\\perp is a subspace of \\mathbb{R}^n. For A (m\\times n), \\text{Null}(A) = \\text{RowSp}(A)^\\perp.\nThe dimension of V\\perp is equal to the dimension of n - dim V.\nWe can see this forming\n\\begin{align*}\nA = \\begin{pmatrix}\n& \\cdots & v_1^T\n\\end{pmatrix}\n\\end{align*}\nSuppose that V is a subspace of \\mathbb{R}^\\ell of dimension d.\nIf v_1,\\ldots,v_d are linearly independent in V, then they are a basis of V. If the vectors span V, they also form a basis.\nThis is because any LI subset of V can be enlarged into a basis. Thus the collection of d elements in V clearly forms a basis for V. Replace enlarge with shrink and you have a second proof.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nFor v,w subspaces of \\mathbb{R}^\\ell, V + W is defined to be \\text{Span}(V \\cup W).\n\n\nIf V \\cap W = \\{0\\},then the dimesnions of v + w is the dimesnion of v plus the dimension of w. The union of any two bases is a basis. Thus the set \\{v_1,w_e\\} Spans V + W\nSuppose c_1v_1 \\cdots c_d v_d + b_1 w _ e + \\cdots b_ew_e.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nWhen V \\cup W = 0. we then denote the sum V + W as a direct sum, and use a circle around the plus sign.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nSay that the dimension v = d, and know that V^\\perp has dimension \\ell - d. Thus V \\intersect V^\\perp = \\varnothing.\n\n\nRemember that matrix theory doesn’t work over complex numbers.\nFor problem 14 on the homework, assume that v and w are subspaces of \\mathbb{R}^\\ell. Find the basis of V \\ cap W.\nForm A such that the column space is V + W, and the rank being the dimensoo. We can construct the Nullspace by using a basis. Thus A is a\nWe can take a basis of V \\+ W amd send it to a basis in order to get a result of dimension V W = the dimension of the Null space of A. The rank of V + w + V W = dim V plus dim W,=."
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.1",
    "href": "qmd/matrix/unitfour.html#section-4.1",
    "title": "Unit four",
    "section": "",
    "text": "Recall that\n\nv \\perp w \\iff  |v+w|^2 = |v|^2 + |w|^2\n\nWhich only occurs when\n\nv\\cdot w = 0\n\nAs\n\n|v+w|^2 = (v + w) \\cdot (v + w) = v \\cdot v + 2(v\\cdot w) + w\\cdot w\n\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nTake V any subspace of \\mathbb{R}^n. Then\n\nV^\\perp = \\{x \\in \\mathbb{R}^n \\mid x \\cdot v = 0, \\forall v \\in V\\}\n\n\n\nBecause the dot product is linear, we know that V^\\perp is a subspace of \\mathbb{R}^n. For A (m\\times n), \\text{Null}(A) = \\text{RowSp}(A)^\\perp.\nThe dimension of V\\perp is equal to the dimension of n - dim V.\nWe can see this forming\n\\begin{align*}\nA = \\begin{pmatrix}\n& \\cdots & v_1^T\n\\end{pmatrix}\n\\end{align*}\nSuppose that V is a subspace of \\mathbb{R}^\\ell of dimension d.\nIf v_1,\\ldots,v_d are linearly independent in V, then they are a basis of V. If the vectors span V, they also form a basis.\nThis is because any LI subset of V can be enlarged into a basis. Thus the collection of d elements in V clearly forms a basis for V. Replace enlarge with shrink and you have a second proof.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nFor v,w subspaces of \\mathbb{R}^\\ell, V + W is defined to be \\text{Span}(V \\cup W).\n\n\nIf V \\cap W = \\{0\\},then the dimesnions of v + w is the dimesnion of v plus the dimension of w. The union of any two bases is a basis. Thus the set \\{v_1,w_e\\} Spans V + W\nSuppose c_1v_1 \\cdots c_d v_d + b_1 w _ e + \\cdots b_ew_e.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nWhen V \\cup W = 0. we then denote the sum V + W as a direct sum, and use a circle around the plus sign.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nSay that the dimension v = d, and know that V^\\perp has dimension \\ell - d. Thus V \\intersect V^\\perp = \\varnothing.\n\n\nRemember that matrix theory doesn’t work over complex numbers.\nFor problem 14 on the homework, assume that v and w are subspaces of \\mathbb{R}^\\ell. Find the basis of V \\ cap W.\nForm A such that the column space is V + W, and the rank being the dimensoo. We can construct the Nullspace by using a basis. Thus A is a\nWe can take a basis of V \\+ W amd send it to a basis in order to get a result of dimension V W = the dimension of the Null space of A. The rank of V + w + V W = dim V plus dim W,=."
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.2-projections",
    "href": "qmd/matrix/unitfour.html#section-4.2-projections",
    "title": "Unit four",
    "section": "Section 4.2 Projections",
    "text": "Section 4.2 Projections\nFour subspaces for the rank 1 simple Matrix\n\nA = \\begin{pmatrix}\n1 & 0\\\\\n0 & 0  \n\\end{pmatrix}\n\nA three dimensional shadow can be visualized \nA = \\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 0\n\\end{pmatrix}\n\nThe projection of b onto the line created by the vector a is\n\nP_ab = \\mu a\n\nFor some \\mu. Note that because the perpindicular lines are zero.\n\na \\cdot P_ab = a \\cdot \\mu a\n\nTherefore\n\nP_ab = \\frac{a \\cdot b}{a \\cdot a}a = \\frac{a a^T b}{a^Ta}\n\n\nP_a = \\frac{aa^T}{a^Ta}\n\nLet a = (1,2)\n\nP_a = \\frac{1}{5}\\{\\}\n\nFor homework problems 5,7, if a_1 \\perp a_2, then P_{a_1} + P_{a_2} is equal to the projection of the span. In \\mathbb{R}^3, if you have three orthogonal vectors, then the three projections are equal to the identity matrix."
  },
  {
    "objectID": "qmd/geometry/geometry.html#induction-duction-what-is-your-function",
    "href": "qmd/geometry/geometry.html#induction-duction-what-is-your-function",
    "title": "Geometry",
    "section": "Induction-duction what is your function",
    "text": "Induction-duction what is your function\nWe arrive at the following identites through less than rigourous means (Fishman wrote them on the board)\n\n1 + 2 + 3 + \\cdots + n = \\frac{n}{2}(n+1)\n\n\n1^2 + 2^2 + 3^2 + \\cdots n^2 = \\frac{n}{6}(n+1)(n+2)\n\n\n1^3 + 2^3 + 3^3 + \\cdots n^3 = \\left(\\frac{n}{2}(n+1)\\right)^2\n\nWe prove these using induction. But how do we come up with the formulas?\nThe following telescopic series\n\n\\sum^n_{k=1} k^2 - (k-1)^2 = n^2\n\nNote\n\n\\sum^n_{k=1} k^2 - (k-1)^2 = 2 \\sum^n_{k=1} k - n = n^2\n\nThus\n\n\\sum^n_{k=1} k = \\frac{n}{2}(n+1)\n\nWe can repeat the same thing to get the next identity.\n\n\\sum^n_{k=1} k^3 - (k-1)^3 = n^3\n\n\n\\sum^n_{k=1} k^3 - (k^3 - 3k^2 + 3k - 1)\n\n\n\\sum^n_{k=1} 3k^2 - 3k + 1 = 3\\sum^n_{k=1} k^2 - 3\\sum^n_{k=1} k + n = n^3\n\n\n3\\sum^n_{k=1} k^2 - 3\\sum^n_{k=1} k = n^3 - n\n\n\n3\\sum^n_{k=1} k^2 - 3\\frac{n}{2}(n+1) = n^3 - n\n\n\n\\sum^n_{k=1} k^2 = \\frac{n}{6}(n+1)(n+2)\n\nConsider the interval [a,b]. We say that P_n is a partition of [a,b] if\n\nP_n = \\{x_0,x_1,x_2,\\ldots,x_n\\}\n\nWhere x_0 = a, and x_n = b.\nWe say that P_m is a refinement of P_n if\n\nP_n \\subset P_m\n\nWe also want that if P_1 is a subset of P_2, is a subset of P_3, ect.\nThen the maximum distance between points as n \\to \\infty goes to 0."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups-generated-by-subsets",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups-generated-by-subsets",
    "title": "Homomorphisms and Isomorphisms",
    "section": "2.4 Subgroups generated by subsets",
    "text": "2.4 Subgroups generated by subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im} \\varphi = \\{\\varphi(x) \\mid x \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then the \\ker \\varphi \\leq G and \\text{im} \\leq H.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\phi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#quotient-groups",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#quotient-groups",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Quotient groups",
    "text": "Quotient groups\nAnother way to get a smaller subgroup from a group G is by forming a quotient group.\nSubgroups of H \\leq G are injective onto G.\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism.\nFibers are sets of elements in G that map to single points in H.\nDraw a box and a line???"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/quotient-group.html",
    "href": "qmd/abstract/intro-to-groups/quotient-group.html",
    "title": "Quotient groups",
    "section": "",
    "text": "Definition\n\n\n\nLet \\varphi \\colon G \\to H be a surjective homomorphism with \\ker k. The quotient group G/K is the group whose elements are the fibers of \\varphi with group operation inherited from H.\n\n\nThis definition requires knowing \\varphi explictly. You can however define the group operation on fibers in terms of representatives.\n\n\n\n\n\n\nProposition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with \\ker k. Let X \\in G/K be the fiber above a \\in H. X = \\varphi^{-1}(a). Then for any u \\in X,\n\nX = \\{uk\\mid k \\in K\\}\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet u \\in X, then \\varphi(u) = a. Let\n\nuK = \\{uk \\mid k \\in K\\}\n\nWe want to show that X is equal to uK. We will first show that uK is a subset of X. For k \\in K \n\\varphi(uk) = \\varphi(u)\\varphi(k) = \\varphi(u) = a\n\nThus uK \\subseteq X. Now to show that X \\subseteq uK, let g \\in X and k = u^{-1}g. \n\\varphi(k) = \\varphi(u^{-1})\\varphi(g) = a^{-1}a = e_H\n\nThus k \\in \\ker \\varphi since k = u^{-1}g. Thus X \\subseteq uK\n\n\nThus we can write any elements of the quoitent group as the set uk for all k \\in K.\n\n\n\n\n\n\nDefinition\n\n\n\nFor any N \\leq G and g \\in G,\n\ngN = \\{gn\\mid n \\in N\\}\n\nThis is a (left) coset of N in G.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet \\varphi \\colon G \\to H homomorphism with a kernal K. The set of cosets of K in G with operation uK \\star vK = (uv)K forms a group.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet X,Y \\in G/K, and Z = XY \\in G/K. Then for some a,b \\in H, \nX = \\varphi^{-1}(a)\\: Y = \\varphi^{-1}(b)\n\nThis implies Z = \\varphi^{-1}(ab). Let u,v be representations of X,Y respectivly. We want to show that uv \\in Z. Which is only true If\n\n\\varphi(uv) \\in ab \\leftrightarrow \\varphi(u)\\varphi(v) = ab\n\nWhich is true! Thus by our previous proposition Z = uvK.\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\nTheorem\n\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with Kernal K. Then\n\ngKg^{-1} \\subseteq K \\; \\forall g \\in G\n\n\\varphi(gkg^{-1}) = e\n\n\nIf we have a subgroup N of $G such that gNg^{-1} \\subseteq N for all g \\in G, then multiplication in G/N is well defined.\n\n\n\n\n\n\nTheorem\n\n\n\nG/N \\times G/N \\rightarrow G/N\n (xN, xG)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf x_1N = x_2N, y_1N=y_2N then x_1^{-1}x_2 \\in N and y_1^{-1}y_2 \\in N"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#wave-function",
    "href": "qmd/pde/introduction copy.html#wave-function",
    "title": "PDE",
    "section": "Wave function",
    "text": "Wave function\nThe general solution for a wave equation is in the form\n\nu(x,t) = \\frac{f(x+ct)+f(x-ct)}{2} + \\frac{1}{2c}\\int_{x-ct}^{x+ct}g(s)ds\n\nWhen given a wave function in the form\n\\begin{cases}\n      u_{tt} = c^2u_{xx}\\\\\n      u(x,0) = f(x) \\\\\n      u_t(x,0) = g(x)\\\\\n      u(0,t) = 0\n\\end{cases}\nWe can invent a function f(x) such that f(x) is odd, forcing the solution to be zero. For example\n\\begin{cases}\n      u_{tt} = c^2u_{xx}\\\\\n      u(x,0) = x^2\\\\\n      u_t(x,0) = 0\\\\\n      u(0,t) = 0\n\\end{cases}\nClearly in this case the function x^2 is even. Because we are restricted to the positive realm, we can write f(x) = x|x|, which perfectly models x^2 when x&gt;0, but is an odd function. Thus we can easily find the solution.\n\n\n\n\n\n\nExample\n\n\n\nGiven the following, solve for x \\geq 0, t &gt; 0\n\\begin{cases}\n      u_{tt} = c^2u_{xx}\\\\\n      u(x,0) = e^{-x}\\\\\n      u_t(x,0) = \\sin(x)\\\\\n      u(0,t) = 0\n\\end{cases}\nNote that \\sin(x) is already odd, and we can convert e^{-x} to be odd using \\frac{x}{|x|}e^{-|x|}"
  },
  {
    "objectID": "qmd/numanal/fundementals.html#error",
    "href": "qmd/numanal/fundementals.html#error",
    "title": "Fundementals",
    "section": "Error",
    "text": "Error\nSuppose that we have an error\n\n\\varepsilon = \\frac{h^3}{4}f^{(4)}(c_1) + \\frac{h^3}{8}f^{\\prime\\prime}(c_2)\n\nWe have a simplified expression\n\n\\varepsilon = h^3(\\frac{1}{4}+\\frac{1}{8})f^{\\prime\\prime}(c)\n\nFor some c."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#multi-panel-integration-formula",
    "href": "qmd/numanal/fundementals.html#multi-panel-integration-formula",
    "title": "Fundementals",
    "section": "Multi-panel integration formula",
    "text": "Multi-panel integration formula\n\n\\int\\limits^b_a f(s) ds = \\int\\limits^{a+h}_a f(s) ds + \\int\\limits^{a+2h}_{a+h} f(s) ds \\cdots \\int\\limits^{b}_{b-h} f(s) ds\n\nUsing the formula from last class, this is equal too\n\n\\int\\limits_a^{a+h}f(s)ds = \\frac{h}{2}(f(a)+f(a+h))-\\frac{h^3}{12}\nf^{\\prime\\prime}(c_1)\n\nExpanding our initial integral, we can see it’s telescoping. This gives\n\n\\int\\limits^b_a f(s) ds = \\frac{h}{2}\\left(f(a)+2f(a+h)\\cdots2f(b-h) + f(b)\\right) - \\varepsilon\n\n\n\\varepsilon = \\frac{h^3}{12}(f^{\\prime\\prime}(c_1)\\cdots f^{\\prime\\prime}(c_m))\n\nUsing the generalized intermediate value theorem, we can simplify\n\n\\varepsilon= \\frac{h^3}{12}mf^{\\prime\\prime}(c) = \\frac{(a-b)h^2}{12}f^{\\prime\\prime}(c)\n\nWhich gives us an error for the trapezoidal formula.\nfor what m is the error less than 10^{-6}/"
  },
  {
    "objectID": "qmd/numanal/fundementals.html#simpson-integration",
    "href": "qmd/numanal/fundementals.html#simpson-integration",
    "title": "Fundementals",
    "section": "Simpson integration",
    "text": "Simpson integration\n\n\\mathrlap{\\int\\limits_x^{x+2h}}\\quad\\quad f(s) \\,ds = \\frac{h^3}{3}(f(x) + 4f(x+h) + f(x+2h)) - \\frac{h^5}{90}f^{(4)}(c)"
  },
  {
    "objectID": "qmd/matrix/unitfive.html",
    "href": "qmd/matrix/unitfive.html",
    "title": "Unit four",
    "section": "",
    "text": "Suppose we have a matrix A_{m,n}. This acts as a function mapping \\mathbb{R}^n to \\mathbb{R}^m.\n\n\n\n\n\n\nFact\n\n\n\nA matrix A maps \\text{RowSp}(A) bijectivly to \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProposition\n\n\n\nSuppose x_1,\\ldots,x_r is a basis of \\text{RowSp}(A). Then Ax_1,\\ldots,Ax_r is a basis of \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose c_1Ax_1,\\ldots,c_rAx_r = 0. then\n\nA(c_1x_1,\\ldots,c_rx_r) = 0\n\nAll c_i must be zero as x_1,\\ldots,x_r is a basis. Thus Ax is independent.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pseudoinverser of A, A^+ is basically\n\nA|_{\\text{RowSp}(A)} \\colon \\text{RowSp}(A) \\to \\text{ColSp}(A)\n\n\n\nNote that when we multiply A^+A, we get an n\\times n matrix. Lets look at what happens to each subspace under A^+A.\nThe Null space disapears, as A maps \\text{NullSp}(A) \\to 0. The row space is restored. Thus we have an interesting map\n\nA^+A|_{\\text{Row(A)}} = P_{\\text{Row}(A)}\n\nWe also have\n\nAA^A|_{\\text{Col(A)}} = P_{\\text{Col}(A)}\n\nSomewhat suprisingly, (A^+)^+ = A. Every subspace of A is the same under A^T and A^+.\n\n\n\n\n\n\nExample\n\n\n\nIf A_{(n\\times n)} is invertible, Then\n\nA^+ = A^{-1}.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 2\\\\\n0 & 0\n\\end{pmatrix}\n\\end{align*}\nThen\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 0\\\\\n\\frac{1}{2} & 0\n\\end{pmatrix}\n\\end{align*}\nNote that\n\\begin{align*}\nAA^+ =\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 0\n\\end{pmatrix}= P_{\\text{Col}(A)}\n\\end{align*}\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\na & 0\\\\\n0 & 0\\\\\n0 & b\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitfive.html#section-4.5",
    "href": "qmd/matrix/unitfive.html#section-4.5",
    "title": "Unit four",
    "section": "",
    "text": "Suppose we have a matrix A_{m,n}. This acts as a function mapping \\mathbb{R}^n to \\mathbb{R}^m.\n\n\n\n\n\n\nFact\n\n\n\nA matrix A maps \\text{RowSp}(A) bijectivly to \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProposition\n\n\n\nSuppose x_1,\\ldots,x_r is a basis of \\text{RowSp}(A). Then Ax_1,\\ldots,Ax_r is a basis of \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose c_1Ax_1,\\ldots,c_rAx_r = 0. then\n\nA(c_1x_1,\\ldots,c_rx_r) = 0\n\nAll c_i must be zero as x_1,\\ldots,x_r is a basis. Thus Ax is independent.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pseudoinverser of A, A^+ is basically\n\nA|_{\\text{RowSp}(A)} \\colon \\text{RowSp}(A) \\to \\text{ColSp}(A)\n\n\n\nNote that when we multiply A^+A, we get an n\\times n matrix. Lets look at what happens to each subspace under A^+A.\nThe Null space disapears, as A maps \\text{NullSp}(A) \\to 0. The row space is restored. Thus we have an interesting map\n\nA^+A|_{\\text{Row(A)}} = P_{\\text{Row}(A)}\n\nWe also have\n\nAA^A|_{\\text{Col(A)}} = P_{\\text{Col}(A)}\n\nSomewhat suprisingly, (A^+)^+ = A. Every subspace of A is the same under A^T and A^+.\n\n\n\n\n\n\nExample\n\n\n\nIf A_{(n\\times n)} is invertible, Then\n\nA^+ = A^{-1}.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 2\\\\\n0 & 0\n\\end{pmatrix}\n\\end{align*}\nThen\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 0\\\\\n\\frac{1}{2} & 0\n\\end{pmatrix}\n\\end{align*}\nNote that\n\\begin{align*}\nAA^+ =\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 0\n\\end{pmatrix}= P_{\\text{Col}(A)}\n\\end{align*}\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\na & 0\\\\\n0 & 0\\\\\n0 & b\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitfive.html#section-5.1",
    "href": "qmd/matrix/unitfive.html#section-5.1",
    "title": "Unit four",
    "section": "Section 5.1",
    "text": "Section 5.1\nPermutations matrices are matrices with the same columns as I. For an n\\times n permutation matrix, there exists n! permutation matrices.\nHalf of these matrices are even. Meaning we can get to P via an even number of row exchanges on I. Half are odd.\n\n\n\n\n\n\nDefinition\n\n\n\nWe will define the operation \\text{Prod}(A\\colon P) as the product of all entries of A matching a non zero entry of P.\n\n\nThus we define the determinate \\det A as\n\n\\det A = \\sum\\limits_{\\text{Even perms }P} \\text{Prod}(A\\colon P) - \\sum\\limits_{\\text{Odd perms }P} \\text{Prod}(A\\colon P)\n\nThis is actually just the cofactor expansion formula wrote in a different way. If you multiply a single row of A by a constant \\mu, then your determinate gets multiplied by \\mu. If you exchange two rows of A, multiply the determinate by negative 1.\nAnd if you add a row to another, the determinate has no change. The determinate of A^T is equal to the determinate of A. This is all the same for rows and columnss.\nIf A is upper triangular, then \\text{Prod}(A\\colon P) = 0 if P \\not = I. Thus \\det A = \\text{Prod}(A \\colon I) = \\Pi of the diagonal entries.\nThe determinate of A is equal to\n\n\\det A = (-1)^{\\# \\text{ of row exhchanges}} \\cdot \\text{Product of pivots}\n\n\n\n\n\n\n\nCorollary\n\n\n\n\n\\det A \\not = 0\n\nIf and only if A is invertible\n\n\n\n\n\n\n\n\nTheorem\n\n\n\n\n\\det ZA = \\det Z \\det A\n\n\n\nThus the determinate of ZA is simply the product of the operations of Z on A."
  },
  {
    "objectID": "qmd/abstract/Problems.html",
    "href": "qmd/abstract/Problems.html",
    "title": "Problems",
    "section": "",
    "text": "Problem 1\nIs the function f \\colon \\mathbb{N} \\to \\mathbb{N}, f(x) = x + 1 surjective?\nYes, let n = x + 1.\n\n\nProblem 2\nLet G be a finite group such that the order of G is equal to n &gt; 2. Prove G cannot have a subgroup H of order n - 1.\nThis can proved using Lagranges theorem. Towards a contradiction, assume there exists a subgroup H or G with order n-1. By lagranges theorem, the order of H must divide the order of G. This means\n\n\\exists n \\in \\mathbb{N}, n &gt; 2, \\; n - 1 \\mid n\n\nWhich is a contradiction.\n\n\nProblem 3\nLet n \\geq 3. Prove D_{2n} has a normal subgroup \\left&lt;r\\right&gt;.\n\n\nProblem 5\nLet [42] \\in \\mathbb{Z}/180\\mathbb{Z}. Find |[42]|.\nBecause \\gcd(42,180) = 6, and |x| = \\frac{n}{\\gcd(x,n)}. Thus |[42]| = 30.\n\n\nProblem 10\nLet GL_n(R) be the group of (n\\times n) matrices with non-zero determinates. Let SL_n(R) be the group of (n \\times n) matrices with determinate 1. Prove that SL_N(R) \\leq GL_n(R)\nNote that SL_n(R) is a subset of GL_n(R), because for every A \\in SL_n(R), \\det(A) = 1 \\not = 0, thus A \\in GL_n(R). We know SL_n(R) is not empty as the (n \\times n) identity matrix has determinate 1.\nLet A,B \\in SL_n(R). Note that AB^{-1} has determinate 1. through algebra\n\n\\det(AB^{-1}) = \\det(A)\\det(B^{-1}) = 1 \\not = 0\n\nThus AB^{-1} \\in SL_n(R). Thus by subgroup criterian, we have shown SL_n(R) \\leq GL_n(R).\nNote that SL_n \\trianglelefteq GL_n(R). To see this, take L \\in Ln(R) with \\det(L) = x. Thus for any \\mathcal{o} \\in SL_n(R),\n\n\n\\det(LoL^{-1}) = \\det(L)\\det(o)\\det(L^{-1}) = 1.\n\n\n\nProblem 11\nGiven cycles\n\n\\sigma = (1523)(47)\n\n\n\\tau = (183462)((57))\n\nWe compute\n\n\\sigma\\tau = (18)(2543657)\n\nAnd the orders of \\sigma and \\tau as the lcm of the cycle lengths.\n\n\nProblem 12\nLet G be a group with a,b,c \\in G and a unique x such that axb = c.\nWe can prove x exists, because a^{-1},b^{-1} \\in G, and thus\n\nx = a^{-1}cb^{-1}.\n\nSuppose there exists two solutions x_1,x_2.\n\n\nProblem 13\nLet A be an abelian group, and B be a subgroup of A. Then A/B is also abelian.\nLet a_n \\in A, b_n \\in B, and n \\in \\mathbb{N}. Because were constructing a set A/B, we know that\n\naBa^{-1} \\subseteq B\n\nFor any b \\in B. Thus B can be though of as \\ker(\\phi) where\n\n\\phi \\colon A \\to A/B\n\nThus A/B is the group containing the fibers of \\phi. The fibers of \\phi will be denoted with x_n \\in A/B.\nEach x_n is related to a single a_n, so\n\na_1 \\star a_2 = a_2 \\star a_1 \\implies x_1 \\star x_2 = x_2 \\star x_1\n\n\n\nProblem 15\nProve the identity element e of a group is unique.\nTowards a contradiction, let G be a group with two identity elements e_1, and e_2.\n\n\nProblem 18\nLet G be a group with identity e. Suppose that the order of G is equal to n. Prove x^n = e."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html#groups",
    "href": "qmd/abstract/intro-to-groups/axioms.html#groups",
    "title": "Definitions and basic properties",
    "section": "Groups",
    "text": "Groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group is an ordered pair (G,\\star) where G is a set and \\star is an associative binary relation on that set, such that\n\nThere exists an element e in G known as the identity such that for all a \\in G,\n\n\na \\star e = e \\star a = a\n\n\nFor each a \\in G, there exists an element a^{-1} \\in G called the inverse of a, such that\n\n\na \\star a^{-1} = a^{-1} \\star a = e\n\n\n\nWe call a group abelian if the binary operation \\star is commutative on G.\n\n\n\n\n\n\nExample\n\n\n\nIs the ordered pair (\\mathbb{Z},+) a group?\nWe know the addition operator is associative, so we just need to prove that there exists an identity element in G, and an inverse element for each a \\in \\mathbb{Z}.\n\nThe element 0 is the identity of (\\mathbb{Z},+), as for every a \\in \\mathbb{Z}\n\n\na + 0 = 0 + a = a\n\n\nFor each a \\in G, a^{-1} = -a, because\n\n\na + (-a) = (-a) + a = 0\n\nTherefore (\\mathbb{Z},+) is a group.\n\n\nGroups have the following properties\n\n\n\n\n\n\nProposition 1.1\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n(1) The identity element e of G is unique.\n(2) For each a \\in G, there exist a unique a^{-1}.\n(3) (a^{-1})^{-1} = a for all a \\in G.\n(4) (a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Suppose there exists two identity elements e_1 and e_2. By the definition of an identity element, e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n(2) Suppose b and c are both inverses of a and let e be the identity of G. By the definition of an inverse element a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b\n\n(3) Rather straightforwardly a \\star a^{-1} = a^{-1} \\star a = e. So by the definition of an inverse element, (a^{-1})^{-1} = a.\n(4) Let c = (a \\star b)^{-1}. Therefore (a \\star b) \\star c = e. Using algebra\n\\begin{align*}\n\na^{-1} \\star (a \\star b) \\star c &= a^{-1} \\star e\\\\\n(a^{-1} \\star a) \\star (b \\star c) &= a^{-1}\\\\\n(b \\star c) &= a^{-1}\\\\\nc &= b^{-1} \\star a^{-1}\n\\end{align*}\n\n\n\nNext\n\n\n\n\n\n\nProposition\n\n\n\nLet G be a group under an binary operation \\star, and a,b \\in G. The equations a \\star x = b and y \\star a = b have unique solutions for all x,y \\in G. In particular\n(1) If a \\star u = a \\star v then u = v\n(2) If u \\star b = v \\star b then u = v\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) The existence of a solution to a \\star x = b is given by x = a^{-1} \\star b. This is unique as proved in the previous proposition.\n(2) The proof is nearly identical for (y \\star a) = b, where y = b \\star a^{-1}."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html#binary-operations",
    "href": "qmd/abstract/intro-to-groups/axioms.html#binary-operations",
    "title": "Definitions and basic properties",
    "section": "Binary operations",
    "text": "Binary operations\nWe start by examining binary operations\n\n\n\n\n\n\nDefinition\n\n\n\nA binary operation \\star on a set G is a function \\star \\colon G \\to G.\n\n\nWe commonly denote \\star(a,b) as a \\star b. Binary operations may have the following two properties\n\nA binary relation is associative on a set G if for all a,b \\in G\n\n\n(a \\star b) \\star c = a \\star (b \\star c)\n\n\nA binary operation is commutative on a set G if for all a,b \\in G,\n\n\na \\star b = b \\star a\n\nAddition is an example of an associative and commutative binary operation on \\mathbb{Z}. Multiplication is also an associative and commutative binary operation, whereas something like subtraction is neither associative nor commutative."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html",
    "href": "qmd/abstract/intro-to-groups/definitions.html",
    "title": "Definitions and basic properties",
    "section": "",
    "text": "This section examines the definitions and important properties of groups."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html#binary-operations",
    "href": "qmd/abstract/intro-to-groups/definitions.html#binary-operations",
    "title": "Definitions and basic properties",
    "section": "Binary operations",
    "text": "Binary operations\nWe start by examining binary operations\n\n\n\n\n\n\nDefinition\n\n\n\nA binary operation \\star on a set G is a function \\star \\colon G \\times G \\to G.\n\n\nWe commonly denote \\star(a,b) as a \\star b. Binary operations may have the following two properties\n\nA binary relation is associative on a set G if for all a,b \\in G\n\n\n(a \\star b) \\star c = a \\star (b \\star c)\n\n\nA binary operation is commutative on a set G if for all a,b{\\;\\in\\;}G,\n\n\na \\star b = b \\star a\n\nAddition is an example of an associative and commutative binary operation on \\mathbb{Z}. Multiplication is also an associative and commutative binary operation, whereas something like subtraction is neither associative nor commutative."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html#groups",
    "href": "qmd/abstract/intro-to-groups/definitions.html#groups",
    "title": "Definitions and basic properties",
    "section": "Groups",
    "text": "Groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group is an ordered pair (G,\\star) where G is a set and \\star is an associative binary relation on that set, such that\n\nThere exists an element e in G known as the identity such that for all a \\in G,\n\n\na \\star e = e \\star a = a\n\n\nFor each a \\in G, there exists an element a^{-1} \\in G called the inverse of a, such that\n\n\na \\star a^{-1} = a^{-1} \\star a = e\n\n\n\nWe call a group abelian if the binary operation \\star is commutative on G.\n\n\n\n\n\n\nExample\n\n\n\nIs the ordered pair (\\mathbb{Z},+) a group?\nWe know the addition operator is associative, so we just need to prove that there exists an identity element in G, and an inverse element for each a \\in \\mathbb{Z}.\n\nThe element 0 is the identity of (\\mathbb{Z},+), as for every a \\in \\mathbb{Z}\n\n\na + 0 = 0 + a = a\n\n\nFor each a \\in G, a^{-1} = -a, because\n\n\na + (-a) = (-a) + a = 0\n\nTherefore (\\mathbb{Z},+) is a group.\n\n\nGroups have the following properties\n\n\n\n\n\n\nProposition 1.1.1\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n(1) The identity element e of G is unique.\n(2) For each a \\in G, there exist a unique a^{-1}.\n(3) (a^{-1})^{-1} = a for all a \\in G.\n(4) (a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Suppose there exists two identity elements e_1 and e_2. By the definition of an identity element, e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n(2) Suppose b and c are both inverses of a and let e be the identity of G. By the definition of an inverse element a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b\n\n(3) Rather straightforwardly a \\star a^{-1} = a^{-1} \\star a = e. So by the definition of an inverse element, (a^{-1})^{-1} = a.\n(4) Let c = (a \\star b)^{-1}. Therefore (a \\star b) \\star c = e. Using algebra\n\\begin{align*}\na^{-1} \\star (a \\star b) \\star c &= a^{-1} \\star e\\\\\n(a^{-1} \\star a) \\star (b \\star c) &= a^{-1}\\\\\n(b \\star c) &= a^{-1}\\\\\nc &= b^{-1} \\star a^{-1}\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.1.2\n\n\n\nLet G be a group under an binary operation \\star, and a,b \\in G. The equations a \\star x = b and y \\star a = b have unique solutions for all x,y \\in G. In particular\n(1) If a \\star u = a \\star v then u = v\n(2) If u \\star b = v \\star b then u = v\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) The existence of a solution to a \\star x = b is given by x = a^{-1} \\star b. This is unique as proved in the previous proposition.\n(2) The proof is nearly identical for (y \\star a) = b, where y = b \\star a^{-1}.\n\n\n\nBecause it is often tedious to write the full notation of a group, it is often abbreviated. For example, the group (G,\\star) is commonly wrote as “the group G” where the operation is implied.\nAdditionally, we often write ab as an abbreviation for a \\star b. Because group operations are associative, we write a^n to abbreviate a\\star \\cdots \\star a (n times)."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html#order",
    "href": "qmd/abstract/intro-to-groups/definitions.html#order",
    "title": "Definitions and basic properties",
    "section": "Order",
    "text": "Order\nAs always, we start with a definition.\n\n\n\n\n\n\nDefinition\n\n\n\nFor a group G and x \\in G, the order of x is the smallest positive integer n such that x \\star x \\star \\cdots \\star x (n times) is equal to the identity element e.\n\n\nNote that we notate x \\star x \\star x \\cdots as x^n. We also denote the order of x as |x|. This is an abuse of notation with both cardinailty and absolute value. So that sucks.\nFor any group G, it’s clear that |e| = 1. If x^n \\not = e for any n, we say that x has order infinity. For example, given the group (\\mathbb{Z}/15\\mathbb{Z},\\times), the element 2 has an order of 4.\n\n2 = 2,\\quad 2^2 = 4,\\quad 2^3 = 8,\\quad 2^4 = 16 = 1 = e"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html",
    "title": "Symmetric Groups",
    "section": "",
    "text": "Symmetric groups are groups based on symmetries of certain mathematical objects and structures."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html#dihedral-groups",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html#dihedral-groups",
    "title": "Symmetric Groups",
    "section": "Dihedral groups",
    "text": "Dihedral groups\nAn important example of a group comes from symmetries of geometric objects, most notably, polygons.\nLets take a hexagon, and apply an operation s, which reflects it along a line of symmetry. We could also apply an operation r, which rotates the hexagon by \\pi / 3 radians. These operations swap the location of the vertices of the hexagon.\n\n\n\n\n\n\n(Insert picture of a hexagon being rotated and symetry)\n\n\n\n\n\nIf we represent the orignal labelling of the vertices as\n\n\\{1,2,3,4,5,6\\}\n\nThen we can represent our operations r and s as the permutations\n\nr = \\{2,3,4,5,6,1\\} \\quad s = \\{1,6,5,4,3,2\\}\n\n\n\n\n\n\n\nDefinition\n\n\n\nA symmetry is a reordering of the vertices on a geometric shape such that their structure remains. We typically denote a symmetry with \\sigma.\n\n\nFor polygons in 2-space, we say that the ‘structure’ of the polygon remains if it can be transferred to 3-space, rotated, and then placed back into 2-space.\nThus our operations r and s are symmetries of the polygon. They can be combined to produce additional symmetries. The set of all possible symmetries on a n-polygon is denoted D_{2n}.\n\n\n\n\n\n\nDefinition\n\n\n\nThe set of symmetries on an n-polygon is denoted D_{2n}, and called the dihedral group of order 2n.\n\n\nWe will prove that D_{2n} is indeed a group later, but for now it can be taken as fact. D_{2n} has 2n symmetries, all of which can be constructed via compositions of our symmetries r and s.\n\n\n\n\n\n\nExample\n\n\n\nLets examine the group D_{12}, the symmetries of a hexagon.\nFirst lets look at our possible rotations r. Let e be the orignal labelling of the vertices, and r be defined\n\nr \\colon \\{1,2,3,4,5,6\\} \\to \\{2,3,4,5,6,1\\}\n\nWe can repeatedly compose r to construct the following symmetries\n\ne, r, r^2, r^3, r^4, r^5.\n\nNote that r^6 = r^0 = e, thus |r| = 6.\nNext we can look at our reflections. Let s be defined\n\ns \\colon \\{1,2,3,4,5,6\\} \\to \\{1,6,5,4,3,2\\}\n\nNote that s^2 = e. Combining s and r, we can create \ns, sr, sr^2, sr^3, sr^5, sr^6\n\nGiving us six new symmetries. This gives us a total of 12 symmmetries in D_{12}.\n\n\nIt should be noted that D_{12} is not abelian, which can be clearly be seen with\n\nrs = \\{6,5,4,3,2,1\\} = sr^5 \\quad sr = \\{2,1,6,5,4,3\\}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html#cyclic-groups",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html#cyclic-groups",
    "title": "Symmetric Groups",
    "section": "Cyclic groups",
    "text": "Cyclic groups\n\n\n\n\n\n\nDefinition\n\n\n\nA cyclic group"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html#symmetric-groups",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html#symmetric-groups",
    "title": "Symmetric Groups",
    "section": "Symmetric Groups",
    "text": "Symmetric Groups\nLets define a new symmetric group \\Omega.\n\n\n\n\n\n\nDefinition\n\n\n\nWe define a set \\Omega by the following rules\nLet \\Omega \\not = \\varnothing.\nLet S_\\Omega be the set of all bijections from \\Omega \\to \\Omega, called a permutation.\nLet \\sigma,\\tau be permutations of \\Omega.\n\n\nThis gives \\Omega, and more precisly S_\\Omega some interesting properties.\n\nThe identity of S_\\Omega is the permutation 1 where 1(a) = a\\, \\forall a \\in \\Omega.\nSince function composition is associative, the operation is associative.\nEvery permutation has an inverse since it’s a bijection. Take \\sigma\\colon \\Omega \\to \\Omega, then \\sigma^{-1} \\colon \\Omega \\to \\Omega and \\sigma \\circ \\sigma^{-1} = 1\n\nTherefore, (S_\\Omega, \\circ) is a group and its called the symmetric group on \\Omega. Usually we take \\Omega as the first n natural numbers.\n\n\n\n\n\n\nExample\n\n\n\nLets examine \\Omega = \\{1,2,3\\}.\nWe have \\sigma \\in S_3, which we define by\n\n\\sigma \\colon \\{1,2,3\\} \\to \\{2,3,1\\}.\n\nThis is represented in shorthand by\n\n\\sigma \\colon (1\\,2\\,3)\n\nWe can also define a permutation \\tau \\in S_3 By\n\n\\tau \\colon \\{1,2,3\\} \\to \\{2,1,3\\}\n\nWhich is represented in shorthand by\n\n\\tau \\colon (1\\,2)(3) \\text{ or } \\tau \\colon (1\\,2)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA cycle is a string of integers representing an element of S_n which cyclicly permutes the integers.\nEg. (1\\,2\\,3), (1\\,2)(3)::: {.callout-note icon=“false”} ## Definition\nD_{2n} with these operations is called the dihedral group of order 2n.\n\n\n\n\n\n\n\n\nExample\n\n\n\nContinuing to examine S_3, we know that there exist 3! = 6 total permutations of the set. We can denote the identity permutation\n\n(1)(2)(3)\n\nWe have three example where we leave one number untouched \n(1)(2\\,3), (2)(1\\,3), (3)(1\\,2)\n\nAnd two examples where we permute every number\n\n(1\\,2\\,3), (1\\,3\\,2)\n\n\n\nFor any \\sigma \\in S_n, the cycle decomposition of \\sigma^{-1} is obtained by writing the numbers in cycle of the cycle decomposition of \\sigma is in reverse order. For example, given\n\n\\sigma \\colon (1\\,2\\,3),\\quad \\sigma^{-1} \\colon (3\\,2\\,1)\n\nWhen composing in S_n, we read from right to left, for example, if we were in S^4, and given \n\\sigma \\colon (1\\,2\\,3)(4),\\quad \\tau \\colon (1\\,2)(3\\,4)\n\nWe can get \\sigma \\circ \\tau by combining the two. Rather tedious, but we eventually get\n\n\\sigma \\circ \\tau \\colon (1\\to 3)(2\\to 2)(3\\to4)(4\\to1) = (1\\,3\\,4)(2)\n\nNote that S_n is non-abelian for all n\\geq3. That being said, disjoint cycles will commute. The order of an element \\sigma \\in S_n is the l.c.m of the lengths in it’s cycle decomposition.\nA trasposition is an element of length 2."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#homomorphisms-and-isomorphisms",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#homomorphisms-and-isomorphisms",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Homomorphisms and Isomorphisms",
    "text": "Homomorphisms and Isomorphisms\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) and (H,\\diamond) be groups.\nGiven a map \\varphi \\colon G \\to H, if we can show that\n\n\\forall x,y \\in G,\\, \\varphi (x \\star y) = \\varphi (x) \\diamond \\varphi(y)\n\nThe \\varphi is a homomorphism\n\n\nOne can think of a homomorphism as a map of sets that respect the group operations. When group operations are not specified, we often abbreviate\n\n\\varphi(xy) = \\varphi(x)\\varphi(y)\n\nWhere the LHS is the G operation, and the RHS is the operation in H.\n\n\n\n\n\n\nDefinition\n\n\n\nThe map\n\n\\varphi \\colon G \\to H\n\nis an Isomorphisms if \\varphi is both a homomorphism, and a bijection. If two groups are isomorphic, they are denoted\n\nG \\cong H\n\n\n\nIf two groups are isomorphic, they are essentially the same. Every property satisfied by G will be satisifed by H.\nA homomorphism from a group to itself is called an endomorphism, and an isomorphism from a group to itself is called an automorphism.\n\n\n\n\n\n\nExample\n\n\n\nTake the map \\varphi such that\n\n\\varphi \\colon (\\mathbb{Z},+) \\to (\\mathbb{Z}/m\\mathbb{Z}, +)\n\n\nx \\rightarrowtail [x]\n\nWe can prove \\varphi to be a homomorphism, as\n\n\\varphi (x+y) = [x + y]\n\n\n\\varphi (x) + \\varphi (y) = [x] + [y] = [x + y]\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any group G, the identity map\n\nG \\rightarrow G\n\n\nx \\rightarrowtail x\n\nis an isomorphism, and an automorphism. Therefore for any group G, there exists some \\varphi such that G is isomorphic to itself.\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any groups G,H, the map \\varphi\n\n\\varphi \\colon G \\rightarrow H\n\n\ng \\rightarrowtail e_H\n\nis called the trivial homomorphism. As\n\n\\varphi(g_1g_2) = e_H\n\n\n\\varphi (g_1)\\varphi (g_2) = e_He_H = e_H"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html",
    "href": "qmd/abstract/quotient-groups/quotient-group.html",
    "title": "Quotient groups",
    "section": "",
    "text": "Quotient groups"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#definitions",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#definitions",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) and (H,\\diamond) be groups.\nGiven a map \\varphi \\colon G \\to H, if we can show that\n\n\\forall x,y \\in G,\\, \\varphi (x \\star y) = \\varphi (x) \\diamond \\varphi(y)\n\nThe \\varphi is a homomorphism\n\n\nOne can think of a homomorphism as a map of sets that respect the group operations. When group operations are not specified, we often abbreviate\n\n\\varphi(xy) = \\varphi(x)\\varphi(y)\n\nWhere the LHS is the G operation, and the RHS is the operation in H.\n\n\n\n\n\n\nDefinition\n\n\n\nThe map\n\n\\varphi \\colon G \\to H\n\nis an Isomorphisms if \\varphi is both a homomorphism, and a bijection. If two groups are isomorphic, they are denoted\n\nG \\cong H\n\n\n\nIf two groups are isomorphic, they are essentially the same. Every property satisfied by G will be satisifed by H.\nA homomorphism from a group to itself is called an endomorphism, and an isomorphism from a group to itself is called an automorphism.\n\n\n\n\n\n\nExample\n\n\n\nTake the map \\varphi such that\n\n\\varphi \\colon (\\mathbb{Z},+) \\to (\\mathbb{Z}/m\\mathbb{Z}, +)\n\n\nx \\rightarrowtail [x]\n\nWe can prove \\varphi to be a homomorphism, as\n\n\\varphi (x+y) = [x + y]\n\n\n\\varphi (x) + \\varphi (y) = [x] + [y] = [x + y]\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any group G, the identity map\n\nG \\rightarrow G\n\n\nx \\rightarrowtail x\n\nis an isomorphism, and an automorphism. Therefore for any group G, there exists some \\varphi such that G is isomorphic to itself.\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any groups G,H, the map \\varphi\n\n\\varphi \\colon G \\rightarrow H\n\n\ng \\rightarrowtail e_H\n\nis called the trivial homomorphism. As\n\n\\varphi(g_1g_2) = e_H\n\n\n\\varphi (g_1)\\varphi (g_2) = e_He_H = e_H"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-morphisms",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-morphisms",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Properties of morphisms",
    "text": "Properties of morphisms\nNow we can be to look at some of the properties of homomorphisms and Isomorphisms.\n\n\n\n\n\n\nProposition 1.2.1\n\n\n\nLet \n(G, \\star) \\quad (H, \\diamond) \\quad (M, \\square).\n\nAlso let\n\nf \\colon G \\rightarrow H,\\quad g \\colon H \\rightarrow M\n\nbe homomorphisms. Then\n\ng \\circ f \\colon G \\rightarrow M\n\nis a homomorphism.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe proof is just a few lines of algebra\n\\begin{align*}\ng(f(x \\star y)) &= g(f(x) \\diamond f(y))\\\\\n&= g(f(x))\\, \\square \\,g(f(y)))\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.2.2\n\n\n\nLet\n\n\\varphi \\colon G \\rightarrow H\n\nbe a homomorphism. Let e_H,e_G be the identity of H and G respectivly. Then\n\n\\varphi(e_G) = e_H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy algebra\n\\begin{align*}\ne_G &= e_Ge_G\\\\\n\\varphi(e_G) = \\varphi&(e_Ge_G) = \\varphi(e_G)\\varphi(e_G)\\\\\n(\\varphi(e_G))^{-1}\\varphi(e_G) &= (\\varphi(e_G))^{-1}\\varphi(e_G)\\varphi(e_G)\\\\\ne_H &= e_H\\varphi(e_G)\\\\\ne_H &= \\varphi(e_G) \\quad\\square\n\\end{align*}\n\n\n\n\n\n\n\n\n\nProposition 1.2.3\n\n\n\nIf \\varphi \\colon G \\rightarrow H is an isomorphism, then\n\nThe cardinality of G and H are equivalent\nIf G is abelian, then H is abelian\nFor all x in G, the order of x is the order of \\varphi(x)\n\n\n\nThis proposition essentially states that Isomorphisms preserve group structure. The proof will make use of the following lemma\n\n\n\n\n\n\nLemma 1.2.4\n\n\n\nLet \\varphi \\colon G \\rightarrow H be a homomorphism. Then\n\n\\varphi(x^n) = \\varphi(x)^n \\quad \\forall n \\in \\mathbb{Z}\n\n\n\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\n\n\n\n\nNow to prove Proposition 1.2.3.\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\nWe have three cases for this proposition\nCase 1:\nCase 2:\nSuppose the order |x| = \\infty, |\\phi(x)| = n &lt; \\infty\nNote that \n\\varphi (x^n) = \\varphi (x)^n = e_H\n\nBecause\n\n\\varphi (e_G) = e_H\n\nBy the injective property (which we can use because we have a bijection), we have\n\nx^n = e_G\n\nThus |x| \\leq n &lt; \\infty. Thus |x| and |\\varphi(x)| must either both be finite or infinite.\nCase 3:\nSuppose |x| = n, |\\varphi(x)| = m. Then\n\n\\varphi(x)^n = \\varphi(x^n) = \\varphi(e_G) = e_H \\implies m \\leq n.\n\nSimilarly,\n\n\\varphi (e_G)= e_H = \\varphi (x)^m = \\varphi(x^m) \\implies m \\geq n\n\nThus\n\nm = n\n\n\n\n\nDetermining if two groups are isomorphic is an NP problem, so it can take a while to prove.\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\nLets take the following groups S_3 and \\mathbb{Z}/6\\mathbb{Z}. There does not exist an isomorphism between these two, as S_3 is abelian, and \\mathbb{Z}/6\\mathbb{Z} is not. Thus\n\nS_3 \\not \\cong \\mathbb{Z}/6\\mathbb{Z}\n\nThere is however, an isomorphism between D_6 and S_3.\nLet\n\nD_6 = \\{r,s \\mid r^3 = s^2 = 1, sr = r^{-1}s\\}\n\nWe can map\n\nS_3 \\rightarrow D_6\n\n\n(1\\,2\\,3) \\rightarrowtail r\n\n\n(1\\,2) \\rightarrowtail s\n\nWhich maps the generators to each other. Thus\n\nD_6 \\cong S_3"
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html",
    "href": "qmd/abstract/subgroups/definitions.html",
    "title": "Subgroups",
    "section": "",
    "text": "Definition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same notation.\nThis is notated\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLets look at some subgroups\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n(\\mathbb{Q}\\backslash \\{0\\},x) \\leq (\\mathbb{R}\\backslash\\{0\\},x)\n\n\n\nIf G is a group, and H = G, or H = \\{e_G\\}, these are both subgroups of G.\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric. This the relation is not an equivalence relation.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#subgroups",
    "href": "qmd/abstract/subgroups/definitions.html#subgroups",
    "title": "Subgroups",
    "section": "",
    "text": "Definition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same notation.\nThis is notated\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLets look at some subgroups\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n(\\mathbb{Q}\\backslash \\{0\\},x) \\leq (\\mathbb{R}\\backslash\\{0\\},x)\n\n\n\nIf G is a group, and H = G, or H = \\{e_G\\}, these are both subgroups of G.\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric. This the relation is not an equivalence relation.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#centralizers-normalizers-center",
    "href": "qmd/abstract/subgroups/definitions.html#centralizers-normalizers-center",
    "title": "Subgroups",
    "section": "Centralizers, Normalizers, Center",
    "text": "Centralizers, Normalizers, Center\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G.\nThe Centralizer of A in G is a set of elements of G that commute with all elements of A. This is denoted\n\nC_G(A) = \\{g \\in G \\mid gag^{-1} = a, \\; \\forall a \\in A\\}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe centralizer of a subset A of G is a subgroup of G. Symbollically \nC_G(A) \\leq G\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe know\n\ne \\in C_G(A)\n\nThus we can fufill the first property of a subgroup C_G(A) \\not = \\varnothing. Now, let x,y \\in C_G(A). We see\n\ny^{-1}yayy^{-1} = y^{-1}ay\n\n\na = y^{-1}ay = y^{-1}a(y^{-1})^{-1}\n\nThus y^{-1} \\in C_G(A).\nNow we wish to show xy \\in C_G(A)\n\n(xy)a(xy)^{-1} = xyay^{-1}x^{-1}\n\nBecause x,y \\in C_G(A), we have xy \\in C_G(A). Thus\n\nC_G(A) \\leq G\n\n\n\nNext\n\n\n\n\n\n\nDefinition\n\n\n\nThe center of G is denoted\n\nZ(G) = \\{g \\in G \\mid gx = xg,\\, \\forall x \\in G\\}\n\n\n\nThe center of G is the centralizer where A = G. Clearly Then\n\nZ(G) = C_G(G)\n\n\nZ(G) \\leq G\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G, such that g \\in G.\n\ngAg^{-1} = \\{gag^{-1} \\mid a \\in A\\}\n\n\n\nWe use this definition immeditally\n\n\n\n\n\n\nDefinition\n\n\n\nThe normalizer of A in G is denoted\n\nN_G(A) = \\{g \\in G \\mid gAg^{-1} = A\\}\n\n\n\nNote that C_G(A) \\leq N_G(A).\nIf G is abelian, then\n\nZ(G) = G, \\quad C_G(A) = G, \\quad N_G(A) = G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G = D_8, and our subset A = \\{e,r,r^2,r^3\\}.\nWe want to find C_{D_8}\nWe know that A \\subset C_{D_8}(A) because rotations are commutative, that meaning\n\nr^ir^j = r^{i+j} = r^{j+i} = r^jr^i\n\nWe know that sr \\not = rs, so s\\not \\in C_{D_8}(A). We now need to check the remaining elements of D_8, sr,sr^2,sr^3.\nBecause C_{D_8}(A) \\leq D_8 we have\n\nsr^i \\in C_{D_8}(A) \\implies sr^ir^{-1} = s \\in C_{D_8}\n\nWhich is a contradiction, thus\n\nC_{D_8}(A) = A\n\nNow lets find N_{D_8}(A).\nBecause C_{D_8} \\leq N_{D_8}, we know A \\subseteq N_{D_8}(A). We have then\n\nsAs^{-1} = \\{ses^{-1},srs^{-1},sr^2s^{-1},sr^3s^{-1}\\}\n\nTake as a fact r^is = sr^{-1}. Thus\n\nsAs^{-1} = \\{e,r^3,r^2,r\\}\n\nThus s \\in N_{D_8}. We need now check sr^i. Because N_{D_8}(A) \\leq D_8, we have that sr^i is in the normalizer. Thus\n\nN_{D_8}(A) = D_8\n\nWe now wish to find the center of D_8. Since\n\nZ(D_8) \\leq C_{D_8}(A)\n\nWe know that Z(D_8) \\subseteq A.\nWe can check these four elements of A to see if their commutative with everything. We have\n\nrs = sr^{-1} \\not =sr\n\nThus r is not commutative with s, and is not in the center.\n\nr^2s = sr^{-2} = sr^2\n\nSo r^2 commutes with s. Now we check if it commutes with sr^i.\n\nr^2sr^i = sr^{-2}r^i = sr^ir^{-2}\n\nThus our center is \nZ(D_8) = \\{e,r^2\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#subgroups-generated-by-subsets",
    "href": "qmd/abstract/subgroups/definitions.html#subgroups-generated-by-subsets",
    "title": "Subgroups",
    "section": "2.4 Subgroups generated by subsets",
    "text": "2.4 Subgroups generated by subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im} \\varphi = \\{\\varphi(x) \\mid x \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then the \\ker \\varphi \\leq G and \\text{im} \\leq H.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\phi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H."
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#quotient-groups",
    "href": "qmd/abstract/subgroups/definitions.html#quotient-groups",
    "title": "Subgroups",
    "section": "Quotient groups",
    "text": "Quotient groups\nAnother way to get a smaller subgroup from a group G is by forming a quotient group.\nSubgroups of H \\leq G are injective onto G.\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism.\nFibers are sets of elements in G that map to single points in H.\nDraw a box and a line???"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html",
    "href": "qmd/abstract/intro-to-groups/subgroups.html",
    "title": "Subgroups",
    "section": "",
    "text": "Subgroups are subsets of groups which are also groups in their own right."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#definition",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#definition",
    "title": "Subgroups",
    "section": "Definition",
    "text": "Definition\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same operation.\nIf H is a subgroup of G, we write\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G be the group (\\mathbb{Q},+). We previously showed that (\\mathbb{Z},+) was a group. Because \\mathbb{Z} \\subseteq \\mathbb{Q}, we have\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n\n\n\nTrivially, if G is a group, H = G and H = e_G are both subgroups of G.\n\n\n\n\n\n\nExample\n\n\n\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\n\n\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#centralizers-normalizers-center",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#centralizers-normalizers-center",
    "title": "Subgroups",
    "section": "Centralizers, Normalizers, Center",
    "text": "Centralizers, Normalizers, Center\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G.\nThe Centralizer of A in G is a set of elements of G that commute with all elements of A.\n\nC_G(A) = \\{g \\in G \\mid gag^{-1} = a, \\; \\forall a \\in A\\}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe centralizer of a subset A of G is a subgroup of G. \nC_G(A) \\leq G\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe know\n\ne \\in C_G(A)\n\nThus we can fufill the first property of a subgroup C_G(A) \\not = \\varnothing. Now, let x,y \\in C_G(A). We see\n\ny^{-1}yayy^{-1} = y^{-1}ay\n\n\na = y^{-1}ay = y^{-1}a(y^{-1})^{-1}\n\nThus y^{-1} \\in C_G(A).\nNow we wish to show xy \\in C_G(A)\n\n(xy)a(xy)^{-1} = xyay^{-1}x^{-1}\n\nBecause x,y \\in C_G(A), we have xy \\in C_G(A). Thus\n\nC_G(A) \\leq G\n\n\n\n\nAttempting to give an explanation, the centralizer is an operation which when given a set G, and a subset A \\subset G, gives all elements of A which commute with every element in G.\n\n\n\n\n\n\nDefinition\n\n\n\nThe center of G is defined\n\nZ(G) = \\{g \\in G \\mid gx = xg,\\, \\forall x \\in G\\}\n\n\n\nThe center of G is the centralizer where A = G. Clearly Then\n\nZ(G) = C_G(G)\n\n\nZ(G) \\leq G\n\n\n\n\n\n\n\nNotation\n\n\n\nLet A be a subset of a group G, such that g \\in G.\n\ngAg^{-1} = \\{gag^{-1} \\mid a \\in A\\}\n\n\n\nNote that gag^{-1} does not neccessarily have to equal a. Given two elements a,b \\in A, such that \ngag^{-1} = b\\quad gbg^{-1} = a\n\nWe would still write gAg^{-1} = A.\n\n\n\n\n\n\nDefinition\n\n\n\nThe normalizer of A in G is denoted\n\nN_G(A) = \\{g \\in G \\mid gAg^{-1} = A\\}\n\n\n\nNote that C_G(A) \\leq N_G(A).\nIf G is abelian, then\n\nZ(G) = G, \\quad C_G(A) = G, \\quad N_G(A) = G\n\n\n\n\n\n\n\nExample (CHECK)\n\n\n\nLet G = D_8, and our subset A = \\{e,r,r^2,r^3\\}.\nWe want to find C_{D_8}\nWe know that A \\subset C_{D_8}(A) because rotations are commutative, that meaning\n\nr^ir^j = r^{i+j} = r^{j+i} = r^jr^i\n\nWe know that sr \\not = rs, so s\\not \\in C_{D_8}(A). We now need to check the remaining elements of D_8, sr,sr^2,sr^3.\nBecause C_{D_8}(A) \\leq D_8 we have\n\nsr^i \\in C_{D_8}(A) \\implies sr^ir^{-1} = s \\in C_{D_8}\n\nWhich is a contradiction, thus\n\nC_{D_8}(A) = A\n\nNow lets find N_{D_8}(A).\nBecause C_{D_8} \\leq N_{D_8}, we know A \\subseteq N_{D_8}(A). We have then\n\nsAs^{-1} = \\{ses^{-1},srs^{-1},sr^2s^{-1},sr^3s^{-1}\\}\n\nTake as a fact r^is = sr^{-1}. Thus\n\nsAs^{-1} = \\{e,r^3,r^2,r\\}\n\nThus s \\in N_{D_8}. We need now check sr^i. Because N_{D_8}(A) \\leq D_8, we have that sr^i is in the normalizer. Thus\n\nN_{D_8}(A) = D_8\n\nWe now wish to find the center of D_8. Since\n\nZ(D_8) \\leq C_{D_8}(A)\n\nWe know that Z(D_8) \\subseteq A.\nWe can check these four elements of A to see if their commutative with everything. We have\n\nrs = sr^{-1} \\not =sr\n\nThus r is not commutative with s, and is not in the center.\n\nr^2s = sr^{-2} = sr^2\n\nSo r^2 commutes with s. Now we check if it commutes with sr^i.\n\nr^2sr^i = sr^{-2}r^i = sr^ir^{-2}\n\nThus our center is \nZ(D_8) = \\{e,r^2\\}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#subgroups-generated-by-subsets",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#subgroups-generated-by-subsets",
    "title": "Subgroups",
    "section": "2.4 Subgroups generated by subsets",
    "text": "2.4 Subgroups generated by subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im} \\varphi = \\{\\varphi(x) \\mid x \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then the \\ker \\varphi \\leq G and \\text{im} \\leq H.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\phi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#definition-and-properties",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#definition-and-properties",
    "title": "Subgroups",
    "section": "Definition and Properties",
    "text": "Definition and Properties\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same operation.\nIf H is a subgroup of G, we write\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G be the group (\\mathbb{Q},+). We previously showed that (\\mathbb{Z},+) was a group. Because \\mathbb{Z} \\subseteq \\mathbb{Q}, we have\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n\n\n\nTrivially, if G is a group, H = G and H = e_G are both subgroups of G.\n\n\n\n\n\n\nExample\n\n\n\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\n\n\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric.\n\n\n\n\n\n\nProposition\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cap K\n\n\n(2)\\,x,y \\in H \\cup K \\implies x \\star y \\in H \\cup\n\n\n\n\nThere is a simpler way however to check if a group H is a subgroup of G, called the Subgroup criterion.\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nProof (Subgroup criterion)\n\n\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups",
    "title": "Subgroups",
    "section": "Cyclic groups",
    "text": "Cyclic groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups-rewrite",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups-rewrite",
    "title": "Subgroups",
    "section": "Cyclic groups (REWRITE)",
    "text": "Cyclic groups (REWRITE)\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#subsets",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#subsets",
    "title": "Subgroups",
    "section": "Subsets",
    "text": "Subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html#definitions",
    "href": "qmd/abstract/quotient-groups/quotient-group.html#definitions",
    "title": "Quotient groups",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im}\\,\\varphi = \\{\\varphi(g) \\mid g \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then\n\n\\ker \\varphi \\leq G \\: \\text{ and } \\: \\text{im} \\leq H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\varphi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a surjective homomorphism with \\ker k. The quotient group G/K is the group whose elements are the fibers of \\varphi with group operation inherited from H.\n\n\nThis definition requires knowing \\varphi explictly. You can however define the group operation on fibers in terms of representatives.\n\n\n\n\n\n\nProposition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with \\ker k. Let X \\in G/K be the fiber above a \\in H. X = \\varphi^{-1}(a). Then for any u \\in X,\n\nX = \\{uk\\mid k \\in K\\}\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet u \\in X, then \\varphi(u) = a. Let\n\nuK = \\{uk \\mid k \\in K\\}\n\nWe want to show that X is equal to uK. We will first show that uK is a subset of X. For k \\in K \n\\varphi(uk) = \\varphi(u)\\varphi(k) = \\varphi(u) = a\n\nThus uK \\subseteq X. Now to show that X \\subseteq uK, let g \\in X and k = u^{-1}g. \n\\varphi(k) = \\varphi(u^{-1})\\varphi(g) = a^{-1}a = e_H\n\nThus k \\in \\ker \\varphi since k = u^{-1}g. Thus X \\subseteq uK\n\n\nThus we can write any elements of the quoitent group as the set uk for all k \\in K.\n\n\n\n\n\n\nDefinition\n\n\n\nFor any N \\leq G and g \\in G,\n\ngN = \\{gn\\mid n \\in N\\}\n\nThis is a (left) coset of N in G.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet \\varphi \\colon G \\to H homomorphism with a kernal K. The set of cosets of K in G with operation uK \\star vK = (uv)K forms a group.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet X,Y \\in G/K, and Z = XY \\in G/K. Then for some a,b \\in H, \nX = \\varphi^{-1}(a)\\: Y = \\varphi^{-1}(b)\n\nThis implies Z = \\varphi^{-1}(ab). Let u,v be representations of X,Y respectivly. We want to show that uv \\in Z. Which is only true If\n\n\\varphi(uv) \\in ab \\leftrightarrow \\varphi(u)\\varphi(v) = ab\n\nWhich is true! Thus by our previous proposition Z = uvK.\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\nTheorem\n\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with Kernal K. Then\n\ngKg^{-1} \\subseteq K \\; \\forall g \\in G\n\n\\varphi(gkg^{-1}) = e\n\n\nIf we have a subgroup N of $G such that gNg^{-1} \\subseteq N for all g \\in G, then multiplication in G/N is well defined.\n\n\n\n\n\n\nTheorem\n\n\n\nG/N \\times G/N \\rightarrow G/N\n (xN, xG)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf x_1N = x_2N, y_1N=y_2N then x_1^{-1}x_2 \\in N and y_1^{-1}y_2 \\in N"
  },
  {
    "objectID": "qmd/abstract/intro.html#abstract",
    "href": "qmd/abstract/intro.html#abstract",
    "title": "Intro",
    "section": "",
    "text": "Its like algebra but more abstract ig idk"
  }
]